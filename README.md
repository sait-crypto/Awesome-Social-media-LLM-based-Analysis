# Awesome Social Media Analysis with LLM Method

> **Contributions**
>
> If you want to add your own paper or update paper details, please follow the [contributor_manual](./docs/contributor_manual_chs.md)  for the relevant operations. We greatly appreciate your contributions. Alternatively, you can email me  ([Gmail](lixiajie2182712226@gmail.com))with the links to your paper and project, and I will manually add your paper to the list.

### **technical and manual documentation guide**
[contributor_manual](./docs/contributor_manual_chs.md) 
<br>[plugin_manual](./docs/plugin_manual.md)
<br>[PROJECT_README](./docs/PROJECT_README.md)
<br>[maintenance_manual](./docs/maintenance_manual.md)
>[Download the recommended Zotero plugins](https://github.com/sait-crypto/Awesome-Social-media-LLM-based-Analysis/raw/refs/heads/main/tools/One-Click%20Copy%20Metadata.xpi):
<br>Developed specifically for this project, it can work with the GUI interface to quickly fill in paper information.Refer to the technical documentation for details.
<br>(chs: ç‰¹åœ°ä¸ºè¯¥é¡¹ç›®å¼€å‘ï¼Œå¯é…åˆguiç•Œé¢å¿«é€Ÿå¡«å†™è®ºæ–‡ä¿¡æ¯ï¼Œè¯¦æƒ…è§æŠ€æœ¯æ–‡æ¡£)
><br><br>This plugin can also be used as an alternative:
<br>https://zotero-chinese.com/plugins/#search=Zutilo%20Utility%20for%20Zotero
---
<p align="center">
<img src="assets/taxonomy.png" width = "95%" alt="" align=center />
</p>

>For complete paper information, please refer to the paper_database.xlsx file.
><br>å®Œæ•´è®ºæ–‡ä¿¡æ¯å¯ä»¥æŸ¥çœ‹paper_database.xlsxæ–‡ä»¶

### Key Points for Table Usage
- <b>Paper Link</b>: Please click the paper title
- <b>Paper Project Link</b>: Please click the GitHub icon or Project icon above the paper title
- <b>Summary</b> and <b>Notes</b> can be expanded by clicking

## Full paper list (27 papers)
### Quick Links

  - [Uncategorized](#-Uncategorized-0-papers) (0 papers)
  - [Base Techniques](#-Base-Techniques-2-papers) (2 papers)
  - [Perception and Classification](#-Perception-and-Classification-14-papers) (14 papers)
    - [Hate Speech Analysis](#Hate-Speech-Analysis-4-papers) (4 papers)
    - [Misinformation Analysis](#Misinformation-Analysis-6-papers) (6 papers)
    - [Controversy Analysis](#Controversy-Analysis-0-papers) (0 papers)
    - [Sentiment Analysis](#Sentiment-Analysis-3-papers) (3 papers)
    - [Meme Analysis](#Meme-Analysis-0-papers) (0 papers)
    - [Steganography Detection](#Steganography-Detection-0-papers) (0 papers)
    - [User Stance Detection](#User-Stance-Detection-0-papers) (0 papers)
    - [Malicious User Detection](#Malicious-User-Detection-1-papers) (1 papers)
  - [Understanding](#-Understanding-6-papers) (6 papers)
    - [Event Extraction](#Event-Extraction-6-papers) (6 papers)
    - [Topic Modeling](#Topic-Modeling-0-papers) (0 papers)
    - [Social Psychological Phenomena Analysis](#Social-Psychological-Phenomena-Analysis-0-papers) (0 papers)
    - [Social Popularity Prediction](#Social-Popularity-Prediction-0-papers) (0 papers)
    - [User Identity Understanding](#User-Identity-Understanding-0-papers) (0 papers)
    - [User Profiling](#User-Profiling-0-papers) (0 papers)
    - [User Behavior Prediction](#User-Behavior-Prediction-0-papers) (0 papers)
    - [Dynamic Community Analysis](#Dynamic-Community-Analysis-0-papers) (0 papers)
    - [Information Diffusion Analysis](#Information-Diffusion-Analysis-0-papers) (0 papers)
  - [Generation](#-Generation-2-papers) (2 papers)
    - [Comment Generation](#Comment-Generation-2-papers) (2 papers)
    - [Debate Generation](#Debate-Generation-0-papers) (0 papers)
    - [Rumor Refutation Generation](#Rumor-Refutation-Generation-0-papers) (0 papers)
    - [Psychological Healing](#Psychological-Healing-0-papers) (0 papers)
    - [Misinformation Generation](#Misinformation-Generation-0-papers) (0 papers)
    - [Humor Generation](#Humor-Generation-0-papers) (0 papers)
    - [Social Bots](#Social-Bots-0-papers) (0 papers)
  - [Simulation and Deduction](#-Simulation-and-Deduction-4-papers) (4 papers)
    - [Social Simulation](#Social-Simulation-3-papers) (3 papers)
    - [Social Network Simulation](#Social-Network-Simulation-1-papers) (1 papers)
    - [Town/Community Simulation](#TownCommunity-Simulation-0-papers) (0 papers)
    - [Game Simulation](#Game-Simulation-0-papers) (0 papers)
    - [Family Simulation](#Family-Simulation-0-papers) (0 papers)
    - [Macrosocial Phenomena Analysis](#Macrosocial-Phenomena-Analysis-1-papers) (1 papers)
    - [Frontier Applications](#Frontier-Applications-0-papers) (0 papers)
  - [Social Media Security](#-Social-Media-Security-0-papers) (0 papers)
  - [Other](#-Other-0-papers) (0 papers)


### | Base Techniques (2 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
|[![Project](https://img.shields.io/badge/Project-View-blue)](https://netsys.surrey.ac.uk/datasets/slashdot/) [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Conversation Kernels: A Flexible Mechanism to Learn Relevant Context for Online Conversation Unde...](https://ojs.aaai.org/index.php/ICWSM/article/view/35800) <br> Vibhor Agarwal,Arjoo Gupta,Suparna De,Nishanth Sastry <br> 2025-06-07 <br> <span style="color:cyan">[multi-categoryï¼š[Base Techniques](#-Base-Techniques-2-papers), [Comment Generation](#Comment-Generation-2-papers)]</span>|A flexible, structural context discovery framework that enhances conversation understanding by learning to attend to relevant topological neighborhoods within conversation trees.\[ç¿»è¯‘\] ä¸€ä¸ªçµæ´»çš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡å‘ç°æ¡†æ¶ï¼Œé€šè¿‡å­¦ä¹ å…³æ³¨å¯¹è¯æ ‘å†…ç›¸å…³çš„æ‹“æ‰‘é‚»åŸŸæ¥å¢å¼ºå¯¹è¯ç†è§£èƒ½åŠ›ã€‚|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Conversation Kernels.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Conversation Kernels2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Addressing the sparsity and context-dependency of individual online utterances, where traditional models often fail to capture implicit dependencies within conversation trees or introduce noise through indiscriminate context inclusion. \[ç¿»è¯‘\] é’ˆå¯¹åœ¨çº¿è¨€è®ºå›ºæœ‰çš„ç¨€ç–æ€§å’Œè¯­å¢ƒä¾èµ–æ€§é—®é¢˜ï¼Œå³ä¼ ç»Ÿæ¨¡å‹å¾€å¾€éš¾ä»¥æ•æ‰å¯¹è¯æ ‘å†…çš„éšå¼ä¾èµ–å…³ç³»ï¼Œæˆ–å› æ— å·®åˆ«åœ°å¼•å…¥ä¸Šä¸‹æ–‡è€Œäº§ç”Ÿå™ªå£° **[innovation]** The proposal of &quot;Conversation Kernels,&quot; a general-purpose mechanism that employs flexible topological shapes to retrieve fine-grained, structured conversational context, distinguishing itself by identifying the &quot;right&quot; structural neighborhood rather than merely increasing context length. \[ç¿»è¯‘\] æå‡ºäº†â€œå¯¹è¯æ ¸â€è¿™ä¸€é€šç”¨æœºåˆ¶ï¼Œåˆ©ç”¨çµæ´»çš„æ‹“æ‰‘å½¢çŠ¶æ¥æ£€ç´¢ç»†ç²’åº¦çš„ç»“æ„åŒ–å¯¹è¯ä¸Šä¸‹æ–‡ï¼›å…¶ç‹¬åˆ°ä¹‹å¤„åœ¨äºé€šè¿‡è¯†åˆ«â€œæ­£ç¡®â€çš„ç»“æ„é‚»åŸŸè€Œéå•çº¯å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦æ¥ç†è§£å¯¹è¯ã€‚ **[method]** An end-to-end trained probabilistic framework that first retrieves relevant structural windows \(e.g., ancestors, neighbors\) via similarity scoring, and subsequently fuses these contexts through a weighted marginalization of the predictive distributions generated by a RoBERTa-based encoder. \[ç¿»è¯‘\] ä¸€ä¸ªç«¯åˆ°ç«¯è®­ç»ƒçš„æ¦‚ç‡æ¡†æ¶ï¼Œé¦–å…ˆé€šè¿‡ç›¸ä¼¼åº¦è¯„åˆ†æ£€ç´¢ç›¸å…³çš„ç»“æ„åŒ–çª—å£ï¼ˆå¦‚ç¥–å…ˆã€é‚»å±…ï¼‰ï¼Œéšåé€šè¿‡å¯¹RoBERTaç¼–ç å™¨ç”Ÿæˆçš„é¢„æµ‹åˆ†å¸ƒè¿›è¡ŒåŠ æƒæ±‚å’Œï¼ˆè¾¹ç¼˜åŒ–ï¼‰ï¼Œä»è€Œèåˆè¿™äº›ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\[é€šä¿—æ ¸å¿ƒ\]é’ˆå¯¹ç›®æ ‡è¯„è®ºæ„å»ºå›å¤æ ‘ï¼Œå–å‡ ä¸ªçª—å£ï¼ˆå¦‚çˆ¶è¯„è®ºçª—å£ã€1è·³çª—å£ï¼‰ï¼Œæ¯ä¸ªçª—å£ä¸­æ‰€æœ‰è¯„è®ºä¸åŸè¯„è®ºæ‹¼æ¥ï¼Œå¹¶è¿›è¡Œé¢„æµ‹ï¼Œæœ€åä¸åŒçª—å£ä¸åŸè¯„è®ºçš„ç›¸å…³æ€§ç»è¿‡softmaxä½œä¸ºæƒé‡ï¼Œå¯¹æ‰€æœ‰é¢„æµ‹ç½®ä¿¡åº¦åŠ æƒå’Œï¼Œå¾—åˆ°æœ€ç»ˆç»“æœ **[conclusion/contribution]** Extensive experiments on Slashdot data demonstrate that context-augmented kernels outperform baseline transformers by up to 20% in accuracy and surpass general-purpose LLMs \(GPT-3.5/4\) in specific categorization tasks, revealing that different tasks require distinct structural context patterns. \[ç¿»è¯‘\] åœ¨Slashdotæ•°æ®ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œä¸Šä¸‹æ–‡å¢å¼ºçš„æ ¸æœºåˆ¶åœ¨å‡†ç¡®ç‡ä¸Šæ¯”åŸºçº¿Transformeræ¨¡å‹é«˜å‡º20%ï¼Œå¹¶åœ¨ç‰¹å®šåˆ†ç±»ä»»åŠ¡ä¸­è¶…è¶Šäº†é€šç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆGPT-3.5/4ï¼‰ï¼Œæ­ç¤ºäº†ä¸åŒä»»åŠ¡éœ€è¦æˆªç„¶ä¸åŒçš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ¨¡å¼ã€‚ **[limitation/future]** The approach relies heavily on explicit tree-structured reply threads, limiting applicability in flat discussion formats, and may face cold-start challenges in early-stage conversations with sparse context. \[ç¿»è¯‘\] è¯¥æ–¹æ³•ä¸¥é‡ä¾èµ–æ˜¾å¼çš„æ ‘çŠ¶å›å¤çº¿ç´¢ï¼Œé™åˆ¶äº†å…¶åœ¨æ‰å¹³åŒ–è®¨è®ºå½¢å¼ä¸­çš„é€‚ç”¨æ€§ï¼Œå¹¶ä¸”åœ¨ä¸Šä¸‹æ–‡ç¨€ç–çš„å¯¹è¯æ—©æœŸé˜¶æ®µå¯èƒ½é¢ä¸´å†·å¯åŠ¨æŒ‘æˆ˜ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Addressing the sparsity and context-dependency of individual online utterances, where traditional models often fail to capture implicit dependencies within conversation trees or introduce noise through indiscriminate context inclusion.<br>\[ç¿»è¯‘\] é’ˆå¯¹åœ¨çº¿è¨€è®ºå›ºæœ‰çš„ç¨€ç–æ€§å’Œè¯­å¢ƒä¾èµ–æ€§é—®é¢˜ï¼Œå³ä¼ ç»Ÿæ¨¡å‹å¾€å¾€éš¾ä»¥æ•æ‰å¯¹è¯æ ‘å†…çš„éšå¼ä¾èµ–å…³ç³»ï¼Œæˆ–å› æ— å·®åˆ«åœ°å¼•å…¥ä¸Šä¸‹æ–‡è€Œäº§ç”Ÿå™ªå£°<br>**[innovation]** The proposal of "Conversation Kernels," a general-purpose mechanism that employs flexible topological shapes to retrieve fine-grained, structured conversational context, distinguishing itself by identifying the "right" structural neighborhood rather than merely increasing context length.<br>\[ç¿»è¯‘\] æå‡ºäº†â€œå¯¹è¯æ ¸â€è¿™ä¸€é€šç”¨æœºåˆ¶ï¼Œåˆ©ç”¨çµæ´»çš„æ‹“æ‰‘å½¢çŠ¶æ¥æ£€ç´¢ç»†ç²’åº¦çš„ç»“æ„åŒ–å¯¹è¯ä¸Šä¸‹æ–‡ï¼›å…¶ç‹¬åˆ°ä¹‹å¤„åœ¨äºé€šè¿‡è¯†åˆ«â€œæ­£ç¡®â€çš„ç»“æ„é‚»åŸŸè€Œéå•çº¯å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦æ¥ç†è§£å¯¹è¯ã€‚<br>**[method]** An end-to-end trained probabilistic framework that first retrieves relevant structural windows \(e.g., ancestors, neighbors\) via similarity scoring, and subsequently fuses these contexts through a weighted marginalization of the predictive distributions generated by a RoBERTa-based encoder.<br>\[ç¿»è¯‘\] ä¸€ä¸ªç«¯åˆ°ç«¯è®­ç»ƒçš„æ¦‚ç‡æ¡†æ¶ï¼Œé¦–å…ˆé€šè¿‡ç›¸ä¼¼åº¦è¯„åˆ†æ£€ç´¢ç›¸å…³çš„ç»“æ„åŒ–çª—å£ï¼ˆå¦‚ç¥–å…ˆã€é‚»å±…ï¼‰ï¼Œéšåé€šè¿‡å¯¹RoBERTaç¼–ç å™¨ç”Ÿæˆçš„é¢„æµ‹åˆ†å¸ƒè¿›è¡ŒåŠ æƒæ±‚å’Œï¼ˆè¾¹ç¼˜åŒ–ï¼‰ï¼Œä»è€Œèåˆè¿™äº›ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\[é€šä¿—æ ¸å¿ƒ\]é’ˆå¯¹ç›®æ ‡è¯„è®ºæ„å»ºå›å¤æ ‘ï¼Œå–å‡ ä¸ªçª—å£ï¼ˆå¦‚çˆ¶è¯„è®ºçª—å£ã€1è·³çª—å£ï¼‰ï¼Œæ¯ä¸ªçª—å£ä¸­æ‰€æœ‰è¯„è®ºä¸åŸè¯„è®ºæ‹¼æ¥ï¼Œå¹¶è¿›è¡Œé¢„æµ‹ï¼Œæœ€åä¸åŒçª—å£ä¸åŸè¯„è®ºçš„ç›¸å…³æ€§ç»è¿‡softmaxä½œä¸ºæƒé‡ï¼Œå¯¹æ‰€æœ‰é¢„æµ‹ç½®ä¿¡åº¦åŠ æƒå’Œï¼Œå¾—åˆ°æœ€ç»ˆç»“æœ<br>**[conclusion/contribution]** Extensive experiments on Slashdot data demonstrate that context-augmented kernels outperform baseline transformers by up to 20% in accuracy and surpass general-purpose LLMs \(GPT-3.5/4\) in specific categorization tasks, revealing that different tasks require distinct structural context patterns.<br>\[ç¿»è¯‘\] åœ¨Slashdotæ•°æ®ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œä¸Šä¸‹æ–‡å¢å¼ºçš„æ ¸æœºåˆ¶åœ¨å‡†ç¡®ç‡ä¸Šæ¯”åŸºçº¿Transformeræ¨¡å‹é«˜å‡º20%ï¼Œå¹¶åœ¨ç‰¹å®šåˆ†ç±»ä»»åŠ¡ä¸­è¶…è¶Šäº†é€šç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆGPT-3.5/4ï¼‰ï¼Œæ­ç¤ºäº†ä¸åŒä»»åŠ¡éœ€è¦æˆªç„¶ä¸åŒçš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ¨¡å¼ã€‚<br>**[limitation/future]** The approach relies heavily on explicit tree-structured reply threads, limiting applicability in flat discussion formats, and may face cold-start challenges in early-stage conversations with sparse context.<br>\[ç¿»è¯‘\] è¯¥æ–¹æ³•ä¸¥é‡ä¾èµ–æ˜¾å¼çš„æ ‘çŠ¶å›å¤çº¿ç´¢ï¼Œé™åˆ¶äº†å…¶åœ¨æ‰å¹³åŒ–è®¨è®ºå½¢å¼ä¸­çš„é€‚ç”¨æ€§ï¼Œå¹¶ä¸”åœ¨ä¸Šä¸‹æ–‡ç¨€ç–çš„å¯¹è¯æ—©æœŸé˜¶æ®µå¯èƒ½é¢ä¸´å†·å¯åŠ¨æŒ‘æˆ˜ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">ã€åŸºç¡€æŠ€æœ¯â€”ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ–¹æ³•ã€‘å¯ç”¨äºæ‰€æœ‰å†…å®¹ç†è§£ä»»åŠ¡ï¼Œè®ºæ–‡ä¸­çš„å®éªŒç”¨çš„æ˜¯æ˜¯å¦å—æ¬¢è¿äºŒåˆ†ç±»<br>\[å¼•ç”¨æ–‡\]To better bridge pattern recognition with social interaction structures, Agarwal et al. \(2025\) proposed Conversation Kernels, an end-to-end framework designed to extract fine-grained context from conversation trees. By dynamically retrieving and weighting specific topological neighborhoods \(e.g., ancestors or siblings\) rather than ingesting linear history, their method effectively filters noise inherent in social discussions. This structural selectivity demonstrates that incorporating explicit interaction topologies is crucial for accurately decoding the nature of online conversations, yielding performance that surpasses even general-purpose Large Language Models like GPT-4.<br>\[ç¿»è¯‘\]<br>ä¸ºäº†æ›´å¥½åœ°å°†æ¨¡å¼è¯†åˆ«ä¸ç¤¾ä¼šäº’åŠ¨ç»“æ„è”ç³»èµ·æ¥ï¼ŒAgarwalç­‰äºº \(2025\) æå‡ºäº†â€œå¯¹è¯æ ¸ï¼ˆConversation Kernelsï¼‰â€ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨ä»å¯¹è¯æ ‘ä¸­æå–ç»†ç²’åº¦ä¸Šä¸‹æ–‡çš„ç«¯åˆ°ç«¯æ¡†æ¶ã€‚é€šè¿‡åŠ¨æ€æ£€ç´¢å¹¶åŠ æƒç‰¹å®šçš„æ‹“æ‰‘é‚»åŸŸï¼ˆå¦‚ç¥–å…ˆæˆ–å…„å¼ŸèŠ‚ç‚¹ï¼‰è€Œéæ‘„å…¥çº¿æ€§å†å²ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°è¿‡æ»¤äº†ç¤¾ä¼šè®¨è®ºä¸­å›ºæœ‰çš„å™ªå£°ã€‚è¿™ç§ç»“æ„é€‰æ‹©æ€§è¯æ˜ï¼Œç»“åˆæ˜¾å¼çš„äº’åŠ¨æ‹“æ‰‘å¯¹äºå‡†ç¡®è§£è¯»åœ¨çº¿å¯¹è¯çš„æ€§è´¨è‡³å…³é‡è¦ï¼Œå…¶è¡¨ç°ç”šè‡³è¶…è¶Šäº†åƒ GPT-4 è¿™æ ·çš„é€šç”¨å¤§è¯­è¨€æ¨¡å‹ã€‚</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/OpenBMB/IoA.svg?style=social&label=Star)](https://github.com/OpenBMB/IoA) [![Publish](https://img.shields.io/badge/Conference-The%20Thirteenth%20International%20Conference%20on%20Learning%20Representations-blue)]()<br>[Internet of agents: Weaving a web of heterogeneous agents for collaborative intelligence](https://openreview.net/forum?id=o1Et3MogPw) <br> Weize Chen\*, Ziming You\*, Ran Li\*, Yitong Guan\*, Chen Qian, Chenyang Zhao Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun <br> 2024-10-04|agentäº’è”ç½‘ï¼Œå‡çº§ç‰ˆABMç³»ç»Ÿï¼Œé‡‡ç”¨ç±»ä¼¼äº’è”ç½‘æ€æƒ³ï¼ŒC/Sæ¶æ„ï¼Œåˆ†å¸ƒåŒ–ã€æœåŠ¡åŒ–ã€å¹³å°åŒ–|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/IoA.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/IoA2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** å…ˆå‰çš„multi-agentç³»ç»Ÿçš„å±€é™æ€§ï¼Œç³»ç»ŸåŒ–å¹³å°åŒ–ç¨‹åº¦ä¸è¶³ï¼ˆç¼ºä¹ç¬¬ä¸‰æ–¹é›†æˆæ”¯æŒï¼Œæ— æ³•åˆ†å¸ƒå¼ï¼Œé€šä¿¡åè®®å’ŒçŠ¶æ€è½¬æ¢ä¾èµ–äºç¡¬ç¼–ç ï¼‰ **[innovation]** å°†äº’è”ç½‘çš„å¼€æ”¾ã€åˆ†å¸ƒå¼ã€æœåŠ¡åŒ–æ€æƒ³å¼•å…¥ï¼Œæ„å»ºä¸€ç§æ ‡å‡†åŒ–ã€å¯æ‰©å±•çš„æ”¯æŒåˆ†å¸ƒå¼ã€å¼‚æ„çš„æ™ºèƒ½ä½“é›†æˆä¸é€šä¿¡åè®®ã€‚ **[method]** æœåŠ¡å™¨ï¼šæ™ºèƒ½ä½“æ³¨å†Œï¼ˆåˆ†å‘ç³»ç»Ÿæç¤ºè¯ï¼‰ã€ç®¡ç†å·²æ³¨å†Œæ™ºèƒ½ä½“ï¼ˆä¸“å®¶ï¼‰ã€ä¸“å®¶å‘ç°æœåŠ¡ã€ç¾¤èŠç®¡ç†å’Œæ¶ˆæ¯ä¼ é€’ï¼›å®¢æˆ·ç«¯ï¼šåŒ…è£…å…·ä½“æ™ºèƒ½ä½“ï¼Œæä¾›é€šä¿¡æ¥å£ï¼›ä¸‰å±‚ç»“æ„ï¼›é€šä¿¡å³å¯åµŒå¥—çµæ´»ç¾¤èŠï¼›ç¾¤èŠé‡‡ç”¨**æœ‰é™çŠ¶æ€æœº**ç®¡ç†æµç¨‹ï¼›å¹³å°åˆå§‹åŒ–ä¸æ³¨å†Œ-&gt;ä»»åŠ¡è§¦å‘å›¢é˜Ÿå½¢æˆ-&gt;å†…éƒ¨åµŒå¥—åä½œ **[conclusion/contribution]** åœ¨ GAIA åŸºå‡†æµ‹è¯•ä¸­ï¼Œä»…ä½¿ç”¨å››ä¸ªåŸºç¡€ ReAct æ™ºèƒ½ä½“å³è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼›åœ¨ RAG ä»»åŠ¡ä¸­ï¼ŒåŸºäº GPT-3.5 çš„ IoA è¾¾åˆ°æˆ–è¶…è¿‡ GPT-4 çš„æ€§èƒ½ **[limitation/future]** å®éªŒä¸­å­˜åœ¨å†—ä½™æ¶ˆæ¯ï¼Œé€šä¿¡ Token æ¶ˆè€—å¢åŠ è¿‘ä¸€å€ï¼Œè¿™è¯æ˜agentä½œä¸ºå¯¹è¯è€…è€Œéæ‰§è¡Œè€…çš„æœ¬è´¨èƒ½åŠ›åŒºåˆ«ï¼›å•ç‚¹æœåŠ¡å™¨å¯èƒ½å­˜åœ¨ç“¶é¢ˆï¼›æ™ºèƒ½ä½“é€šè¿‡æ³¨å†Œè·å–æç¤ºè¯æˆä¸ºä¸åŒä¸“å®¶ï¼Œä»é«˜åº¦ä¾èµ–äººå·¥å®éªŒè®¾è®¡ï¼Œä¸”è¿™ç§ä¸“å®¶çš„èƒ½åŠ›æ˜¯å¦å¯é ">**[summary]**</summary><div style="margin-top:6px">**[motivation]** å…ˆå‰çš„multi-agentç³»ç»Ÿçš„å±€é™æ€§ï¼Œç³»ç»ŸåŒ–å¹³å°åŒ–ç¨‹åº¦ä¸è¶³ï¼ˆç¼ºä¹ç¬¬ä¸‰æ–¹é›†æˆæ”¯æŒï¼Œæ— æ³•åˆ†å¸ƒå¼ï¼Œé€šä¿¡åè®®å’ŒçŠ¶æ€è½¬æ¢ä¾èµ–äºç¡¬ç¼–ç ï¼‰<br>**[innovation]** å°†äº’è”ç½‘çš„å¼€æ”¾ã€åˆ†å¸ƒå¼ã€æœåŠ¡åŒ–æ€æƒ³å¼•å…¥ï¼Œæ„å»ºä¸€ç§æ ‡å‡†åŒ–ã€å¯æ‰©å±•çš„æ”¯æŒåˆ†å¸ƒå¼ã€å¼‚æ„çš„æ™ºèƒ½ä½“é›†æˆä¸é€šä¿¡åè®®ã€‚<br>**[method]** æœåŠ¡å™¨ï¼šæ™ºèƒ½ä½“æ³¨å†Œï¼ˆåˆ†å‘ç³»ç»Ÿæç¤ºè¯ï¼‰ã€ç®¡ç†å·²æ³¨å†Œæ™ºèƒ½ä½“ï¼ˆä¸“å®¶ï¼‰ã€ä¸“å®¶å‘ç°æœåŠ¡ã€ç¾¤èŠç®¡ç†å’Œæ¶ˆæ¯ä¼ é€’ï¼›å®¢æˆ·ç«¯ï¼šåŒ…è£…å…·ä½“æ™ºèƒ½ä½“ï¼Œæä¾›é€šä¿¡æ¥å£ï¼›ä¸‰å±‚ç»“æ„ï¼›é€šä¿¡å³å¯åµŒå¥—çµæ´»ç¾¤èŠï¼›ç¾¤èŠé‡‡ç”¨**æœ‰é™çŠ¶æ€æœº**ç®¡ç†æµç¨‹ï¼›å¹³å°åˆå§‹åŒ–ä¸æ³¨å†Œ->ä»»åŠ¡è§¦å‘å›¢é˜Ÿå½¢æˆ->å†…éƒ¨åµŒå¥—åä½œ<br>**[conclusion/contribution]** åœ¨ GAIA åŸºå‡†æµ‹è¯•ä¸­ï¼Œä»…ä½¿ç”¨å››ä¸ªåŸºç¡€ ReAct æ™ºèƒ½ä½“å³è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼›åœ¨ RAG ä»»åŠ¡ä¸­ï¼ŒåŸºäº GPT-3.5 çš„ IoA è¾¾åˆ°æˆ–è¶…è¿‡ GPT-4 çš„æ€§èƒ½<br>**[limitation/future]** å®éªŒä¸­å­˜åœ¨å†—ä½™æ¶ˆæ¯ï¼Œé€šä¿¡ Token æ¶ˆè€—å¢åŠ è¿‘ä¸€å€ï¼Œè¿™è¯æ˜agentä½œä¸ºå¯¹è¯è€…è€Œéæ‰§è¡Œè€…çš„æœ¬è´¨èƒ½åŠ›åŒºåˆ«ï¼›å•ç‚¹æœåŠ¡å™¨å¯èƒ½å­˜åœ¨ç“¶é¢ˆï¼›æ™ºèƒ½ä½“é€šè¿‡æ³¨å†Œè·å–æç¤ºè¯æˆä¸ºä¸åŒä¸“å®¶ï¼Œä»é«˜åº¦ä¾èµ–äººå·¥å®éªŒè®¾è®¡ï¼Œä¸”è¿™ç§ä¸“å®¶çš„èƒ½åŠ›æ˜¯å¦å¯é </div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">æ¯ä¸ªagentè¢«ä¸€ä¸ªå®¢æˆ·ç«¯åŒ…è£…ï¼›æœåŠ¡å™¨ä¸æ˜¯agentï¼Œå®ƒåªåšå››ä»¶äº‹ï¼šæ³¨å†Œã€å‘ç°ã€å»ºç¾¤ã€è·¯ç”±ï¼›ç›¸å¯¹äºä¼ ç»ŸABMï¼Œè¿™æ˜¯ä¸€ä¸ªæ›´å¤§å‹çš„æœåŠ¡ç³»ç»Ÿï¼Œè¯¥æ–¹æ³•é€šè¿‡åŸºäºä»»åŠ¡çš„â€œç¾¤èŠâ€æ–¹å¼ç»„ç»‡é—®é¢˜è§£å†³ï¼Œç›¸å¯¹ä¼ ç»Ÿå›åˆåˆ¶æ–¹å¼æ›´åŠ è‡ªç”±ã€‚æœ¬èº«ä¹Ÿæ˜¯ä¸€ä¸ªé«˜åº¦å¯æ‰©å±•ç³»ç»Ÿã€‚é—®é¢˜åœ¨äºæ™ºèƒ½ä½“é€šè¿‡æ³¨å†Œè·å–æç¤ºè¯æˆä¸ºä¸åŒä¸“å®¶ï¼Œä»ä¾èµ–æ‰‹å·¥è®¾è®¡ï¼Œä¸”è¿™ç§ä¸“å®¶çš„èƒ½åŠ›æ˜¯å¦å¯é ã€‚å¯¹äºç¤¾ä¼šæ¨¡æ‹Ÿä»»åŠ¡ç›¸å¯¹äºä¼ ç»Ÿæ–¹æ³•æœ‰ä½•å†³å®šæ€§ä¼˜åŠ¿ä»æœªå¯çŸ¥</div></details></div></div>|

### | Perception and Classification (14 papers)


### Hate Speech Analysis (4 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence-blue)]()<br>[TOT: Topology-Aware Optimal Transport for Multimodal Hate Detection](https://ojs.aaai.org/index.php/AAAI/article/view/25614) <br> Linhao Zhangï¼ŒLi Jinï¼ŒXian Sunï¼ŒGuangluan Xuï¼ŒZequn Zhang,Xiaoyu Li,Nayu Liu,Qing Liu,Shiyao Yan <br> 2023-06-26|å¼ºåŒ–æ¶æ„Memeçš„å›¾åƒä¸æ–‡æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ï¼Œä½¿ç”¨OTæ–¹æ³•å»ºç«‹ç‰¹å¾å‘é‡é—´çš„å¯è§£é‡Šè”ç³»|<img width="1200" alt="pipeline" src="figures/TOT.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** ä¸ºäº†è§£å†³å¤šæ¨¡æ€ä»‡æ¨æ£€æµ‹ä¸­å› â€ éšå¼å¯¹é½â€ å’Œâ€ æ¨¡æ€é¸¿æ²Ÿâ€ å¯¼è‡´çš„å›¾åƒå’Œæ–‡æœ¬è·¨æ¨¡æ€è¯­ä¹‰å¯¹é½éš¾é¢˜ **[innovation]** å°†OTç”¨äºç‰¹å¾å¯¹é½ï¼Œå°†å¥å­çº§å¯¹é½ç»†ç²’åŒ–è‡³å‘é‡çº§ï¼Œä¸ºåç»­å·¥ä½œæä¾›äº†â€œæ˜¾å¼å¯¹é½+ç»“æ„æ¨ç†â€çš„èŒƒå¼ **[method]** æœ€ä¼˜ä¼ è¾“ + æ‹“æ‰‘ç»“æ„æ¨ç†æ–¹æ³• TOTï¼šCLIP æ–¹æ³•ç»Ÿä¸€è¡¨å¾æ˜ å°„-&gt;æœ€ä¼˜ä¼ è¾“optimal transport \(OT\)å°†éšå¼è”ç³»ç»†ç²’åŒ–ä¸ºå‘é‡çº§ï¼ˆè¿™æ˜¯ä¸€ä¸ªæ•°å­¦è®¡ç®—è¿‡ç¨‹ï¼Œä¸æ¶‰åŠéœ€è¦å­¦ä¹ çš„å‚æ•°ï¼‰-&gt;ç±»GNNè¿­ä»£æ•æ‰è‡ªèº«è¯­ä¹‰è”ç³»ï¼ˆç±»è‡ªæ³¨æ„åŠ›ï¼‰ï¼ˆå› ä¸ºå‘é‡é—´è·ç¦»æ„ä¹‰æ˜ç¡®ï¼‰-&gt;æ®‹å·®è¿æ¥ **[conclusion/contribution]** è¾¾æˆäº†åœ¨ä¸¤ä¸ªæœ‰å®³ Meme æ£€æµ‹æ•°æ®é›†ï¼ˆHarm-C, Harm-Pï¼‰ä¸Šçš„æœ€å…ˆè¿›æ€§èƒ½ï¼› **[limitation/future]** å¯¹é½å’Œæ¨ç†ä»å±€é™äºç‰¹å¾å±‚é¢ï¼Œæœªä¸Šå‡åˆ°è¯­ä¹‰å•å…ƒï¼ˆå¦‚äº‹ä»¶ã€æ¦‚å¿µï¼‰å±‚é¢ï¼ŒOTè¿‡ç¨‹ä¸ºå†»ç»“æ— æ³•è®­ç»ƒçš„ï¼Œå¯ä»¥è®­ç»ƒå…¶å‚æ•°ä»¥å®ç°æ›´å¥½çš„å¯¹é½ï¼›å¯¹äºå¹½é»˜ç­‰ç±»ä¼¼éšå¼è¡¨è¾¾å®¹æ˜“è¯¯åˆ¤">**[summary]**</summary><div style="margin-top:6px">**[motivation]** ä¸ºäº†è§£å†³å¤šæ¨¡æ€ä»‡æ¨æ£€æµ‹ä¸­å› â€ éšå¼å¯¹é½â€ å’Œâ€ æ¨¡æ€é¸¿æ²Ÿâ€ å¯¼è‡´çš„å›¾åƒå’Œæ–‡æœ¬è·¨æ¨¡æ€è¯­ä¹‰å¯¹é½éš¾é¢˜<br>**[innovation]** å°†OTç”¨äºç‰¹å¾å¯¹é½ï¼Œå°†å¥å­çº§å¯¹é½ç»†ç²’åŒ–è‡³å‘é‡çº§ï¼Œä¸ºåç»­å·¥ä½œæä¾›äº†â€œæ˜¾å¼å¯¹é½+ç»“æ„æ¨ç†â€çš„èŒƒå¼<br>**[method]** æœ€ä¼˜ä¼ è¾“ + æ‹“æ‰‘ç»“æ„æ¨ç†æ–¹æ³• TOTï¼šCLIP æ–¹æ³•ç»Ÿä¸€è¡¨å¾æ˜ å°„->æœ€ä¼˜ä¼ è¾“optimal transport \(OT\)å°†éšå¼è”ç³»ç»†ç²’åŒ–ä¸ºå‘é‡çº§ï¼ˆè¿™æ˜¯ä¸€ä¸ªæ•°å­¦è®¡ç®—è¿‡ç¨‹ï¼Œä¸æ¶‰åŠéœ€è¦å­¦ä¹ çš„å‚æ•°ï¼‰->ç±»GNNè¿­ä»£æ•æ‰è‡ªèº«è¯­ä¹‰è”ç³»ï¼ˆç±»è‡ªæ³¨æ„åŠ›ï¼‰ï¼ˆå› ä¸ºå‘é‡é—´è·ç¦»æ„ä¹‰æ˜ç¡®ï¼‰->æ®‹å·®è¿æ¥<br>**[conclusion/contribution]** è¾¾æˆäº†åœ¨ä¸¤ä¸ªæœ‰å®³ Meme æ£€æµ‹æ•°æ®é›†ï¼ˆHarm-C, Harm-Pï¼‰ä¸Šçš„æœ€å…ˆè¿›æ€§èƒ½ï¼›<br>**[limitation/future]** å¯¹é½å’Œæ¨ç†ä»å±€é™äºç‰¹å¾å±‚é¢ï¼Œæœªä¸Šå‡åˆ°è¯­ä¹‰å•å…ƒï¼ˆå¦‚äº‹ä»¶ã€æ¦‚å¿µï¼‰å±‚é¢ï¼ŒOTè¿‡ç¨‹ä¸ºå†»ç»“æ— æ³•è®­ç»ƒçš„ï¼Œå¯ä»¥è®­ç»ƒå…¶å‚æ•°ä»¥å®ç°æ›´å¥½çš„å¯¹é½ï¼›å¯¹äºå¹½é»˜ç­‰ç±»ä¼¼éšå¼è¡¨è¾¾å®¹æ˜“è¯¯åˆ¤</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">æœ€ä¼˜ä¼ è¾“OTè´Ÿè´£å›ç­”â€œå›¾ç‰‡çš„å“ªä¸ªéƒ¨åˆ†å’Œæ–‡æœ¬çš„å“ªä¸ªè¯ç›¸å…³ï¼Ÿâ€ï¼ˆå®ç°ç»Ÿä¸€ä¸”å¯¹é½çš„è¡¨ç¤ºï¼Œä»è€Œå»ºç«‹è·¨æ¨¡æ€çš„æ˜¾å¼è”ç³»ï¼ŒOTæ–¹æ³•æ˜¯å¯è§£é‡Šçš„ï¼‰ã€‚ã€å³å°†CLIPç”Ÿæˆçš„ç‰¹å¾çŸ©é˜µçº§åˆ«çš„å¯¹é½ï¼Œç»†åŒ–ä¸ºç‰¹å¾å‘é‡é—´çš„å¯¹é½ï¼Œä¸¤ä¸ªç‰¹å¾çŸ©é˜µä¼šæ›´ç›¸åƒã€‚è¿™ç§æ˜¾å¼å¯¹é½èƒ½åŠ›æœ¬è´¨ä¸Šæ¥æºäºCLIPå®ç°çš„éšå¯¹é½ã€‘ï¼›æ‹“æ‰‘å»ºæ¨¡è´Ÿè´£å›ç­”â€œè¿™äº›ç›¸å…³çš„éƒ¨åˆ†ç»„åˆåœ¨ä¸€èµ·ï¼Œè¡¨è¾¾äº†ä»€ä¹ˆæ›´æ·±å±‚çš„å«ä¹‰ï¼Ÿâ€ï¼ˆæ•æ‰æ–‡æœ¬ï¼ˆå›¾ç‰‡ï¼‰ä¸­äº’ç›¸æœ‰è”ç³»çš„tokenï¼ˆpatchï¼‰ï¼Œè¿›è¡Œæ¨¡æ€å†…çš„æ·±åº¦æ¨ç†ï¼‰ã€‚ã€è¿™ç§ç±»ä¼¼GNNçš„æ–¹æ³•æœ¬è´¨ä¸Šæ˜¯æ›´æœ‰å±‚æ¬¡æ€§çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå¤©ç„¶é€‚ç”¨äºå¤„ç†å…³ç³»å‹æ•°æ®ï¼ˆå›¾ç»“æ„ï¼‰ã€‘ï¼›æœ¬è´¨ä¸Šæ˜¯å°†CLIPå»ºç«‹çš„éšå¼å¯¹é½ç»†ç²’åŒ–ä¸ºå‘é‡å±‚çº§çš„æ˜¾å¼å¯¹é½ï¼Œè¿›è€Œå¾—ä»¥ä½¿ç”¨å›¾æ¨ç†è¿›ä¸€æ­¥å­¦ä¹ å†…éƒ¨è”ç³»</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-IEEE%20Transactions%20on%20Multimedia-blue)]()<br>[Flexible optimal transport with contrastive graphical modeling for multimodal hate detection](https://ieeexplore.ieee.org/abstract/document/11045556) <br> Linhao Zhangï¼ŒLi Jinï¼ŒXiaoyu Li,Xian Sun,Senior Member,IEEE,Xin Wang,Zequn Zhang,Jian Liuï¼ŒZhicong Luï¼ŒGraduate Student Member,IEEE,and Guangluan Xu <br> 2025|\[AI generated\] This method bridges multimodal gaps like a flexible translator, aligning implicit hateful memes through optimal transport and contrastive graphs. \[ç¿»è¯‘\]è¯¥æ–¹æ³•é€šè¿‡æœ€ä¼˜ä¼ è¾“å’Œå›¾å¯¹æ¯”å­¦ä¹ ï¼Œåƒçµæ´»çš„ç¿»è¯‘å®˜ä¸€æ ·å¼¥åˆæ¨¡æ€é¸¿æ²Ÿï¼Œå¯¹é½éšå«ä»‡æ¨è¡¨æƒ…åŒ…ã€‚|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/FLOT1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/FLOT.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** ç¤¾åª’ä¸­éšå«ä»‡æ¨å†…å®¹æ£€æµ‹å›°éš¾ï¼Œä¼ ç»Ÿæ–¹æ³•éš¾ä»¥å®ç°è·¨æ¨¡æ€éšå¼å¯¹é½ã€‚ **[innovation]** ç›¸å¯¹äºåŒå›¢é˜Ÿçš„TOTæ˜¯æ”¹è¿› **[method]** ç›¸å¯¹äºåŒå›¢é˜Ÿçš„TOT:1.OTçš„ç›®æ ‡åŸŸä¸å†æ˜¯å¦ä¸€æ¨¡æ€çš„ç‰¹å¾ï¼Œè€Œæ˜¯å¯å­¦ä¹ çš„ç»Ÿä¸€åµŒå…¥ï¼ˆOTå¼•å…¥å¯å­¦ä¹ çš„å‚æ•°ï¼Œå®ƒä»¬æ˜¯ä¸¤ä¸ªæ¨¡æ€å„è‡ªå¯¹åº”çš„ç›®æ ‡ç‰¹å¾çŸ©é˜µ $T_v$ å’Œ $T_t$ï¼‰ï¼›2.å¼•å…¥äº†å›¾å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼Œæ˜¾å¼çº¦æŸä¸€è‡´æ€§ï¼ˆæ¯”è¾ƒä¸¤ä¸ªå›¾çš„ç›¸ä¼¼ç¨‹åº¦ä½œä¸ºä¸€ä¸ªæŸå¤±ï¼Œä¹‹åæ‰è¿›è¡Œç±»GNNèšåˆï¼ˆåŠ¨æ€æ‹“æ‰‘æ¨ç†ï¼‰ï¼‰ **[conclusion/contribution]** åœ¨Harm-Cã€Harm-Pã€MET-Memeä¸‰ä¸ªæ•°æ®é›†ä¸Šå–å¾—SOTAï¼Œæ˜¾è‘—æå‡å‡†ç¡®ç‡ä¸F1 **[limitation/future]** å¯¹äºå¹½é»˜ç­‰ç±»ä¼¼éšå¼è¡¨è¾¾å®¹æ˜“è¯¯åˆ¤">**[summary]**</summary><div style="margin-top:6px">**[motivation]** ç¤¾åª’ä¸­éšå«ä»‡æ¨å†…å®¹æ£€æµ‹å›°éš¾ï¼Œä¼ ç»Ÿæ–¹æ³•éš¾ä»¥å®ç°è·¨æ¨¡æ€éšå¼å¯¹é½ã€‚<br>**[innovation]** ç›¸å¯¹äºåŒå›¢é˜Ÿçš„TOTæ˜¯æ”¹è¿›<br>**[method]** ç›¸å¯¹äºåŒå›¢é˜Ÿçš„TOT:1.OTçš„ç›®æ ‡åŸŸä¸å†æ˜¯å¦ä¸€æ¨¡æ€çš„ç‰¹å¾ï¼Œè€Œæ˜¯å¯å­¦ä¹ çš„ç»Ÿä¸€åµŒå…¥ï¼ˆOTå¼•å…¥å¯å­¦ä¹ çš„å‚æ•°ï¼Œå®ƒä»¬æ˜¯ä¸¤ä¸ªæ¨¡æ€å„è‡ªå¯¹åº”çš„ç›®æ ‡ç‰¹å¾çŸ©é˜µ $T_v$ å’Œ $T_t$ï¼‰ï¼›2.å¼•å…¥äº†å›¾å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼Œæ˜¾å¼çº¦æŸä¸€è‡´æ€§ï¼ˆæ¯”è¾ƒä¸¤ä¸ªå›¾çš„ç›¸ä¼¼ç¨‹åº¦ä½œä¸ºä¸€ä¸ªæŸå¤±ï¼Œä¹‹åæ‰è¿›è¡Œç±»GNNèšåˆï¼ˆåŠ¨æ€æ‹“æ‰‘æ¨ç†ï¼‰ï¼‰<br>**[conclusion/contribution]** åœ¨Harm-Cã€Harm-Pã€MET-Memeä¸‰ä¸ªæ•°æ®é›†ä¸Šå–å¾—SOTAï¼Œæ˜¾è‘—æå‡å‡†ç¡®ç‡ä¸F1<br>**[limitation/future]** å¯¹äºå¹½é»˜ç­‰ç±»ä¼¼éšå¼è¡¨è¾¾å®¹æ˜“è¯¯åˆ¤</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-ACL%202024-blue)]()<br>[Improving Hateful Meme Detection through Retrieval-Guided Contrastive Learning](https://aclanthology.org/2024.acl-long.291) <br> Jingbiao Mei,Jinghong Chen,Weizhe Lin,Bill Byrne,Maarcus Tomalin <br> 2024|ä¸“é¢˜å¼ºåŒ–ï¼šéš¾å­¦æ ·æœ¬å•æ‹‰å‡ºæ¥ä¸æ­£ä¾‹è¿›è¡Œå¯¹æ¯”å­¦ä¹ ï¼Œä»è€Œæé«˜è¯†åˆ«èƒ½åŠ›|<img width="1200" alt="pipeline" src="figures/RGCL.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** ç°æœ‰CLIPç­‰æ¨¡å‹å¯¹ä»‡æ¨è¡¨æƒ…åŒ…çš„å›¾åƒ-æ–‡æœ¬çš„ç»†å¾®å·®å¼‚ï¼ˆå¦‚â€œæ··æ·†æ ·æœ¬â€ï¼‰æ•æ„Ÿåº¦ä¸è¶³ï¼Œå¯¼è‡´çš„è¯¯åˆ¤ã€‚ **[innovation]** å¯¹äºæ˜“æ··æ·†çš„éš¾ä¾‹ï¼ˆä¸å½“å‰æ ·æœ¬ç›¸ä¼¼åº¦æœ€é«˜ä½†æ ‡ç­¾ç›¸åçš„ï¼‰ï¼Œä½¿ç”¨**åŠ¨æ€æ£€ç´¢**æ–¹å¼å•æ‹‰å‡ºæ¥ï¼Œä¸**ä¼ªé»„é‡‘æ­£æ ·æœ¬**ï¼ˆå’Œå½“å‰æ ·æœ¬ç›¸ä¼¼åº¦æœ€é«˜çš„æ ‡ç­¾ç›¸åŒçš„ï¼‰æˆå¯¹ï¼Œä½œä¸ºæ­£åä¾‹è¿›è¡Œå¯¹æ¯”å­¦ä¹ ã€‚ä»è€Œè§£å†³é—®é¢˜ **[method]** 1. ä½¿ç”¨å†»ç»“çš„CLIPç¼–ç å™¨æå–å›¾æ–‡ç‰¹å¾ï¼› 2. é€šè¿‡Faissæ£€ç´¢åŠ¨æ€è·å–åŒç±»ç›¸ä¼¼æ ·æœ¬ï¼ˆä¼ªé»„é‡‘æ­£æ ·æœ¬ï¼‰ä¸å¼‚ç±»ç›¸ä¼¼æ ·æœ¬ï¼ˆå›°éš¾è´Ÿæ ·æœ¬ï¼‰ä½œä¸ºæ­£åä¾‹ï¼› 3. ç»“åˆæ­£åä¾‹å¯¹æ¯”æŸå¤±ï¼ˆRGCLLï¼‰ä¸äº¤å‰ç†µæŸå¤±è®­ç»ƒMLPï¼› 4. å®ç°é€»è¾‘åˆ†ç±»ä¸KNNæ£€ç´¢åˆ†ç±»ä¸¤ç§åˆ†ç±»å™¨ï¼Œåè€…é€šè¿‡ç›¸ä¼¼åº¦åŠ æƒæŠ•ç¥¨è¿›è¡Œé¢„æµ‹ã€‚ **[conclusion/contribution]** åœ¨HatefulMemesæ•°æ®é›†ä¸Šè¾¾åˆ° AUROC 87.0%ï¼ˆSOTAï¼‰ï¼Œè¶…è¶ŠFlamingo-80Bç­‰å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ **[limitation/future]** ä»‡æ¨è¨€è®ºçš„å®šä¹‰å…·æœ‰äº‰è®®æ€§ä¸æ–‡åŒ–ä¾èµ–æ€§ï¼›ç³»ç»Ÿå¯¹ ç»†å¾®é¢éƒ¨è¡¨æƒ… è¯†åˆ«èƒ½åŠ›æœ‰é™ï¼›ä¾èµ–æ•°æ®æ ‡æ³¨è´¨é‡ï¼Œå¯èƒ½å­˜åœ¨æ ‡æ³¨åå·®ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** ç°æœ‰CLIPç­‰æ¨¡å‹å¯¹ä»‡æ¨è¡¨æƒ…åŒ…çš„å›¾åƒ-æ–‡æœ¬çš„ç»†å¾®å·®å¼‚ï¼ˆå¦‚â€œæ··æ·†æ ·æœ¬â€ï¼‰æ•æ„Ÿåº¦ä¸è¶³ï¼Œå¯¼è‡´çš„è¯¯åˆ¤ã€‚<br>**[innovation]** å¯¹äºæ˜“æ··æ·†çš„éš¾ä¾‹ï¼ˆä¸å½“å‰æ ·æœ¬ç›¸ä¼¼åº¦æœ€é«˜ä½†æ ‡ç­¾ç›¸åçš„ï¼‰ï¼Œä½¿ç”¨**åŠ¨æ€æ£€ç´¢**æ–¹å¼å•æ‹‰å‡ºæ¥ï¼Œä¸**ä¼ªé»„é‡‘æ­£æ ·æœ¬**ï¼ˆå’Œå½“å‰æ ·æœ¬ç›¸ä¼¼åº¦æœ€é«˜çš„æ ‡ç­¾ç›¸åŒçš„ï¼‰æˆå¯¹ï¼Œä½œä¸ºæ­£åä¾‹è¿›è¡Œå¯¹æ¯”å­¦ä¹ ã€‚ä»è€Œè§£å†³é—®é¢˜<br>**[method]** 1. ä½¿ç”¨å†»ç»“çš„CLIPç¼–ç å™¨æå–å›¾æ–‡ç‰¹å¾ï¼›<br>2. é€šè¿‡Faissæ£€ç´¢åŠ¨æ€è·å–åŒç±»ç›¸ä¼¼æ ·æœ¬ï¼ˆä¼ªé»„é‡‘æ­£æ ·æœ¬ï¼‰ä¸å¼‚ç±»ç›¸ä¼¼æ ·æœ¬ï¼ˆå›°éš¾è´Ÿæ ·æœ¬ï¼‰ä½œä¸ºæ­£åä¾‹ï¼›<br>3. ç»“åˆæ­£åä¾‹å¯¹æ¯”æŸå¤±ï¼ˆRGCLLï¼‰ä¸äº¤å‰ç†µæŸå¤±è®­ç»ƒMLPï¼›<br>4. å®ç°é€»è¾‘åˆ†ç±»ä¸KNNæ£€ç´¢åˆ†ç±»ä¸¤ç§åˆ†ç±»å™¨ï¼Œåè€…é€šè¿‡ç›¸ä¼¼åº¦åŠ æƒæŠ•ç¥¨è¿›è¡Œé¢„æµ‹ã€‚<br>**[conclusion/contribution]** åœ¨HatefulMemesæ•°æ®é›†ä¸Šè¾¾åˆ° AUROC 87.0%ï¼ˆSOTAï¼‰ï¼Œè¶…è¶ŠFlamingo-80Bç­‰å¤§å‹å¤šæ¨¡æ€æ¨¡å‹<br>**[limitation/future]** ä»‡æ¨è¨€è®ºçš„å®šä¹‰å…·æœ‰äº‰è®®æ€§ä¸æ–‡åŒ–ä¾èµ–æ€§ï¼›ç³»ç»Ÿå¯¹ ç»†å¾®é¢éƒ¨è¡¨æƒ… è¯†åˆ«èƒ½åŠ›æœ‰é™ï¼›ä¾èµ–æ•°æ®æ ‡æ³¨è´¨é‡ï¼Œå¯èƒ½å­˜åœ¨æ ‡æ³¨åå·®ã€‚</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic Analysis of Annotators and T...](https://ojs.aaai.org/index.php/ICWSM/article/view/35837) <br> Tommaso Giorgi\*,Lorenzo Cima\*,Tiziano Fagni,Marco Avvenuti,Stefano Cresci <br> 2025-06-07|ä»‡æ¨è¨€è®ºåˆ†æä¸­çš„æ•°æ®é›†æ ‡æ³¨å¦‚ä½•å—ä¸»è§‚åè§å½±å“ï¼Œæç¤ºè¯å¼•å¯¼çš„è§’è‰²æ‰®æ¼”LLMèƒ½å¦å¤åˆ»è¿™ç§åè§|<img width="1200" alt="pipeline" src="figures/HateAnaBias.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** è¯¥é¢†åŸŸéœ€è¦å¤§é‡äººå·¥æ ‡æ³¨ï¼Œå­˜åœ¨å›ºæœ‰çš„ä¸»è§‚æ€§biasé—®é¢˜ï¼Œéœ€è¦ç³»ç»Ÿæ€§çš„ç ”ç©¶ **[innovation]** The authors introduce a novel methodological framework on the Measuring Hate Speech corpus that quantifies bias through &quot;Intensity&quot; and &quot;Prevalence&quot; metrics without relying on ground truth, uniquely isolating the interplay between specific annotator profiles and target groups. \[ç¿»è¯‘\] æŒ‡æ ‡è®¾è®¡ï¼šæå‡ºäº†åå·®å¼ºåº¦ï¼ˆIntensity, ğ¼ï¼‰å’Œåå·®æ™®éæ€§ï¼ˆPrevalence, ğ‘ƒï¼‰ï¼Œæ— éœ€Ground Truthå³å¯è¡¡é‡ç›¸å¯¹åå·®ï¼ˆå°†**å…¶ä½™æ‰€æœ‰æ ‡æ³¨è€…ï¼ˆReference Groupï¼‰**çš„å…±è¯†ä½œä¸ºåŸºå‡†ï¼‰ã€‚ LLMå¯¹é½åˆ†æï¼šè¯„ä¼°äº†è§’è‰²æ‰®æ¼”LLMåœ¨â€œå¤ç°æ ‡æ³¨åå·®â€ä»»åŠ¡ä¸Šçš„èƒ½åŠ› **[method]** Leveraging a large-scale dataset with rich demographic attributes, the methodology employs a comparative analysis using confusion matrices to measure relative labeling discrepancies between demographic groups, subsequently evaluating open-source LLMs via role-playing prompts to assess their alignment with human bias patterns. \[ç¿»è¯‘\]é€šè¿‡**æ··æ·†çŸ©é˜µ**ï¼ˆè¡Œä»£è¡¨ä¸å…·å¤‡è¯¥å±æ€§ï¼Œåˆ—ä»£è¡¨å…·å¤‡è¯¥å±æ€§ï¼‰å¯¹æ¯”ç‰¹å®šå±æ€§ç¾¤ä½“åœ¨è¯„ä»·ç‰¹å®šå±æ€§å—å®³è€…æ—¶çš„æ ‡ç­¾å·®å¼‚ã€‚è®¡ç®—åå·®å¼ºåº¦å’Œæ™®éæ€§\\nä½¿ç”¨**prompt**å¼•å¯¼LLMè¿›è¡Œç›¸åŒä»»åŠ¡ä»¥å¯¹æ¯” **[conclusion/contribution]** Quantitative analysis reveals that while human annotators exhibit significant &quot;in-group&quot; hypersensitivity and demographic-specific labeling variations, persona-based LLMs demonstrate a limited correlation with these human biases, failing to accurately mirror the complex social prejudices inherent in human data. \[ç¿»è¯‘\] äººç±»åå·®ï¼šå­˜åœ¨æ˜¾è‘—çš„â€œç»„å†…é«˜æ•åº¦â€ï¼ˆå³å€¾å‘äºé«˜ä¼°é’ˆå¯¹è‡ªèº«ç¾¤ä½“çš„ä»‡æ¨ï¼‰ï¼Œå—äººå£ç»Ÿè®¡å­¦äº¤äº’å½±å“ä¸¥é‡ï¼ˆå¦‚å¹´è½»äººå€¾å‘ä½ä¼°ä»‡æ¨ï¼Œè€å¹´äººå€¾å‘é«˜ä¼°ï¼‰ã€‚ LLMè¡¨ç°ï¼šMè¡¨ç°å‡ºè‡ªèº«åå·®ï¼Œä½†æœªèƒ½æœ‰æ•ˆå¤ç°äººç±»çš„ç‰¹å®šåå·®ï¼ˆç›¸å…³æ€§æä½ï¼‰ï¼Œ**æ¬ ç¼ºå¯¹é½èƒ½åŠ›**ï¼ˆé«˜ä¼°ä»£è¡¨æ›´æ•æ„Ÿï¼‰ **[limitation/future]** The study&#x27;s limitations include data scarcity for specific minority groups which constrains statistical significance, and a reliance solely on prompting strategies without fine-tuning, which may restrict the models&#x27; capacity for deep behavioral mimicry. \[ç¿»è¯‘\] è¯¥ç ”ç©¶çš„å±€é™æ€§åŒ…æ‹¬ç‰¹å®šå°‘æ•°ç¾¤ä½“çš„æ•°æ®ç¨€ç¼ºé™åˆ¶äº†ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œä»¥åŠä»…ä»…ä¾èµ–æç¤ºç­–ç•¥è€Œæ²¡æœ‰è¿›è¡Œå¾®è°ƒï¼Œè¿™å¯èƒ½é™åˆ¶äº†æ¨¡å‹çš„æ·±åº¦è¡Œä¸ºæ¨¡ä»¿èƒ½åŠ›ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** è¯¥é¢†åŸŸéœ€è¦å¤§é‡äººå·¥æ ‡æ³¨ï¼Œå­˜åœ¨å›ºæœ‰çš„ä¸»è§‚æ€§biasé—®é¢˜ï¼Œéœ€è¦ç³»ç»Ÿæ€§çš„ç ”ç©¶<br>**[innovation]** The authors introduce a novel methodological framework on the Measuring Hate Speech corpus that quantifies bias through "Intensity" and "Prevalence" metrics without relying on ground truth, uniquely isolating the interplay between specific annotator profiles and target groups.<br>\[ç¿»è¯‘\] æŒ‡æ ‡è®¾è®¡ï¼šæå‡ºäº†åå·®å¼ºåº¦ï¼ˆIntensity, ğ¼ï¼‰å’Œåå·®æ™®éæ€§ï¼ˆPrevalence, ğ‘ƒï¼‰ï¼Œæ— éœ€Ground Truthå³å¯è¡¡é‡ç›¸å¯¹åå·®ï¼ˆå°†**å…¶ä½™æ‰€æœ‰æ ‡æ³¨è€…ï¼ˆReference Groupï¼‰**çš„å…±è¯†ä½œä¸ºåŸºå‡†ï¼‰ã€‚<br>LLMå¯¹é½åˆ†æï¼šè¯„ä¼°äº†è§’è‰²æ‰®æ¼”LLMåœ¨â€œå¤ç°æ ‡æ³¨åå·®â€ä»»åŠ¡ä¸Šçš„èƒ½åŠ›<br>**[method]** Leveraging a large-scale dataset with rich demographic attributes, the methodology employs a comparative analysis using confusion matrices to measure relative labeling discrepancies between demographic groups, subsequently evaluating open-source LLMs via role-playing prompts to assess their alignment with human bias patterns.<br>\[ç¿»è¯‘\]é€šè¿‡**æ··æ·†çŸ©é˜µ**ï¼ˆè¡Œä»£è¡¨ä¸å…·å¤‡è¯¥å±æ€§ï¼Œåˆ—ä»£è¡¨å…·å¤‡è¯¥å±æ€§ï¼‰å¯¹æ¯”ç‰¹å®šå±æ€§ç¾¤ä½“åœ¨è¯„ä»·ç‰¹å®šå±æ€§å—å®³è€…æ—¶çš„æ ‡ç­¾å·®å¼‚ã€‚è®¡ç®—åå·®å¼ºåº¦å’Œæ™®éæ€§\\nä½¿ç”¨**prompt**å¼•å¯¼LLMè¿›è¡Œç›¸åŒä»»åŠ¡ä»¥å¯¹æ¯”<br>**[conclusion/contribution]** Quantitative analysis reveals that while human annotators exhibit significant "in-group" hypersensitivity and demographic-specific labeling variations, persona-based LLMs demonstrate a limited correlation with these human biases, failing to accurately mirror the complex social prejudices inherent in human data.<br>\[ç¿»è¯‘\] äººç±»åå·®ï¼šå­˜åœ¨æ˜¾è‘—çš„â€œç»„å†…é«˜æ•åº¦â€ï¼ˆå³å€¾å‘äºé«˜ä¼°é’ˆå¯¹è‡ªèº«ç¾¤ä½“çš„ä»‡æ¨ï¼‰ï¼Œå—äººå£ç»Ÿè®¡å­¦äº¤äº’å½±å“ä¸¥é‡ï¼ˆå¦‚å¹´è½»äººå€¾å‘ä½ä¼°ä»‡æ¨ï¼Œè€å¹´äººå€¾å‘é«˜ä¼°ï¼‰ã€‚<br>LLMè¡¨ç°ï¼šMè¡¨ç°å‡ºè‡ªèº«åå·®ï¼Œä½†æœªèƒ½æœ‰æ•ˆå¤ç°äººç±»çš„ç‰¹å®šåå·®ï¼ˆç›¸å…³æ€§æä½ï¼‰ï¼Œ**æ¬ ç¼ºå¯¹é½èƒ½åŠ›**ï¼ˆé«˜ä¼°ä»£è¡¨æ›´æ•æ„Ÿï¼‰<br>**[limitation/future]** The study's limitations include data scarcity for specific minority groups which constrains statistical significance, and a reliance solely on prompting strategies without fine-tuning, which may restrict the models' capacity for deep behavioral mimicry.<br>\[ç¿»è¯‘\] è¯¥ç ”ç©¶çš„å±€é™æ€§åŒ…æ‹¬ç‰¹å®šå°‘æ•°ç¾¤ä½“çš„æ•°æ®ç¨€ç¼ºé™åˆ¶äº†ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œä»¥åŠä»…ä»…ä¾èµ–æç¤ºç­–ç•¥è€Œæ²¡æœ‰è¿›è¡Œå¾®è°ƒï¼Œè¿™å¯èƒ½é™åˆ¶äº†æ¨¡å‹çš„æ·±åº¦è¡Œä¸ºæ¨¡ä»¿èƒ½åŠ›ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[å¼•ç”¨å¥\]Serving as a foundational critique within the transition from static classification to dynamic social simulation, Giorgi et al. \(2025\) demonstrate that although human perception of hate speech is fundamentally shaped by the interplay between annotator and target demographics, current persona-based LLMs fail to faithfully emulate these emergent sociological biases, highlighting a critical gap in the development of realistic AI agents.<br>\[ç¿»è¯‘\] ä½œä¸ºä»é™æ€åˆ†ç±»å‘åŠ¨æ€ç¤¾ä¼šä»¿çœŸè¿‡æ¸¡è¿‡ç¨‹ä¸­çš„ä¸€é¡¹åŸºç¡€æ€§æ‰¹åˆ¤ç ”ç©¶ï¼ŒGiorgiç­‰äººï¼ˆ2025ï¼‰è¯æ˜ï¼Œå°½ç®¡äººç±»å¯¹ä»‡æ¨è¨€è®ºçš„æ„ŸçŸ¥ä»æ ¹æœ¬ä¸Šå—æ ‡æ³¨è€…ä¸ç›®æ ‡äººå£ç»Ÿè®¡ç‰¹å¾äº¤äº’ä½œç”¨çš„å½±å“ï¼Œä½†å½“å‰çš„åŸºäºè§’è‰²çš„LLMæ— æ³•å¿ å®åœ°æ¨¡æ‹Ÿè¿™äº›æ¶Œç°çš„ç¤¾ä¼šå­¦åå·®ï¼Œçªæ˜¾äº†æ„å»ºé€¼çœŸAIæ™ºèƒ½ä½“æ–¹é¢çš„ä¸€ä¸ªå…³é”®å·®è·ã€‚</div></details></div></div>|

### Misinformation Analysis (6 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence-blue)]()<br>[GAMC: An Unsupervised Method for Fake News Detection Using Graph Autoencoder with Masking](https://ojs.aaai.org/index.php/AAAI/article/view/27788) <br> Shu Yin,Peican Zhu,Lianwei Wu,Chao Gao,Zhen Wang <br> 2024-03-24|è‡ªç¼–ç å™¨æ–¹æ³•å¤„ç†ç±»ç¤¾äº¤ç½‘ç»œå›¾ç»“æ„|<img width="1200" alt="pipeline" src="figures/GAMC.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** ç°æœ‰æ–¹æ³•å¤šä¾èµ–æ–°é—»å†…å®¹æˆ–éœ€å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨ä¼ æ’­ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ **[innovation]** é¦–ä¸ªç»“åˆå›¾è‡ªç¼–ç å™¨ã€æ©ç ä¸å¯¹æ¯”å­¦ä¹ çš„æ— ç›‘ç£å‡æ–°é—»æ£€æµ‹æ–¹æ³•ï¼ŒåŒæ—¶åˆ©ç”¨ä¼ æ’­ç»“æ„ä¸å†…å®¹ä¿¡æ¯ï¼Œæ— éœ€æ ‡æ³¨æ•°æ® **[method]** 1. å°†æ–°é—»ä¼ æ’­å»ºæ¨¡ä¸ºå›¾ï¼ˆæ–°é—»èŠ‚ç‚¹å’Œç”¨æˆ·èŠ‚ç‚¹ï¼Œè¾¹è¡¨ç¤ºè½¬å‘å…³ç³»ï¼ŒèŠ‚ç‚¹ç‰¹å¾æ¥è‡ªæ–°é—»å†…å®¹å’Œç”¨æˆ·å†å²è´´æ–‡ï¼‰ï¼› 2. æ•°æ®å¢å¼ºï¼ˆèŠ‚ç‚¹ç‰¹å¾æ©ç +è¾¹ä¸¢å¼ƒï¼‰ï¼ˆéšæœºé€‰å–èŠ‚ç‚¹å°†å…¶ç‰¹å¾æ›¿æ¢ä¸ºæ©ç æ ‡è®°ï¼Œéšæœºåˆ é™¤éƒ¨åˆ†è¾¹ï¼‰æ„é€ è‡ªç›‘ç£ç‰¹æ€§ï¼› 3. å›¾ç¼–ç å™¨ï¼ˆGINï¼‰ç”Ÿæˆæ½œåœ¨è¡¨ç¤ºï¼› 4. å›¾è§£ç å™¨é‡å»ºç‰¹å¾ï¼› 5. æŸå¤±å‡½æ•°ç»„æˆï¼ˆ**é‡å»ºæŸå¤±**ï¼ˆä½¿é‡å»ºç‰¹å¾æ¥è¿‘åŸå§‹ç‰¹å¾ï¼‰+**å¯¹æ¯”æŸå¤±**ï¼ˆæ¥è‡ªåŒä¸€ä¸ªåŸå§‹å›¾çš„ä¸¤ä¸ªå¢å¼ºå›¾é‡å»ºååº”å°½é‡ç›¸ä¼¼ï¼‰ï¼‰è®­ç»ƒã€‚ **[conclusion/contribution]** åœ¨ FakeNewsNet æ•°æ®é›†ä¸Šï¼ŒGAMC åœ¨æ— ç›‘ç£æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ï¼ˆå¦‚ GossipCop å‡†ç¡®ç‡ 0.946ï¼‰ï¼Œç”šè‡³æ¥è¿‘æˆ–è¶…è¶Šéƒ¨åˆ†ç›‘ç£æ–¹æ³• **[limitation/future]** éœ€è¦æ–°é—»å…·æœ‰ä¸€å®šçš„ä¼ æ’­é‡æ‰èƒ½å»ºæ¨¡ä¸ºå›¾ï¼›æ—©æœŸä¼ æ’­é˜¶æ®µæ£€æµ‹èƒ½åŠ›å—é™">**[summary]**</summary><div style="margin-top:6px">**[motivation]** ç°æœ‰æ–¹æ³•å¤šä¾èµ–æ–°é—»å†…å®¹æˆ–éœ€å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨ä¼ æ’­ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚<br>**[innovation]** é¦–ä¸ªç»“åˆå›¾è‡ªç¼–ç å™¨ã€æ©ç ä¸å¯¹æ¯”å­¦ä¹ çš„æ— ç›‘ç£å‡æ–°é—»æ£€æµ‹æ–¹æ³•ï¼ŒåŒæ—¶åˆ©ç”¨ä¼ æ’­ç»“æ„ä¸å†…å®¹ä¿¡æ¯ï¼Œæ— éœ€æ ‡æ³¨æ•°æ®<br>**[method]** 1. å°†æ–°é—»ä¼ æ’­å»ºæ¨¡ä¸ºå›¾ï¼ˆæ–°é—»èŠ‚ç‚¹å’Œç”¨æˆ·èŠ‚ç‚¹ï¼Œè¾¹è¡¨ç¤ºè½¬å‘å…³ç³»ï¼ŒèŠ‚ç‚¹ç‰¹å¾æ¥è‡ªæ–°é—»å†…å®¹å’Œç”¨æˆ·å†å²è´´æ–‡ï¼‰ï¼›<br>2. æ•°æ®å¢å¼ºï¼ˆèŠ‚ç‚¹ç‰¹å¾æ©ç +è¾¹ä¸¢å¼ƒï¼‰ï¼ˆéšæœºé€‰å–èŠ‚ç‚¹å°†å…¶ç‰¹å¾æ›¿æ¢ä¸ºæ©ç æ ‡è®°ï¼Œéšæœºåˆ é™¤éƒ¨åˆ†è¾¹ï¼‰æ„é€ è‡ªç›‘ç£ç‰¹æ€§ï¼›<br>3. å›¾ç¼–ç å™¨ï¼ˆGINï¼‰ç”Ÿæˆæ½œåœ¨è¡¨ç¤ºï¼›<br>4. å›¾è§£ç å™¨é‡å»ºç‰¹å¾ï¼›<br>5. æŸå¤±å‡½æ•°ç»„æˆï¼ˆ**é‡å»ºæŸå¤±**ï¼ˆä½¿é‡å»ºç‰¹å¾æ¥è¿‘åŸå§‹ç‰¹å¾ï¼‰+**å¯¹æ¯”æŸå¤±**ï¼ˆæ¥è‡ªåŒä¸€ä¸ªåŸå§‹å›¾çš„ä¸¤ä¸ªå¢å¼ºå›¾é‡å»ºååº”å°½é‡ç›¸ä¼¼ï¼‰ï¼‰è®­ç»ƒã€‚<br>**[conclusion/contribution]** åœ¨ FakeNewsNet æ•°æ®é›†ä¸Šï¼ŒGAMC åœ¨æ— ç›‘ç£æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ï¼ˆå¦‚ GossipCop å‡†ç¡®ç‡ 0.946ï¼‰ï¼Œç”šè‡³æ¥è¿‘æˆ–è¶…è¶Šéƒ¨åˆ†ç›‘ç£æ–¹æ³•<br>**[limitation/future]** éœ€è¦æ–°é—»å…·æœ‰ä¸€å®šçš„ä¼ æ’­é‡æ‰èƒ½å»ºæ¨¡ä¸ºå›¾ï¼›æ—©æœŸä¼ æ’­é˜¶æ®µæ£€æµ‹èƒ½åŠ›å—é™</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-Companion%20Proceedings%20of%20the%20Web%20Conference%202021-blue)]()<br>[How does truth evolve into fake news? An empirical study of fake news evolution](https://dl.acm.org/doi/10.1145/3442442.3452328) <br> Mingfei Guoï¼ŒXiuying Chenï¼ŒJuntao Liï¼ŒDongyan Zhaoï¼ŒRui Yan <br> 2021-06-03|ä¸€ä¸ªåŒ…å«\[åŸå§‹æ–°é—»ã€å‡æ–°é—»ã€æ¼”åŒ–åçš„å‡æ–°é—»\]ä¸‰å…ƒç»„çš„æ•°æ®é›†|<img width="1200" alt="pipeline" src="figures/FNE.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** è€Œç°æœ‰æ•°æ®é›†å¤šå…³æ³¨é™æ€æ ‡æ³¨ï¼Œç¼ºä¹å¯¹å…¶å‡æ–°é—»æ¼”åŒ–è¿‡ç¨‹çš„ç ”ç©¶ **[innovation]** ç»™å‡ºäº†å…³æ³¨å‡æ–°é—»æ¼”åŒ–çš„æ•°æ®é›†FNEï¼ŒåŒ…å«â€œçœŸç›¸-è™šå‡æ–°é—»-æ¼”åŒ–è™šå‡æ–°é—»â€ä¸‰å…ƒç»„ **[method]** 1. ä» Snopes.com\(ä¸€ä¸ªè¾Ÿè°£ç½‘ç«™\) æŠ“å–truthæ–‡ç« ï¼› 2. é€šè¿‡å…¶å¼•æ–‡æ”¶é›†è™šå‡æ–°é—»ï¼› 3. åˆ©ç”¨ç½‘é¡µå­˜æ¡£å¹³å°ï¼ˆå¦‚ Archive Todayï¼‰è·å–æ¼”åŒ–åç‰ˆæœ¬ï¼› 4. åˆ†æè™šå‡ä¿¡æ¯æŠ€æœ¯åˆ†ç±»ï¼ˆæé€ ã€å¦è®¤ã€æ··æ·†ã€æ­ªæ›²å››ç±»ã€æ–‡æœ¬ç›¸ä¼¼åº¦ã€å…³é”®è¯ã€è¯æ€§ã€æƒ…æ„Ÿç­‰å±æ€§ã€‚ **[conclusion/contribution]** æ¼”åŒ–åè™šå‡æ–°é—»ä¸åŸå§‹è™šå‡æ–°é—»ç›¸ä¼¼åº¦æ›´é«˜ï¼Œæƒ…æ„Ÿæ›´å®¢è§‚ç§¯æï¼Œæ›´éš¾ä»¥è¢«ç°æœ‰åˆ†ç±»æ¨¡å‹æ£€æµ‹ï¼›è™šå‡ä¿¡æ¯æŠ€æœ¯ä¸­ä»¥â€œæé€ â€ä¸ºä¸»ï¼›è¯æ€§å’Œå…³é”®è¯åœ¨æ¼”åŒ–ä¸­ä¿æŒç¨³å®šã€‚ **[limitation/future]** æ•°æ®æ¥æºä¾èµ–å•ä¸€äº‹å®æ ¸æŸ¥ç½‘ç«™ï¼ˆSnopesï¼‰ï¼Œå¯èƒ½å¼•å…¥åè§ï¼›ä»…å…³æ³¨æ–‡æœ¬æ–°é—»ï¼Œæœªæ¶µç›–å›¾åƒã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ¼”å˜ï¼›">**[summary]**</summary><div style="margin-top:6px">**[motivation]** è€Œç°æœ‰æ•°æ®é›†å¤šå…³æ³¨é™æ€æ ‡æ³¨ï¼Œç¼ºä¹å¯¹å…¶å‡æ–°é—»æ¼”åŒ–è¿‡ç¨‹çš„ç ”ç©¶<br>**[innovation]** ç»™å‡ºäº†å…³æ³¨å‡æ–°é—»æ¼”åŒ–çš„æ•°æ®é›†FNEï¼ŒåŒ…å«â€œçœŸç›¸-è™šå‡æ–°é—»-æ¼”åŒ–è™šå‡æ–°é—»â€ä¸‰å…ƒç»„<br>**[method]** 1. ä» Snopes.com\(ä¸€ä¸ªè¾Ÿè°£ç½‘ç«™\) æŠ“å–truthæ–‡ç« ï¼›<br>2. é€šè¿‡å…¶å¼•æ–‡æ”¶é›†è™šå‡æ–°é—»ï¼›<br>3. åˆ©ç”¨ç½‘é¡µå­˜æ¡£å¹³å°ï¼ˆå¦‚ Archive Todayï¼‰è·å–æ¼”åŒ–åç‰ˆæœ¬ï¼›<br>4. åˆ†æè™šå‡ä¿¡æ¯æŠ€æœ¯åˆ†ç±»ï¼ˆæé€ ã€å¦è®¤ã€æ··æ·†ã€æ­ªæ›²å››ç±»ã€æ–‡æœ¬ç›¸ä¼¼åº¦ã€å…³é”®è¯ã€è¯æ€§ã€æƒ…æ„Ÿç­‰å±æ€§ã€‚<br>**[conclusion/contribution]** æ¼”åŒ–åè™šå‡æ–°é—»ä¸åŸå§‹è™šå‡æ–°é—»ç›¸ä¼¼åº¦æ›´é«˜ï¼Œæƒ…æ„Ÿæ›´å®¢è§‚ç§¯æï¼Œæ›´éš¾ä»¥è¢«ç°æœ‰åˆ†ç±»æ¨¡å‹æ£€æµ‹ï¼›è™šå‡ä¿¡æ¯æŠ€æœ¯ä¸­ä»¥â€œæé€ â€ä¸ºä¸»ï¼›è¯æ€§å’Œå…³é”®è¯åœ¨æ¼”åŒ–ä¸­ä¿æŒç¨³å®šã€‚<br>**[limitation/future]** æ•°æ®æ¥æºä¾èµ–å•ä¸€äº‹å®æ ¸æŸ¥ç½‘ç«™ï¼ˆSnopesï¼‰ï¼Œå¯èƒ½å¼•å…¥åè§ï¼›ä»…å…³æ³¨æ–‡æœ¬æ–°é—»ï¼Œæœªæ¶µç›–å›¾åƒã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ¼”å˜ï¼›</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence-blue)]()<br>[Learning Complex Heterogeneous Multimodal Fake News via Social Latent Network Inference](https://ojs.aaai.org/index.php/AAAI/article/view/32022) <br> Mingxin Li,Yuchen Zhang,Haowei Xu,Xianghua Li\*,Chao Gao,Zhen Wang <br> 2025-04-11|é€šè¿‡ç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­ä¸è‡ªç›‘ç£å¤šæ¨¡æ€å­¦ä¹ æ£€æµ‹å¤æ‚å¼‚è´¨å¤šæ¨¡æ€å‡æ–°é—»çš„GNNæ–¹æ³•|<img width="1200" alt="pipeline" src="figures/HML.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** ç¤¾äº¤å¹³å°å¤šå…ƒåŒ–å¯¼è‡´æ–°é—»ä¼ æ’­å¤æ‚ã€å¤šæ¨¡æ€ï¼Œä¼ ç»Ÿå‡æ–°é—»æ£€æµ‹æ–¹æ³•ä¾èµ–æ˜¾å¼ä¼ æ’­å…³ç³»ï¼ˆå¦‚è½¬å‘ï¼‰ï¼Œåœ¨æŠ–éŸ³ç­‰å¹³å°éš¾ä»¥ç›´æ¥è·å–ï¼Œæ£€æµ‹éš¾åº¦å¤§ã€‚ **[innovation]** æå‡ºâ€œç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­Latent Network Inferenceâ€ç­–ç•¥ï¼Œæ— éœ€çœŸå®ä¼ æ’­å…³ç³»ï¼Œå³å¯æ„å»ºæ–°é—»é—´çš„æ½œåœ¨è”ç³» **[method]** 1. ç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­ï¼šåŸºäºHawkes Processå»ºæ¨¡æ–°é—»å½±å“åŠ›éšæ—¶é—´å˜åŒ–ï¼Œå¾—åˆ°äº‹ä»¶å†…éƒ¨ä¸äº‹ä»¶é—´çš„å½±å“å¼ºåº¦ï¼Œæ¨æ–­å‡ºæ½œåœ¨ä¼ æ’­ç½‘ç»œã€‚ 2. å¼‚è´¨å›¾æ„å»ºï¼šèŠ‚ç‚¹å‡ä¸ºæ–°é—»ï¼Œè¾¹ç±»å‹åŸºäºå„ç§ç›¸åŒæˆ–ç›¸ä¼¼å±æ€§ï¼ˆå¦‚ä½œè€…ã€æ ‡é¢˜ã€æ—¶é—´ç­‰ï¼‰æ„å»ºã€‚ä½¿ç”¨**æ³¨æ„åŠ›æœºåˆ¶**åŠ¨æ€èåˆä¸åŒè¾¹ç±»å‹ï¼Œç”Ÿæˆç»Ÿä¸€çš„å¼‚è´¨å›¾è¡¨ç¤ºï¼ˆæ¯ä¸ªç±»å‹çš„è¾¹çœ‹åšä¸€ä¸ªâ€œå¤´â€ï¼Œåˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›æ–¹æ³•ï¼‰ 3. è‡ªç›‘ç£å¤šæ¨¡æ€å†…å®¹å­¦ä¹ ï¼šæŸå¤±å‡½æ•°ï¼šå•æ¨¡æ€å¢å¼ºï¼ˆå¯¹åŒä¸€æ¨¡æ€è¿›è¡Œæ©ç ä¸é‡æ„ï¼‰ã€è·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ ï¼ˆå¯¹é½ä¸åŒæ¨¡æ€ï¼ˆå¦‚æ–‡æœ¬ä¸è§†é¢‘ï¼‰çš„ç‰¹å¾ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ æ‹‰è¿‘æ­£æ ·æœ¬ã€æ¨å¼€è´Ÿæ ·æœ¬ï¼‰ 4. ä¸ªæ€§åŒ–å›¾è¡¨ç¤ºä¸åˆ†ç±»ï¼šä½¿ç”¨å›¾Transformer Encoderèåˆå›¾ç»“æ„ä¸æ¨¡æ€ç‰¹å¾ï¼Œè¿›è¡Œåˆ†ç±»ã€‚ **[conclusion/contribution]** FakeSVå’ŒFVCæ•°æ®é›†ä¸Šå‡†ç¡®ç‡å‡è¶…89%ï¼Œè¾ƒSOTAæå‡0.12%~4.39%ï¼›åœ¨Twitter/å¾®åšä½œä¸ºæ’ä»¶ä¹Ÿæå‡æ˜æ˜¾ï¼ˆæœ€é«˜+10.71% F1ï¼‰ **[limitation/future]** ä¾èµ–äº‹ä»¶å®šä¹‰ä¸æ—¶é—´åºåˆ—å‡è®¾ï¼Œå¯¹å®æ—¶æ€§è¦æ±‚é«˜ï¼›è®¡ç®—å¤æ‚åº¦è¾ƒé«˜">**[summary]**</summary><div style="margin-top:6px">**[motivation]** ç¤¾äº¤å¹³å°å¤šå…ƒåŒ–å¯¼è‡´æ–°é—»ä¼ æ’­å¤æ‚ã€å¤šæ¨¡æ€ï¼Œä¼ ç»Ÿå‡æ–°é—»æ£€æµ‹æ–¹æ³•ä¾èµ–æ˜¾å¼ä¼ æ’­å…³ç³»ï¼ˆå¦‚è½¬å‘ï¼‰ï¼Œåœ¨æŠ–éŸ³ç­‰å¹³å°éš¾ä»¥ç›´æ¥è·å–ï¼Œæ£€æµ‹éš¾åº¦å¤§ã€‚<br>**[innovation]** æå‡ºâ€œç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­Latent Network Inferenceâ€ç­–ç•¥ï¼Œæ— éœ€çœŸå®ä¼ æ’­å…³ç³»ï¼Œå³å¯æ„å»ºæ–°é—»é—´çš„æ½œåœ¨è”ç³»<br>**[method]** 1. ç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­ï¼šåŸºäºHawkes Processå»ºæ¨¡æ–°é—»å½±å“åŠ›éšæ—¶é—´å˜åŒ–ï¼Œå¾—åˆ°äº‹ä»¶å†…éƒ¨ä¸äº‹ä»¶é—´çš„å½±å“å¼ºåº¦ï¼Œæ¨æ–­å‡ºæ½œåœ¨ä¼ æ’­ç½‘ç»œã€‚<br>2. å¼‚è´¨å›¾æ„å»ºï¼šèŠ‚ç‚¹å‡ä¸ºæ–°é—»ï¼Œè¾¹ç±»å‹åŸºäºå„ç§ç›¸åŒæˆ–ç›¸ä¼¼å±æ€§ï¼ˆå¦‚ä½œè€…ã€æ ‡é¢˜ã€æ—¶é—´ç­‰ï¼‰æ„å»ºã€‚ä½¿ç”¨**æ³¨æ„åŠ›æœºåˆ¶**åŠ¨æ€èåˆä¸åŒè¾¹ç±»å‹ï¼Œç”Ÿæˆç»Ÿä¸€çš„å¼‚è´¨å›¾è¡¨ç¤ºï¼ˆæ¯ä¸ªç±»å‹çš„è¾¹çœ‹åšä¸€ä¸ªâ€œå¤´â€ï¼Œåˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›æ–¹æ³•ï¼‰<br>3. è‡ªç›‘ç£å¤šæ¨¡æ€å†…å®¹å­¦ä¹ ï¼šæŸå¤±å‡½æ•°ï¼šå•æ¨¡æ€å¢å¼ºï¼ˆå¯¹åŒä¸€æ¨¡æ€è¿›è¡Œæ©ç ä¸é‡æ„ï¼‰ã€è·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ ï¼ˆå¯¹é½ä¸åŒæ¨¡æ€ï¼ˆå¦‚æ–‡æœ¬ä¸è§†é¢‘ï¼‰çš„ç‰¹å¾ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ æ‹‰è¿‘æ­£æ ·æœ¬ã€æ¨å¼€è´Ÿæ ·æœ¬ï¼‰<br>4. ä¸ªæ€§åŒ–å›¾è¡¨ç¤ºä¸åˆ†ç±»ï¼šä½¿ç”¨å›¾Transformer Encoderèåˆå›¾ç»“æ„ä¸æ¨¡æ€ç‰¹å¾ï¼Œè¿›è¡Œåˆ†ç±»ã€‚<br>**[conclusion/contribution]** FakeSVå’ŒFVCæ•°æ®é›†ä¸Šå‡†ç¡®ç‡å‡è¶…89%ï¼Œè¾ƒSOTAæå‡0.12%~4.39%ï¼›åœ¨Twitter/å¾®åšä½œä¸ºæ’ä»¶ä¹Ÿæå‡æ˜æ˜¾ï¼ˆæœ€é«˜+10.71% F1ï¼‰<br>**[limitation/future]** ä¾èµ–äº‹ä»¶å®šä¹‰ä¸æ—¶é—´åºåˆ—å‡è®¾ï¼Œå¯¹å®æ—¶æ€§è¦æ±‚é«˜ï¼›è®¡ç®—å¤æ‚åº¦è¾ƒé«˜</div></details></div>|
|[![Star](https://img.shields.io/github/stars/xxfwin/NAGASIL.svg?style=social&label=Star)](https://github.com/xxfwin/NAGASIL) [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[Harnessing Network Effect for Fake News Mitigation: Selecting Debunkers via Self-Imitation Learning](https://ojs.aaai.org/index.php/AAAI/article/view/30252) <br> Xiaofei Xu, Ke Deng, Michael Dann, Xiuzhen Zhang <br> 2024-03-24|ä¸€ä¸ªè¾Ÿè°£è€…é€‰æ‹©ç­–ç•¥ï¼ˆMDPé£æ ¼ï¼‰çš„ç”Ÿæˆå™¨|<img width="1200" alt="pipeline" src="figures/NAGASIL.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Current approaches to multi-stage fake news mitigation often fail to address the episodic reward problem, where the effect of selecting an individual debunker cannot be measured until the campaign concludes. This sparse and delayed feedback limits the applicability of standard Reinforcement Learning \(RL\) in real-world social networks. \[ç¿»è¯‘\] ç°æœ‰çš„å¤šé˜¶æ®µå‡æ–°é—»æ²»ç†æ–¹æ³•å¾€å¾€æœªèƒ½è§£å†³ç‰‡æ®µå¼å¥–åŠ±é—®é¢˜ï¼Œå³é€‰æ‹©å•ä¸ªè¾Ÿè°£è€…çš„æ•ˆæœåªæœ‰åœ¨æ´»åŠ¨ç»“æŸæ—¶æ‰èƒ½è¡¡é‡ã€‚è¿™ç§ç¨€ç–ä¸”å»¶è¿Ÿçš„åé¦ˆé™åˆ¶äº†æ ‡å‡†å¼ºåŒ–å­¦ä¹ åœ¨ç°å®ç¤¾äº¤ç½‘ç»œä¸­çš„é€‚ç”¨æ€§ã€‚ **[innovation]** The authors propose NAGASIL, introducing two key enhancements to Self-Imitation Learning: 1\) Negative Sampling, which leverages low-reward historical episodes to explicitly penalize poor debunker selections, and 2\) State Augmentation, which enriches the observed state by integrating historical state-action sequences from the same campaign to address partial observability. \[ç¿»è¯‘\] ä½œè€…æå‡ºäº†NAGASILï¼Œä¸ºè‡ªæ¨¡ä»¿å­¦ä¹ å¼•å…¥äº†ä¸¤ä¸ªå…³é”®å¢å¼ºï¼š1\) è´Ÿé‡‡æ ·ï¼Œåˆ©ç”¨å†å²ä½å¥–åŠ±ç‰‡æ®µæ˜¾å¼æƒ©ç½šä¸è‰¯çš„è¾Ÿè°£è€…é€‰æ‹©ï¼›2\) çŠ¶æ€å¢å¼ºï¼Œé€šè¿‡èåˆåŒä¸€æ´»åŠ¨ä¸­çš„å†å²çŠ¶æ€-åŠ¨ä½œåºåˆ—æ¥ä¸°å¯Œè§‚æµ‹çŠ¶æ€ï¼Œä»¥åº”å¯¹éƒ¨åˆ†å¯è§‚æµ‹æ€§é—®é¢˜ã€‚ **[method]** The debunker selection is formulated as a sequential decision-making problem under a budget constraint. A generative adversarial framework is employed, where a generator selects debunkers and a discriminator distinguishes between state-action pairs from high-reward historical episodes and those generated by the current policy. The generator is trained by integrating signals from the discriminator, an entropy regularizer for exploration, and a novel regularizer derived from a negative sampling model trained on low-reward episodes. This process yields an optimal generator capable of outputting an effective debunker selection policy. \[ç¿»è¯‘\] è¾Ÿè°£è€…é€‰æ‹©è¢«å»ºæ¨¡ä¸ºé¢„ç®—çº¦æŸä¸‹çš„åºåˆ—å†³ç­–é—®é¢˜ã€‚é‡‡ç”¨ç”Ÿæˆå¯¹æŠ—æ¡†æ¶ï¼Œå…¶ä¸­ç”Ÿæˆå™¨é€‰æ‹©è¾Ÿè°£è€…ï¼Œåˆ¤åˆ«å™¨åŒºåˆ†æ¥è‡ªé«˜å¥–åŠ±å†å²ç‰‡æ®µçš„çŠ¶æ€-åŠ¨ä½œå¯¹ä¸å½“å‰ç­–ç•¥ç”Ÿæˆçš„å¯¹ã€‚ç”Ÿæˆå™¨çš„è®­ç»ƒæ•´åˆäº†æ¥è‡ªåˆ¤åˆ«å™¨çš„ä¿¡å·ã€ç”¨äºæ¢ç´¢çš„ç†µæ­£åˆ™é¡¹ï¼Œä»¥åŠä¸€ä¸ªä»ä½å¥–åŠ±ç‰‡æ®µè®­ç»ƒå¾—åˆ°çš„è´Ÿé‡‡æ ·æ¨¡å‹æ‰€è¡ç”Ÿçš„æ–°æ­£åˆ™é¡¹ã€‚è¯¥è¿‡ç¨‹æœ€ç»ˆäº§ç”Ÿä¸€ä¸ªèƒ½è¾“å‡ºæœ‰æ•ˆè¾Ÿè°£è€…é€‰æ‹©ç­–ç•¥çš„æœ€ä¼˜ç”Ÿæˆå™¨ã€‚ **[conclusion/contribution]** Experiments conducted on both real-world \(Facebook\) and synthetic \(Twitter\) networks demonstrate that NAGASIL outperforms state-of-the-art fake news mitigation baselines and standard self-imitation learning methods across various budgets, stage lengths, and network densities. \[ç¿»è¯‘\] åœ¨çœŸå®ä¸–ç•Œï¼ˆFacebookï¼‰å’Œåˆæˆï¼ˆTwitterï¼‰ç½‘ç»œä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒNAGASILåœ¨å„ç§é¢„ç®—ã€é˜¶æ®µé•¿åº¦å’Œç½‘ç»œå¯†åº¦è®¾ç½®ä¸‹ï¼Œå‡ä¼˜äºå…ˆè¿›çš„å‡æ–°é—»æ²»ç†åŸºçº¿æ–¹æ³•å’Œæ ‡å‡†è‡ªæ¨¡ä»¿å­¦ä¹ æ–¹æ³•ã€‚ **[limitation/future]** The proposed method operates under the assumption that the veracity of news is pre-determined, necessitating integration with an external fake news detection system. Future research could explore adaptive propagation models and the dynamic nature of user behavior. \[ç¿»è¯‘\] æ‰€ææ–¹æ³•åŸºäºæ–°é—»çœŸä¼ªå·²çŸ¥çš„å‡è®¾è¿è¡Œï¼Œå› æ­¤éœ€è¦ä¸å¤–éƒ¨å‡æ–°é—»æ£€æµ‹ç³»ç»Ÿç»“åˆã€‚æœªæ¥ç ”ç©¶å¯æ¢ç´¢è‡ªé€‚åº”çš„ä¼ æ’­æ¨¡å‹å’Œç”¨æˆ·è¡Œä¸ºçš„åŠ¨æ€ç‰¹æ€§ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Current approaches to multi-stage fake news mitigation often fail to address the episodic reward problem, where the effect of selecting an individual debunker cannot be measured until the campaign concludes. This sparse and delayed feedback limits the applicability of standard Reinforcement Learning \(RL\) in real-world social networks.<br>\[ç¿»è¯‘\]<br>ç°æœ‰çš„å¤šé˜¶æ®µå‡æ–°é—»æ²»ç†æ–¹æ³•å¾€å¾€æœªèƒ½è§£å†³ç‰‡æ®µå¼å¥–åŠ±é—®é¢˜ï¼Œå³é€‰æ‹©å•ä¸ªè¾Ÿè°£è€…çš„æ•ˆæœåªæœ‰åœ¨æ´»åŠ¨ç»“æŸæ—¶æ‰èƒ½è¡¡é‡ã€‚è¿™ç§ç¨€ç–ä¸”å»¶è¿Ÿçš„åé¦ˆé™åˆ¶äº†æ ‡å‡†å¼ºåŒ–å­¦ä¹ åœ¨ç°å®ç¤¾äº¤ç½‘ç»œä¸­çš„é€‚ç”¨æ€§ã€‚<br>**[innovation]** The authors propose NAGASIL, introducing two key enhancements to Self-Imitation Learning: 1\) Negative Sampling, which leverages low-reward historical episodes to explicitly penalize poor debunker selections, and 2\) State Augmentation, which enriches the observed state by integrating historical state-action sequences from the same campaign to address partial observability.<br>\[ç¿»è¯‘\]<br>ä½œè€…æå‡ºäº†NAGASILï¼Œä¸ºè‡ªæ¨¡ä»¿å­¦ä¹ å¼•å…¥äº†ä¸¤ä¸ªå…³é”®å¢å¼ºï¼š1\) è´Ÿé‡‡æ ·ï¼Œåˆ©ç”¨å†å²ä½å¥–åŠ±ç‰‡æ®µæ˜¾å¼æƒ©ç½šä¸è‰¯çš„è¾Ÿè°£è€…é€‰æ‹©ï¼›2\) çŠ¶æ€å¢å¼ºï¼Œé€šè¿‡èåˆåŒä¸€æ´»åŠ¨ä¸­çš„å†å²çŠ¶æ€-åŠ¨ä½œåºåˆ—æ¥ä¸°å¯Œè§‚æµ‹çŠ¶æ€ï¼Œä»¥åº”å¯¹éƒ¨åˆ†å¯è§‚æµ‹æ€§é—®é¢˜ã€‚<br>**[method]** The debunker selection is formulated as a sequential decision-making problem under a budget constraint. A generative adversarial framework is employed, where a generator selects debunkers and a discriminator distinguishes between state-action pairs from high-reward historical episodes and those generated by the current policy. The generator is trained by integrating signals from the discriminator, an entropy regularizer for exploration, and a novel regularizer derived from a negative sampling model trained on low-reward episodes. This process yields an optimal generator capable of outputting an effective debunker selection policy.<br>\[ç¿»è¯‘\]<br>è¾Ÿè°£è€…é€‰æ‹©è¢«å»ºæ¨¡ä¸ºé¢„ç®—çº¦æŸä¸‹çš„åºåˆ—å†³ç­–é—®é¢˜ã€‚é‡‡ç”¨ç”Ÿæˆå¯¹æŠ—æ¡†æ¶ï¼Œå…¶ä¸­ç”Ÿæˆå™¨é€‰æ‹©è¾Ÿè°£è€…ï¼Œåˆ¤åˆ«å™¨åŒºåˆ†æ¥è‡ªé«˜å¥–åŠ±å†å²ç‰‡æ®µçš„çŠ¶æ€-åŠ¨ä½œå¯¹ä¸å½“å‰ç­–ç•¥ç”Ÿæˆçš„å¯¹ã€‚ç”Ÿæˆå™¨çš„è®­ç»ƒæ•´åˆäº†æ¥è‡ªåˆ¤åˆ«å™¨çš„ä¿¡å·ã€ç”¨äºæ¢ç´¢çš„ç†µæ­£åˆ™é¡¹ï¼Œä»¥åŠä¸€ä¸ªä»ä½å¥–åŠ±ç‰‡æ®µè®­ç»ƒå¾—åˆ°çš„è´Ÿé‡‡æ ·æ¨¡å‹æ‰€è¡ç”Ÿçš„æ–°æ­£åˆ™é¡¹ã€‚è¯¥è¿‡ç¨‹æœ€ç»ˆäº§ç”Ÿä¸€ä¸ªèƒ½è¾“å‡ºæœ‰æ•ˆè¾Ÿè°£è€…é€‰æ‹©ç­–ç•¥çš„æœ€ä¼˜ç”Ÿæˆå™¨ã€‚<br>**[conclusion/contribution]** Experiments conducted on both real-world \(Facebook\) and synthetic \(Twitter\) networks demonstrate that NAGASIL outperforms state-of-the-art fake news mitigation baselines and standard self-imitation learning methods across various budgets, stage lengths, and network densities.<br>\[ç¿»è¯‘\]<br>åœ¨çœŸå®ä¸–ç•Œï¼ˆFacebookï¼‰å’Œåˆæˆï¼ˆTwitterï¼‰ç½‘ç»œä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒNAGASILåœ¨å„ç§é¢„ç®—ã€é˜¶æ®µé•¿åº¦å’Œç½‘ç»œå¯†åº¦è®¾ç½®ä¸‹ï¼Œå‡ä¼˜äºå…ˆè¿›çš„å‡æ–°é—»æ²»ç†åŸºçº¿æ–¹æ³•å’Œæ ‡å‡†è‡ªæ¨¡ä»¿å­¦ä¹ æ–¹æ³•ã€‚<br>**[limitation/future]** The proposed method operates under the assumption that the veracity of news is pre-determined, necessitating integration with an external fake news detection system. Future research could explore adaptive propagation models and the dynamic nature of user behavior.<br>\[ç¿»è¯‘\]<br>æ‰€ææ–¹æ³•åŸºäºæ–°é—»çœŸä¼ªå·²çŸ¥çš„å‡è®¾è¿è¡Œï¼Œå› æ­¤éœ€è¦ä¸å¤–éƒ¨å‡æ–°é—»æ£€æµ‹ç³»ç»Ÿç»“åˆã€‚æœªæ¥ç ”ç©¶å¯æ¢ç´¢è‡ªé€‚åº”çš„ä¼ æ’­æ¨¡å‹å’Œç”¨æˆ·è¡Œä¸ºçš„åŠ¨æ€ç‰¹æ€§ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[å¼•ç”¨æ–‡\]The work by Xu et al. \(2024\) marks a pivotal transition from merely recognizing patterns of disinformation to actively intervening to curtail its spread. By harnessing network effects within a reinforcement learning framework enhanced by self-imitative adversarial learning, their NAGASIL model transcends static pattern recognition. It implements a dynamic, goal-oriented policy learning process that provides actionable guidance for debunker selection strategies.<br>\[ç¿»è¯‘\]<br>Xuç­‰äººï¼ˆ2024ï¼‰çš„ç ”ç©¶æ ‡å¿—ç€ä¸€ä¸ªå…³é”®çš„è½¬å˜ï¼šä»ä»…ä»…è¯†åˆ«è™šå‡ä¿¡æ¯æ¨¡å¼ï¼Œè½¬å‘ä¸»åŠ¨å¹²é¢„ä»¥éåˆ¶å…¶ä¼ æ’­ã€‚é€šè¿‡åœ¨ä¸€ä¸ªç”±è‡ªæ¨¡ä»¿å¯¹æŠ—å­¦ä¹ å¢å¼ºçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶å†…åˆ©ç”¨ç½‘ç»œæ•ˆåº”ï¼Œä»–ä»¬çš„NAGASILæ¨¡å‹è¶…è¶Šäº†é™æ€æ¨¡å¼è¯†åˆ«ã€‚å®ƒå®ç°äº†ä¸€ä¸ªåŠ¨æ€çš„ã€ç›®æ ‡å¯¼å‘çš„ç­–ç•¥å­¦ä¹ è¿‡ç¨‹ï¼Œä¸ºè¾Ÿè°£è€…é€‰æ‹©ç­–ç•¥æä¾›äº†å¯è¡Œçš„æŒ‡å¯¼ã€‚<br>\[notes\]1.è¿™æ˜¯ä¸€ä¸ªå¯¹æŠ—æ€§å­¦ä¹ æ¡†æ¶ï¼Œåˆ¤åˆ«å™¨å¸Œæœ›å¥½åºåˆ—çš„ç½®ä¿¡åº¦é«˜ï¼Œå…¶ä»–åºåˆ—çš„ç½®ä¿¡åº¦ä½ï¼Œé€šè¿‡æŸå¤±å‡½æ•°è®­ç»ƒä¼˜åŒ–ã€‚ç”Ÿæˆå™¨ä¾æ®ç›®æ ‡å‡½æ•°è¿›è¡Œè®­ç»ƒä¼˜åŒ–ï¼Œç›®æ ‡å‡½æ•°åŒ…å«ä¸‰éƒ¨åˆ†ï¼šåˆ¤åˆ«å™¨ä¼ æ¥çš„å¯¹æŠ—ä¿¡å·ï¼ˆç½®ä¿¡åº¦ï¼‰ã€é¼“åŠ±å¤šæ ·æ€§çš„ç†µæ­£åˆ™ã€è´Ÿé‡‡æ ·æ­£åˆ™é¡¹ï¼ˆæ¥è‡ªååºåˆ—çš„è·ç¦»ï¼ˆè®­ç»ƒå¦ä¸€ä¸ªæ¨¡å‹ä»¥è¾“å‡ºè¯¥å€¼ï¼‰ï¼‰ã€‚å¥½ç»éªŒå’Œåç»éªŒæ¯è½®é€šè¿‡å¥–åŠ±å€¼V\(Ï„\) = -log\(æ„ŸæŸ“ç”¨æˆ·æ¯”ä¾‹\)è·å¾—ã€‚<br>2.æ¯**è½®**ä¸­æ¯ä¸ª**é˜¶æ®µ**é€‰æ‹©ä¸€ä¸ªç”¨æˆ·æ¢å¤å¹¶ä½œä¸ºè¾Ÿè°£è€…ï¼Œé¢„ç®—å‡å»å…¶æˆæœ¬ï¼Œè¿›è¡Œwä¸ª**æ—¶é—´æ­¥**çš„è¾Ÿè°£ã€‚æ¯ä¸ªé˜¶æ®µçš„é¢„ç®—ç”¨å®Œåï¼Œè¿›è¡Œæ¯è½®ä¸€æ¬¡çš„æ¢¯åº¦æ›´æ–°å’Œå¥½ååºåˆ—è¯„é€‰ï¼Œç„¶åè¿›å…¥ä¸‹ä¸€è½®</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[News Source Credibility Assessment: A Reddit Case Study](https://ojs.aaai.org/index.php/ICWSM/article/view/35804) <br> Arash Amini, Yigit Ege Bayiz, Ashwin Ram, Radu Marculescu, and Ufuk Topcu <br> 2025-06-07|é€šè¿‡å¸–å­é—´çš„è¯„è®ºåŒºç›¸ä¼¼æ€§æ„å»ºåŠ æƒé“å­ç½‘ç»œï¼Œä»¥æ±‚æ‰¾åˆ°æ°´å†›è››ä¸é©¬è¿¹ï¼Œè¿›è€Œç¡®å®šæ–°é—»æ¥æºæ˜¯å¦å¯ä¿¡|<img width="1200" alt="pipeline" src="figures/CREDiBERT.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Driven by the proliferation of misinformation on social media, this work shifts focus from fact-checking individual news items to assessing the systemic credibility of news sources, addressing a critical gap in combating information pollution at its origin. \[ç¿»è¯‘\] æœ¬ç ”ç©¶å—ç¤¾äº¤åª’ä½“è™šå‡ä¿¡æ¯æ³›æ»¥çš„é©±åŠ¨ï¼Œå°†é‡ç‚¹ä»æ ¸æŸ¥å•ä¸€æ–°é—»çš„çœŸå®æ€§ï¼Œè½¬å‘è¯„ä¼°æ–°é—»æ¥æºçš„ç³»ç»Ÿæ€§å¯ä¿¡åº¦ï¼Œä»¥åº”å¯¹ä»æºå¤´æ²»ç†ä¿¡æ¯æ±¡æŸ“è¿™ä¸€å…³é”®é—®é¢˜ã€‚ **[innovation]** Its core innovation lies in constructing a weighted post-to-post network based on the semantic similarity of user comments. This network models latent socio-contextual linkages between submissions, which are then integrated via a Graph Convolutional Network \(GCN\) to enhance the binary classification of source credibility. \[ç¿»è¯‘\] å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºåŸºäºç”¨æˆ·è¯„è®ºçš„è¯­ä¹‰ç›¸ä¼¼æ€§æ„å»ºäº†ä¸€ä¸ªåŠ æƒå¸–å­é—´ç½‘ç»œã€‚è¯¥ç½‘ç»œå»ºæ¨¡äº†å¸–å­é—´æ½œåœ¨çš„ç¤¾ä¼šè¯­å¢ƒå…³è”ï¼Œå¹¶é€šè¿‡å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰æ•´åˆè¿™äº›å…³è”ï¼Œä»¥æå‡å¯¹æ–°é—»æ¥æºå¯ä¿¡åº¦çš„äºŒåˆ†ç±»æ€§èƒ½ã€‚ **[method]** The framework, CREDiBERT, first trains a bi-encoder on paired submissions about the same event to learn credibility-aware text embeddings. It then builds a novel graph where edge weights encode user reaction similarity via comments. Finally, a GCN fuses these textual and social signals for final classification. \[ç¿»è¯‘\] è¯¥æ¡†æ¶ï¼ˆCREDiBERTï¼‰é¦–å…ˆåœ¨æè¿°åŒä¸€äº‹ä»¶çš„æˆå¯¹å¸–å­ä¸Šè®­ç»ƒä¸€ä¸ªåŒç¼–ç å™¨ï¼Œä»¥å­¦ä¹ å…·æœ‰å¯ä¿¡åº¦æ„ŸçŸ¥çš„æ–‡æœ¬åµŒå…¥ã€‚éšåï¼Œå®ƒæ„å»ºäº†ä¸€ä¸ªæ–°é¢–çš„å›¾ç»“æ„ï¼Œå…¶ä¸­è¾¹çš„æƒé‡é€šè¿‡è¯„è®ºç¼–ç äº†ç”¨æˆ·ååº”çš„ç›¸ä¼¼æ€§ã€‚æœ€åï¼Œä¸€ä¸ªå›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰èåˆäº†è¿™äº›æ–‡æœ¬ä¸ç¤¾ä¼šä¿¡å·ä»¥å®Œæˆæœ€ç»ˆåˆ†ç±»ã€‚ **[conclusion/contribution]** The model outperforms BERT-based baselines by 3% in F1-score for credibility assessment. Incorporating the user-interaction graph yields a further 8% gain, demonstrating the significant value of socially-grounded signals in evaluating information ecosystems. \[ç¿»è¯‘\] è¯¥æ¨¡å‹åœ¨å¯ä¿¡åº¦è¯„ä¼°ä»»åŠ¡ä¸Šçš„F1åˆ†æ•°æ¯”åŸºäºBERTçš„åŸºçº¿æ¨¡å‹é«˜å‡º3%ã€‚èå…¥ç”¨æˆ·äº¤äº’å›¾åï¼Œæ€§èƒ½è¿›ä¸€æ­¥æå‡äº†8%ï¼Œè¿™è¯æ˜äº†åŸºäºç¤¾äº¤çš„æ„ŸçŸ¥ä¿¡å·åœ¨è¯„ä¼°ä¿¡æ¯ç”Ÿæ€ç³»ç»Ÿä¸­çš„é‡è¦ä»·å€¼ã€‚ **[limitation/future]** The method assesses source reputation rather than article veracity, leaving it blind to one-off falsehoods from otherwise credible outlets. Its performance is also tied to the bias present in the training data from specific online communities. \[ç¿»è¯‘\] è¯¥æ–¹æ³•è¯„ä¼°çš„æ˜¯æ¥æºå£°èª‰è€Œéæ–‡ç« çœŸå®æ€§ï¼Œå› æ­¤æ— æ³•è¯†åˆ«é‚£äº›æ¥è‡ªé€šå¸¸å¯ä¿¡åª’ä½“çš„å¶ç„¶æ€§è™šå‡ä¿¡æ¯ã€‚åŒæ—¶ï¼Œå…¶æ€§èƒ½å—é™äºæ¥è‡ªç‰¹å®šç½‘ç»œç¤¾åŒºçš„è®­ç»ƒæ•°æ®ä¸­å­˜åœ¨çš„å›ºæœ‰åå·®ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Driven by the proliferation of misinformation on social media, this work shifts focus from fact-checking individual news items to assessing the systemic credibility of news sources, addressing a critical gap in combating information pollution at its origin.<br>\[ç¿»è¯‘\]<br>æœ¬ç ”ç©¶å—ç¤¾äº¤åª’ä½“è™šå‡ä¿¡æ¯æ³›æ»¥çš„é©±åŠ¨ï¼Œå°†é‡ç‚¹ä»æ ¸æŸ¥å•ä¸€æ–°é—»çš„çœŸå®æ€§ï¼Œè½¬å‘è¯„ä¼°æ–°é—»æ¥æºçš„ç³»ç»Ÿæ€§å¯ä¿¡åº¦ï¼Œä»¥åº”å¯¹ä»æºå¤´æ²»ç†ä¿¡æ¯æ±¡æŸ“è¿™ä¸€å…³é”®é—®é¢˜ã€‚<br>**[innovation]** Its core innovation lies in constructing a weighted post-to-post network based on the semantic similarity of user comments. This network models latent socio-contextual linkages between submissions, which are then integrated via a Graph Convolutional Network \(GCN\) to enhance the binary classification of source credibility.<br>\[ç¿»è¯‘\]<br>å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºåŸºäºç”¨æˆ·è¯„è®ºçš„è¯­ä¹‰ç›¸ä¼¼æ€§æ„å»ºäº†ä¸€ä¸ªåŠ æƒå¸–å­é—´ç½‘ç»œã€‚è¯¥ç½‘ç»œå»ºæ¨¡äº†å¸–å­é—´æ½œåœ¨çš„ç¤¾ä¼šè¯­å¢ƒå…³è”ï¼Œå¹¶é€šè¿‡å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰æ•´åˆè¿™äº›å…³è”ï¼Œä»¥æå‡å¯¹æ–°é—»æ¥æºå¯ä¿¡åº¦çš„äºŒåˆ†ç±»æ€§èƒ½ã€‚<br>**[method]** The framework, CREDiBERT, first trains a bi-encoder on paired submissions about the same event to learn credibility-aware text embeddings. It then builds a novel graph where edge weights encode user reaction similarity via comments. Finally, a GCN fuses these textual and social signals for final classification.<br>\[ç¿»è¯‘\]<br>è¯¥æ¡†æ¶ï¼ˆCREDiBERTï¼‰é¦–å…ˆåœ¨æè¿°åŒä¸€äº‹ä»¶çš„æˆå¯¹å¸–å­ä¸Šè®­ç»ƒä¸€ä¸ªåŒç¼–ç å™¨ï¼Œä»¥å­¦ä¹ å…·æœ‰å¯ä¿¡åº¦æ„ŸçŸ¥çš„æ–‡æœ¬åµŒå…¥ã€‚éšåï¼Œå®ƒæ„å»ºäº†ä¸€ä¸ªæ–°é¢–çš„å›¾ç»“æ„ï¼Œå…¶ä¸­è¾¹çš„æƒé‡é€šè¿‡è¯„è®ºç¼–ç äº†ç”¨æˆ·ååº”çš„ç›¸ä¼¼æ€§ã€‚æœ€åï¼Œä¸€ä¸ªå›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰èåˆäº†è¿™äº›æ–‡æœ¬ä¸ç¤¾ä¼šä¿¡å·ä»¥å®Œæˆæœ€ç»ˆåˆ†ç±»ã€‚<br>**[conclusion/contribution]** The model outperforms BERT-based baselines by 3% in F1-score for credibility assessment. Incorporating the user-interaction graph yields a further 8% gain, demonstrating the significant value of socially-grounded signals in evaluating information ecosystems.<br>\[ç¿»è¯‘\]<br>è¯¥æ¨¡å‹åœ¨å¯ä¿¡åº¦è¯„ä¼°ä»»åŠ¡ä¸Šçš„F1åˆ†æ•°æ¯”åŸºäºBERTçš„åŸºçº¿æ¨¡å‹é«˜å‡º3%ã€‚èå…¥ç”¨æˆ·äº¤äº’å›¾åï¼Œæ€§èƒ½è¿›ä¸€æ­¥æå‡äº†8%ï¼Œè¿™è¯æ˜äº†åŸºäºç¤¾äº¤çš„æ„ŸçŸ¥ä¿¡å·åœ¨è¯„ä¼°ä¿¡æ¯ç”Ÿæ€ç³»ç»Ÿä¸­çš„é‡è¦ä»·å€¼ã€‚<br>**[limitation/future]** The method assesses source reputation rather than article veracity, leaving it blind to one-off falsehoods from otherwise credible outlets. Its performance is also tied to the bias present in the training data from specific online communities.<br>\[ç¿»è¯‘\]<br>è¯¥æ–¹æ³•è¯„ä¼°çš„æ˜¯æ¥æºå£°èª‰è€Œéæ–‡ç« çœŸå®æ€§ï¼Œå› æ­¤æ— æ³•è¯†åˆ«é‚£äº›æ¥è‡ªé€šå¸¸å¯ä¿¡åª’ä½“çš„å¶ç„¶æ€§è™šå‡ä¿¡æ¯ã€‚åŒæ—¶ï¼Œå…¶æ€§èƒ½å—é™äºæ¥è‡ªç‰¹å®šç½‘ç»œç¤¾åŒºçš„è®­ç»ƒæ•°æ®ä¸­å­˜åœ¨çš„å›ºæœ‰åå·®ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[notes\]å…³é”®è®¾è®¡åœ¨äºé€šè¿‡è¯„è®ºåŒºçš„è¯„è®ºç›¸ä¼¼æ€§å»ºæ¨¡ä¸åŒå¸–å­é—´çš„æ½œåœ¨è”ç³»ï¼ˆåŠ æƒå¸–å­ç½‘ç»œçš„è¾¹æƒé‡ï¼‰ï¼Œåœ¨GCNä¸­åˆ©ç”¨è¯¥è”ç³»æ¥è¿›è¡Œå¸–å­çš„æ¥æºæ–°é—»çš„å¯ä¿¡æ€§äºŒåˆ†ç±»<br>\[å¼•ç”¨æ–‡\]Amini et al. \(2025\) move beyond purely content-based pattern recognition, attempting instead to establish connections between posts and the credibility of news sources. Their CREDiBERT framework innovatively constructs a weighted post-to-post network from user comment similarities. This graph structure captures community-specific reaction patterns, which, when processed through a Graph Convolutional Network, significantly enhance the classification of news source credibility. This work underscores a paradigm shift: credibility assessment is beginning to focus on the patterns of information dissemination, rather than solely analyzing the specific content.<br>\[ç¿»è¯‘\]<br>Aminiç­‰äººï¼ˆ2025ï¼‰çš„ç ”ç©¶è¶…è¶Šäº†å•çº¯çš„åŸºäºå†…å®¹çš„æ¨¡å¼è¯†åˆ«ï¼Œè½¬è€Œå°è¯•å»ºç«‹å¸–å­ä¸æ–°é—»æ¥æºå¯ä¿¡åº¦çš„è”ç³»ã€‚ä»–ä»¬çš„CREDiBERTæ¡†æ¶åˆ›æ–°æ€§åœ°ä»ç”¨æˆ·è¯„è®ºç›¸ä¼¼æ€§ä¸­æ„å»ºäº†ä¸€ä¸ªåŠ æƒå¸–å­é—´ç½‘ç»œã€‚è¯¥å›¾ç»“æ„æ•è·äº†ç¤¾åŒºçš„ç‰¹å®šååº”æ¨¡å¼ï¼Œè¿™äº›æ¨¡å¼é€šè¿‡å›¾å·ç§¯ç½‘ç»œå¤„ç†åï¼Œæ˜¾è‘—å¢å¼ºäº†å¯¹æ–°é—»æ¥æºå¯ä¿¡åº¦çš„åˆ†ç±»èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†ä¸€ä¸ªèŒƒå¼è½¬å˜ï¼šå¯ä¿¡åº¦è¯„ä¼°å¼€å§‹å…³æ³¨æ¶ˆæ¯çš„ä¼ æ’­æ¨¡å¼ï¼Œè€Œä¸ä»…ä»…æ˜¯åˆ†æå…·ä½“å†…å®¹ã€‚</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-CIKM%20%2724-blue)]()<br>[Let silence speak: Enhancing fake news detection with generated comments from large language models](https://dl.acm.org/doi/10.1145/3627673.3679519) <br> Qiong Nan,Qiang Shengâˆ—,Juan Cao,Beizhe Hu,Danding Wang,Jintao Li <br> 2024-10-21|â€œè®©æ²‰é»˜çš„ç”¨æˆ·å‘å£°â€”â€”ç”¨LLMç”Ÿæˆå¤šæ ·è¯„è®ºï¼Œè¡¥å……è¯„è®ºç‰¹å¾ï¼Œæå‡è™šå‡æ–°é—»æ£€æµ‹çš„è¦†ç›–åŠ›å’Œæ—©æœŸæ€§èƒ½ã€‚â€|<img width="1200" alt="pipeline" src="figures/GenFEND.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Comment-based fake news detection is hindered by the scarcity and skewed distribution of real user comments \(e.g., in early stages or from â€œsilentâ€ users\), leading to an incomplete and biased perception of public feedback.  \[ç¿»è¯‘\]åŸºäºè¯„è®ºçš„è™šå‡æ–°é—»æ£€æµ‹å—é™äºçœŸå®ç”¨æˆ·è¯„è®ºçš„ç¨€ç¼ºæ€§ä¸åˆ†å¸ƒåå·®ï¼ˆä¾‹å¦‚åœ¨æ—©æœŸä¼ æ’­é˜¶æ®µæˆ–æ¥è‡ªâ€œæ²‰é»˜â€ç”¨æˆ·ï¼‰ï¼Œå¯¼è‡´å¯¹å…¬ä¼—åé¦ˆçš„æ„ŸçŸ¥ä¸å®Œæ•´ä¸”å­˜åœ¨åå·®ã€‚ **[innovation]** ä½¿ç”¨LLMè¡¥å……è¯„è®ºç‰¹å¾ï¼Œè§£å†³è¯¥é¢†åŸŸè¯„è®ºæ•°æ®ä¸è¶³å’Œä¸å…¨é¢çš„é—®é¢˜ **[method]** The GenFEND framework: \(1\) generates comments by prompting an LLM with 30 predefined user profiles \(gender/age/education\); \(2\) analyzes them via group-wise semantic averaging and diversity measurement across demographic views; \(3\) aggregates intra-view and inter-view features adaptively for final classification.  \[ç¿»è¯‘\]GenFENDæ¡†æ¶ï¼š\(1\) é€šè¿‡ä¸ºLLMæä¾›30ä¸ªé¢„å®šä¹‰ç”¨æˆ·ç”»åƒï¼ˆæ€§åˆ«/å¹´é¾„/æ•™è‚²ï¼‰æ¥ç”Ÿæˆè¯„è®ºï¼›\(2\) é€šè¿‡åˆ†ç»„è¯­ä¹‰å¹³å‡å’Œè·¨äººå£ç»Ÿè®¡è§†å›¾çš„å¤šæ ·æ€§åº¦é‡å¯¹å…¶è¿›è¡Œåˆ†æï¼›\(3\) è‡ªé€‚åº”åœ°èšåˆè§†å›¾å†…å’Œè§†å›¾é—´çš„ç‰¹å¾ä»¥è¿›è¡Œæœ€ç»ˆåˆ†ç±»ã€‚ **[conclusion/contribution]** GenFEND consistently boosts both content-only and comment-based detectors across datasets. Notably, LLM-generated comments provide effective signals for early detection and can outperform actual comments, especially in identifying fake news.  \[ç¿»è¯‘\]GenFENDåœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠæŒç»­æå‡äº†ä»…ä½¿ç”¨å†…å®¹å’Œä½¿ç”¨è¯„è®ºçš„æ£€æµ‹å™¨æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒLLMç”Ÿæˆçš„è¯„è®ºä¸ºæ—©æœŸæ£€æµ‹æä¾›äº†æœ‰æ•ˆä¿¡å·ï¼Œå¹¶ä¸”å¯ä»¥è¶…è¶ŠçœŸå®è¯„è®ºçš„æ•ˆæœï¼Œå°¤å…¶åœ¨è¯†åˆ«è™šå‡æ–°é—»æ–¹é¢ã€‚ **[limitation/future]** Limitations include dependence on LLM generation quality, limited considered user attributes, and higher computational cost. Future work may explore more nuanced user modeling, dynamic profile generation, and integration with real social graphs.  \[ç¿»è¯‘\]å±€é™æ€§åŒ…æ‹¬å¯¹LLMç”Ÿæˆè´¨é‡çš„ä¾èµ–ã€æ‰€è€ƒè™‘ç”¨æˆ·å±æ€§çš„æœ‰é™æ€§ä»¥åŠè¾ƒé«˜çš„è®¡ç®—æˆæœ¬ã€‚æœªæ¥å·¥ä½œå¯æ¢ç´¢æ›´ç»†è‡´çš„ç”¨æˆ·å»ºæ¨¡ã€åŠ¨æ€ç”»åƒç”Ÿæˆä»¥åŠä¸çœŸå®ç¤¾äº¤å›¾è°±çš„ç»“åˆã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Comment-based fake news detection is hindered by the scarcity and skewed distribution of real user comments \(e.g., in early stages or from â€œsilentâ€ users\), leading to an incomplete and biased perception of public feedback.<br><br>\[ç¿»è¯‘\]åŸºäºè¯„è®ºçš„è™šå‡æ–°é—»æ£€æµ‹å—é™äºçœŸå®ç”¨æˆ·è¯„è®ºçš„ç¨€ç¼ºæ€§ä¸åˆ†å¸ƒåå·®ï¼ˆä¾‹å¦‚åœ¨æ—©æœŸä¼ æ’­é˜¶æ®µæˆ–æ¥è‡ªâ€œæ²‰é»˜â€ç”¨æˆ·ï¼‰ï¼Œå¯¼è‡´å¯¹å…¬ä¼—åé¦ˆçš„æ„ŸçŸ¥ä¸å®Œæ•´ä¸”å­˜åœ¨åå·®ã€‚<br>**[innovation]** ä½¿ç”¨LLMè¡¥å……è¯„è®ºç‰¹å¾ï¼Œè§£å†³è¯¥é¢†åŸŸè¯„è®ºæ•°æ®ä¸è¶³å’Œä¸å…¨é¢çš„é—®é¢˜<br>**[method]** The GenFEND framework: \(1\) generates comments by prompting an LLM with 30 predefined user profiles \(gender/age/education\); \(2\) analyzes them via group-wise semantic averaging and diversity measurement across demographic views; \(3\) aggregates intra-view and inter-view features adaptively for final classification.<br><br>\[ç¿»è¯‘\]GenFENDæ¡†æ¶ï¼š\(1\) é€šè¿‡ä¸ºLLMæä¾›30ä¸ªé¢„å®šä¹‰ç”¨æˆ·ç”»åƒï¼ˆæ€§åˆ«/å¹´é¾„/æ•™è‚²ï¼‰æ¥ç”Ÿæˆè¯„è®ºï¼›\(2\) é€šè¿‡åˆ†ç»„è¯­ä¹‰å¹³å‡å’Œè·¨äººå£ç»Ÿè®¡è§†å›¾çš„å¤šæ ·æ€§åº¦é‡å¯¹å…¶è¿›è¡Œåˆ†æï¼›\(3\) è‡ªé€‚åº”åœ°èšåˆè§†å›¾å†…å’Œè§†å›¾é—´çš„ç‰¹å¾ä»¥è¿›è¡Œæœ€ç»ˆåˆ†ç±»ã€‚<br>**[conclusion/contribution]** GenFEND consistently boosts both content-only and comment-based detectors across datasets. Notably, LLM-generated comments provide effective signals for early detection and can outperform actual comments, especially in identifying fake news.<br><br>\[ç¿»è¯‘\]GenFENDåœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠæŒç»­æå‡äº†ä»…ä½¿ç”¨å†…å®¹å’Œä½¿ç”¨è¯„è®ºçš„æ£€æµ‹å™¨æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒLLMç”Ÿæˆçš„è¯„è®ºä¸ºæ—©æœŸæ£€æµ‹æä¾›äº†æœ‰æ•ˆä¿¡å·ï¼Œå¹¶ä¸”å¯ä»¥è¶…è¶ŠçœŸå®è¯„è®ºçš„æ•ˆæœï¼Œå°¤å…¶åœ¨è¯†åˆ«è™šå‡æ–°é—»æ–¹é¢ã€‚<br>**[limitation/future]** Limitations include dependence on LLM generation quality, limited considered user attributes, and higher computational cost. Future work may explore more nuanced user modeling, dynamic profile generation, and integration with real social graphs.<br><br>\[ç¿»è¯‘\]å±€é™æ€§åŒ…æ‹¬å¯¹LLMç”Ÿæˆè´¨é‡çš„ä¾èµ–ã€æ‰€è€ƒè™‘ç”¨æˆ·å±æ€§çš„æœ‰é™æ€§ä»¥åŠè¾ƒé«˜çš„è®¡ç®—æˆæœ¬ã€‚æœªæ¥å·¥ä½œå¯æ¢ç´¢æ›´ç»†è‡´çš„ç”¨æˆ·å»ºæ¨¡ã€åŠ¨æ€ç”»åƒç”Ÿæˆä»¥åŠä¸çœŸå®ç¤¾äº¤å›¾è°±çš„ç»“åˆã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[å¼•ç”¨æ–‡\]Within the task of False Content Analysis, a key bottleneck is the scarcity of early-stage comments and the absence of opinions from silent users. The GenFEND framework \(Nan et al., 2024\) addresses this by using Large Language Models \(LLMs\) to supplement these missing comments. Instead of passively relying on sparse real comments, their approach actively generates a rich set of synthetic comments conditioned on diverse user profiles \(e.g., gender, age, education level\). This method effectively performs data augmentation in the social comment space, providing a stable and diverse informational supplement. This helps models establish a more complete perceptual foundation for veracity judgment and has proven to be highly effective for early fake news detection.<br>\[ç¿»è¯‘\]<br>åœ¨è™šå‡å†…å®¹åˆ†æä»»åŠ¡ä¸­ï¼Œä¸€ä¸ªå…³é”®ç“¶é¢ˆæ˜¯æ—©æœŸè¯„è®ºçš„ç¨€ç¼ºæ€§å’Œæ²‰é»˜ç”¨æˆ·æ„è§çš„ç¼ºå¤±ã€‚GenFENDæ¡†æ¶ \(Nan et al., 2024\) é€šè¿‡ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹æ¥è¡¥å……è¿™éƒ¨åˆ†ç¼ºå¤±çš„è¯„è®ºï¼Œä»è€Œè§£å†³äº†è¿™ä¸€é—®é¢˜ã€‚è¯¥æ–¹æ³•ä¸å†è¢«åŠ¨åœ°ä¾èµ–ç¨€ç–çš„çœŸå®è¯„è®ºï¼Œè€Œæ˜¯ä¸»åŠ¨ç”Ÿæˆä¸€ç»„ä»¥å¤šæ ·åŒ–ç”¨æˆ·ç”»åƒï¼ˆå¦‚æ€§åˆ«ã€å¹´é¾„ã€æ•™è‚²ç¨‹åº¦ï¼‰ä¸ºæ¡ä»¶çš„ä¸°å¯Œåˆæˆè¯„è®ºã€‚è¯¥æ–¹æ³•æœ‰æ•ˆåœ°åœ¨ç¤¾äº¤è¯„è®ºç©ºé—´è¿›è¡Œäº†æ•°æ®å¢å¼ºï¼Œæä¾›äº†ä¸€ä¸ªç¨³å®šä¸”å¤šæ ·åŒ–çš„ä¿¡æ¯è¡¥å……ã€‚è¿™æœ‰åŠ©äºæ¨¡å‹ä¸ºçœŸå®æ€§åˆ¤æ–­å»ºç«‹æ›´å®Œæ•´çš„æ„ŸçŸ¥åŸºç¡€ï¼Œå¹¶è¢«è¯æ˜å¯¹æ—©æœŸè™šå‡æ–°é—»æ£€æµ‹éå¸¸æœ‰æ•ˆã€‚</div></details></div></div>|

### Sentiment Analysis (3 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence-blue)]()<br>[CAMEL: Capturing metaphorical alignment with context disentangling for multimodal emotion recogni...](https://ojs.aaai.org/index.php/AAAI/article/view/28787) <br> Linhao Zhang,Li Jin\*,Guangluan Xu,Xiaoyu Li,Cai Xu,Kaiwen Wei,Nayu Liu,Haonan Liu <br> 2024-03-24|\[AI generated\] CAMEL disentangles metaphorical alignment like a prism separating light, then adaptively fuses context for emotion recognition. \[ç¿»è¯‘\]CAMELåƒæ£±é•œåˆ†ç¦»å…‰çº¿èˆ¬è§£è€¦éšå–»å¯¹é½ï¼Œå†è‡ªé€‚åº”èåˆä¸Šä¸‹æ–‡è¿›è¡Œæƒ…æ„Ÿè¯†åˆ«ã€‚|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/CAMEL1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/CAMEL.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** ä¸ºäº†è§£å†³å¤šæ¨¡æ€å†…å®¹ä¸­å› éšå–»å¯¹é½å¯¼è‡´**æƒ…æ„Ÿè¯¯åˆ¤**çš„é—®é¢˜ï¼šä¹‹å‰çš„æ–¹æ³•æœ¬è´¨ä¸Šæ— æ³•ç†è§£éšå–»,ä¸“æ³¨äºç›´æ¥çš„è¯­ä¹‰å¯¹é½ï¼Œæ— æ³•æ•æ‰å¦‚æ–‡å­—â€œçœ¼æ³ªâ€ä¸å›¾ç‰‡â€œæ²³æµâ€çš„è¿™ç§éšå¼è”ç³» **[innovation]** å°†å¤šæ¨¡æ€é—´éšå«è”ç³»çš„å¯¹é½æ€æƒ³åº”ç”¨äºå¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«é¢†åŸŸ **[method]** ä½¿ç”¨äº†åŸºäºæ¡ä»¶ç”Ÿæˆä¸è§£è€¦ä¸Šä¸‹æ–‡é€‚åº”çš„CAMELæ¡†æ¶:éšå–»å¯¹é½å»ºæ¨¡ï¼ˆæ¡ä»¶ç”Ÿæˆï¼‰\(å¼ºåˆ¶æ¨¡å‹æŒ‰ç…§æ¨¡ç‰ˆè¾“å‡ºï¼ˆCMTå’ŒSPVä¸¤ç§æŠ€æœ¯ï¼‰ï¼›ä½¿ç”¨å›¾ç‰‡ã€æ ‡é¢˜ã€æ–‡æœ¬çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œä½¿ç”¨ä¸€ä¸ª\[CLS\] tokenèšåˆå…¨å±€ä¿¡æ¯ï¼‰-&gt;ä¸Šä¸‹æ–‡è¯­ä¹‰é€‚åº”ï¼ˆç‰¹å¾èåˆï¼‰ï¼ˆä½¿ç”¨ä¸¤ä¸ªå¼‚æ„æ¨¡å‹ï¼Œåˆ†åˆ«è¾“å…¥å­—é¢ç‰¹å¾ï¼ˆCAMEL-Cï¼ŒCMTï¼‰å’Œéšå–»ç‰¹å¾ï¼ˆCAMEL-Sï¼ŒSPVï¼‰ç”Ÿæˆä¸¤ä¸ªå‘é‡çŸ©é˜µï¼Œé€šè¿‡éšå–»æŸ¥å­—é¢å®ç°å¤šå¤´æ³¨æ„åŠ›ï¼‰-&gt;è§£è€¦å¯¹æ¯”åŒ¹é…ï¼ˆä¸Šä¸‹æ–‡æ­£åˆ™åŒ–ï¼‰ï¼ˆç¡®ä¿ä¸åç¦»è¯­å¢ƒã€‚é‡‡ç”¨è§£è€¦å­¦ä¹ æ€æƒ³ï¼Œéšå–»ç‰¹å¾ä¸­åˆ†ç¦»å‡ºä»£è¡¨â€œä¸»å¯¼ä¸Šä¸‹æ–‡ç±»åˆ«â€çš„ç¦»æ•£åˆ†å¸ƒï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œä½¿å­—é¢ç‰¹å¾æ¨å‡ºçš„åˆ†å¸ƒä¸ä¹‹å¯¹é½ï¼‰ **[conclusion/contribution]** è¾¾æˆäº†å¯¹éšå«æƒ…æ„Ÿæ›´ç²¾å‡†ã€é²æ£’çš„è¯†åˆ«æ•ˆæœ **[limitation/future]** æ•´ä¸ªæ–¹æ³•æ¡†æ¶å¤æ‚ï¼Œæ¨¡å‹æ‰€éœ€çš„æ‰€æœ‰èƒ½åŠ›ï¼šæ‰¾å­—é¢ç‰¹å¾ã€æ‰¾éšå–»ç‰¹å¾ã€ä¸¤è€…å¯¹é½ã€æ ¹æ®èåˆç‰¹å¾ç”Ÿæˆæƒ…æ„Ÿåˆ†æï¼Œéƒ½æ˜¯ä¸€æ¬¡è®­ç»ƒå®Œæˆçš„ï¼Œæ˜¯å¦éš¾ä»¥æ”¶æ•›ï¼ˆè™½ç„¶è®ºæ–‡ä½¿ç”¨äº†è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼‰ï¼Œæ˜¯å¦èƒ½å¤Ÿåœ¨è®­ç»ƒå±‚é¢è¿›è¡Œä¸€å®šçš„è§£è€¦ï¼Ÿåˆ†åˆ«è®­ç»ƒå„èƒ½åŠ›">**[summary]**</summary><div style="margin-top:6px">**[motivation]** ä¸ºäº†è§£å†³å¤šæ¨¡æ€å†…å®¹ä¸­å› éšå–»å¯¹é½å¯¼è‡´**æƒ…æ„Ÿè¯¯åˆ¤**çš„é—®é¢˜ï¼šä¹‹å‰çš„æ–¹æ³•æœ¬è´¨ä¸Šæ— æ³•ç†è§£éšå–»,ä¸“æ³¨äºç›´æ¥çš„è¯­ä¹‰å¯¹é½ï¼Œæ— æ³•æ•æ‰å¦‚æ–‡å­—â€œçœ¼æ³ªâ€ä¸å›¾ç‰‡â€œæ²³æµâ€çš„è¿™ç§éšå¼è”ç³»<br>**[innovation]** å°†å¤šæ¨¡æ€é—´éšå«è”ç³»çš„å¯¹é½æ€æƒ³åº”ç”¨äºå¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«é¢†åŸŸ<br>**[method]** ä½¿ç”¨äº†åŸºäºæ¡ä»¶ç”Ÿæˆä¸è§£è€¦ä¸Šä¸‹æ–‡é€‚åº”çš„CAMELæ¡†æ¶:éšå–»å¯¹é½å»ºæ¨¡ï¼ˆæ¡ä»¶ç”Ÿæˆï¼‰\(å¼ºåˆ¶æ¨¡å‹æŒ‰ç…§æ¨¡ç‰ˆè¾“å‡ºï¼ˆCMTå’ŒSPVä¸¤ç§æŠ€æœ¯ï¼‰ï¼›ä½¿ç”¨å›¾ç‰‡ã€æ ‡é¢˜ã€æ–‡æœ¬çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œä½¿ç”¨ä¸€ä¸ª\[CLS\] tokenèšåˆå…¨å±€ä¿¡æ¯ï¼‰->ä¸Šä¸‹æ–‡è¯­ä¹‰é€‚åº”ï¼ˆç‰¹å¾èåˆï¼‰ï¼ˆä½¿ç”¨ä¸¤ä¸ªå¼‚æ„æ¨¡å‹ï¼Œåˆ†åˆ«è¾“å…¥å­—é¢ç‰¹å¾ï¼ˆCAMEL-Cï¼ŒCMTï¼‰å’Œéšå–»ç‰¹å¾ï¼ˆCAMEL-Sï¼ŒSPVï¼‰ç”Ÿæˆä¸¤ä¸ªå‘é‡çŸ©é˜µï¼Œé€šè¿‡éšå–»æŸ¥å­—é¢å®ç°å¤šå¤´æ³¨æ„åŠ›ï¼‰->è§£è€¦å¯¹æ¯”åŒ¹é…ï¼ˆä¸Šä¸‹æ–‡æ­£åˆ™åŒ–ï¼‰ï¼ˆç¡®ä¿ä¸åç¦»è¯­å¢ƒã€‚é‡‡ç”¨è§£è€¦å­¦ä¹ æ€æƒ³ï¼Œéšå–»ç‰¹å¾ä¸­åˆ†ç¦»å‡ºä»£è¡¨â€œä¸»å¯¼ä¸Šä¸‹æ–‡ç±»åˆ«â€çš„ç¦»æ•£åˆ†å¸ƒï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œä½¿å­—é¢ç‰¹å¾æ¨å‡ºçš„åˆ†å¸ƒä¸ä¹‹å¯¹é½ï¼‰<br>**[conclusion/contribution]** è¾¾æˆäº†å¯¹éšå«æƒ…æ„Ÿæ›´ç²¾å‡†ã€é²æ£’çš„è¯†åˆ«æ•ˆæœ<br>**[limitation/future]** æ•´ä¸ªæ–¹æ³•æ¡†æ¶å¤æ‚ï¼Œæ¨¡å‹æ‰€éœ€çš„æ‰€æœ‰èƒ½åŠ›ï¼šæ‰¾å­—é¢ç‰¹å¾ã€æ‰¾éšå–»ç‰¹å¾ã€ä¸¤è€…å¯¹é½ã€æ ¹æ®èåˆç‰¹å¾ç”Ÿæˆæƒ…æ„Ÿåˆ†æï¼Œéƒ½æ˜¯ä¸€æ¬¡è®­ç»ƒå®Œæˆçš„ï¼Œæ˜¯å¦éš¾ä»¥æ”¶æ•›ï¼ˆè™½ç„¶è®ºæ–‡ä½¿ç”¨äº†è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼‰ï¼Œæ˜¯å¦èƒ½å¤Ÿåœ¨è®­ç»ƒå±‚é¢è¿›è¡Œä¸€å®šçš„è§£è€¦ï¼Ÿåˆ†åˆ«è®­ç»ƒå„èƒ½åŠ›</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">é¦–å…ˆé€šè¿‡å¤šå¤´è·¨åŸŸæ³¨æ„åŠ›æœºåˆ¶å®ç°åˆæ­¥çš„å¯¹é½ï¼Œç„¶åè®©å­—é¢ç‰¹å¾çš„åˆ†å¸ƒä¸éšå–»ç‰¹å¾çš„åˆ†å¸ƒå¯¹é½ï¼Œè¿›ä¸€æ­¥å¼ºåŒ–å¯¹é½ï¼›</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/neuralnaresh/multimodal-emotion-recognition.svg?style=social&label=Star)](https://github.com/neuralnaresh/multimodal-emotion-recognition) [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%2031st%20ACM%20International%20Conference%20on%20Multimedia-blue)]()<br>[Multi-label emotion analysis in conversation via multimodal knowledge distillation](https://dl.acm.org/doi/10.1145/3581783.3612517) <br> Sidharth Anandâˆ—,Naresh Kumar Devulapallyâˆ—,Sreyasee Das Bhattacharjee,Junsong Yuan <br> 2023-10-27|ä¸‰ä¸ªä¸“å®¶åˆ†åˆ«å¤„ç†ä¸€ä¸ªæ¨¡æ€ï¼Œè®­ç»ƒçš„åŒæ—¶å°†èƒ½åŠ›è’¸é¦ç»™èåˆåˆ†æ”¯ï¼Œæœ€ç»ˆå½¢æˆä¸€ä¸ªæ•´ä½“æ¨¡å‹ï¼Œæ•™å¸ˆï¼ˆåˆ†æ”¯ä¸“å®¶ï¼‰ä¸å­¦ç”Ÿï¼ˆèåˆä¸“å®¶ï¼‰ä¸€åŒå¤„ç†å¤šæ¨¡æ€å†…å®¹ï¼Œå¾—åˆ°æƒ…æ„Ÿåˆ†ç±»|<img width="1200" alt="pipeline" src="figures/SeMuL-PCD.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Addresses the limitations of single-dominant emotion assumptions by tackling the challenge of multi-label emotion co-occurrence and generalization across diverse socio-demographic groups, particularly varying age populations. \[ç¿»è¯‘\] é’ˆå¯¹ç°æœ‰å¤šæ¨¡æ€æ–¹æ³•ä¸»è¦å…³æ³¨å•ä¸€ä¸»å¯¼æƒ…æ„Ÿçš„å±€é™æ€§ï¼Œè¯¥ç ”ç©¶è‡´åŠ›äºè§£å†³æƒ…æ„Ÿæ ‡ç­¾å…±ç°çš„è¯†åˆ«éš¾é¢˜ï¼Œå¹¶æå‡æ¨¡å‹åœ¨ä¸åŒç¤¾ä¼šäººå£ç»Ÿè®¡å­¦ç¾¤ä½“ï¼ˆç‰¹åˆ«æ˜¯ä¸åŒå¹´é¾„æ®µäººç¾¤ï¼‰ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚ **[innovation]** å°†å¤šæ¨¡æ€çŸ¥è¯†è’¸é¦ä¸æ ‡ç­¾ä¸€è‡´æ€§æ ¡å‡†æŸå¤±ï¼ˆLCCï¼‰ç›¸ç»“åˆï¼Œå‡è½»äº†æ¨¡å‹å¯¹ç®€å•æ ‡ç­¾çš„è¿‡æ‹Ÿåˆï¼ˆä¿è¯ç½®ä¿¡åº¦ç›¸è¿‘ï¼‰ï¼›æ„å»ºäº†ä¸€ä¸ªåˆ©ç”¨è’¸é¦æ–¹æ³•çš„æ•´ä½“æ¡†æ¶ï¼Œå…¶ç›®çš„æ˜¯ä¸ºäº†èåˆå„æ¨¡æ€èƒ½åŠ› **[method]** Employing a Multimodal Transformer Network where mode-specific peer branches \(visual, audio, textual\) collaboratively distill learned probabilistic uncertainty into a fusion branch via cross-network attention and noise contrastive estimation.â€¦â€¦ \[ç¿»è¯‘\] å°†ä¸‰ä¸ªç‰¹å®šæ¨¡æ€çš„å¯¹ç­‰åˆ†æ”¯é€šè¿‡è·¨ç½‘ç»œæ³¨æ„åŠ›å’Œå™ªå£°å¯¹æ¯”ä¼°è®¡ï¼ŒååŒåœ°å°†å…¶å­¦ä¹ åˆ°çš„æ¦‚ç‡è’¸é¦åˆ°èåˆåˆ†æ”¯ä¸­ï¼Œæ„å»ºäº†ä¸€ä¸ªæ‹¥æœ‰å››ä¸ªåˆ†æ”¯çš„æ•´ä½“é¢„æµ‹æ¨¡å‹ã€‚\[å€¼å¾—å…³æ³¨\]è§†é¢‘ä½¿ç”¨Tubelet embeddingæŠ€æœ¯ï¼Œå°†è§†é¢‘åˆ‡åˆ†ä¸ºæ—¶ç©ºå°å—ï¼ˆSpatial-Temporal Tubesï¼‰ï¼Œä¿ç•™æ—¶ç©ºä¿¡æ¯ **[conclusion/contribution]** Demonstrates state-of-the-art performance on MOSEI, EmoReact, and ElderReact datasets, achieving an approximate 17% improvement in weighted F1-score during cross-dataset evaluations, thereby validating robustness in age-diverse scenarios. \[ç¿»è¯‘\] åœ¨MOSEIã€EmoReactå’ŒElderReactæ•°æ®é›†ä¸Šæœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè·¨æ•°æ®é›†è¯„ä¼°æœ‰çº¦17%çš„åŠ æƒF1æå‡ï¼Œåœ¨è·¨å¹´é¾„åœºæ™¯ä¸‹å…·æœ‰é²æ£’æ€§ã€‚ **[limitation/future]** The approach necessitates the reduction of complex emotion categories to basic subsets for cross-dataset consistency and entails significant computational overhead due to the spatiotemporal tubelet embedding mechanism. \[ç¿»è¯‘\] ä¸ºäº†ä¿æŒè·¨æ•°æ®é›†ä¸€è‡´æ€§ï¼Œè¦å°†å¤æ‚æƒ…æ„Ÿç±»å½’çº¦ä¸ºåŸºç¡€å­é›†ï¼Œç”±äºé‡‡ç”¨æ—¶ç©ºTubeletåµŒå…¥æœºåˆ¶ï¼Œå¯¼è‡´äº†æ˜¾è‘—çš„è®¡ç®—å¼€é”€">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Addresses the limitations of single-dominant emotion assumptions by tackling the challenge of multi-label emotion co-occurrence and generalization across diverse socio-demographic groups, particularly varying age populations.<br>\[ç¿»è¯‘\] é’ˆå¯¹ç°æœ‰å¤šæ¨¡æ€æ–¹æ³•ä¸»è¦å…³æ³¨å•ä¸€ä¸»å¯¼æƒ…æ„Ÿçš„å±€é™æ€§ï¼Œè¯¥ç ”ç©¶è‡´åŠ›äºè§£å†³æƒ…æ„Ÿæ ‡ç­¾å…±ç°çš„è¯†åˆ«éš¾é¢˜ï¼Œå¹¶æå‡æ¨¡å‹åœ¨ä¸åŒç¤¾ä¼šäººå£ç»Ÿè®¡å­¦ç¾¤ä½“ï¼ˆç‰¹åˆ«æ˜¯ä¸åŒå¹´é¾„æ®µäººç¾¤ï¼‰ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚<br>**[innovation]** å°†å¤šæ¨¡æ€çŸ¥è¯†è’¸é¦ä¸æ ‡ç­¾ä¸€è‡´æ€§æ ¡å‡†æŸå¤±ï¼ˆLCCï¼‰ç›¸ç»“åˆï¼Œå‡è½»äº†æ¨¡å‹å¯¹ç®€å•æ ‡ç­¾çš„è¿‡æ‹Ÿåˆï¼ˆä¿è¯ç½®ä¿¡åº¦ç›¸è¿‘ï¼‰ï¼›æ„å»ºäº†ä¸€ä¸ªåˆ©ç”¨è’¸é¦æ–¹æ³•çš„æ•´ä½“æ¡†æ¶ï¼Œå…¶ç›®çš„æ˜¯ä¸ºäº†èåˆå„æ¨¡æ€èƒ½åŠ›<br>**[method]** Employing a Multimodal Transformer Network where mode-specific peer branches \(visual, audio, textual\) collaboratively distill learned probabilistic uncertainty into a fusion branch via cross-network attention and noise contrastive estimation.â€¦â€¦<br>\[ç¿»è¯‘\] å°†ä¸‰ä¸ªç‰¹å®šæ¨¡æ€çš„å¯¹ç­‰åˆ†æ”¯é€šè¿‡è·¨ç½‘ç»œæ³¨æ„åŠ›å’Œå™ªå£°å¯¹æ¯”ä¼°è®¡ï¼ŒååŒåœ°å°†å…¶å­¦ä¹ åˆ°çš„æ¦‚ç‡è’¸é¦åˆ°èåˆåˆ†æ”¯ä¸­ï¼Œæ„å»ºäº†ä¸€ä¸ªæ‹¥æœ‰å››ä¸ªåˆ†æ”¯çš„æ•´ä½“é¢„æµ‹æ¨¡å‹ã€‚\[å€¼å¾—å…³æ³¨\]è§†é¢‘ä½¿ç”¨Tubelet embeddingæŠ€æœ¯ï¼Œå°†è§†é¢‘åˆ‡åˆ†ä¸ºæ—¶ç©ºå°å—ï¼ˆSpatial-Temporal Tubesï¼‰ï¼Œä¿ç•™æ—¶ç©ºä¿¡æ¯<br>**[conclusion/contribution]** Demonstrates state-of-the-art performance on MOSEI, EmoReact, and ElderReact datasets, achieving an approximate 17% improvement in weighted F1-score during cross-dataset evaluations, thereby validating robustness in age-diverse scenarios.<br>\[ç¿»è¯‘\] åœ¨MOSEIã€EmoReactå’ŒElderReactæ•°æ®é›†ä¸Šæœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè·¨æ•°æ®é›†è¯„ä¼°æœ‰çº¦17%çš„åŠ æƒF1æå‡ï¼Œåœ¨è·¨å¹´é¾„åœºæ™¯ä¸‹å…·æœ‰é²æ£’æ€§ã€‚<br>**[limitation/future]** The approach necessitates the reduction of complex emotion categories to basic subsets for cross-dataset consistency and entails significant computational overhead due to the spatiotemporal tubelet embedding mechanism.<br>\[ç¿»è¯‘\] ä¸ºäº†ä¿æŒè·¨æ•°æ®é›†ä¸€è‡´æ€§ï¼Œè¦å°†å¤æ‚æƒ…æ„Ÿç±»å½’çº¦ä¸ºåŸºç¡€å­é›†ï¼Œç”±äºé‡‡ç”¨æ—¶ç©ºTubeletåµŒå…¥æœºåˆ¶ï¼Œå¯¼è‡´äº†æ˜¾è‘—çš„è®¡ç®—å¼€é”€</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">ã€é¢å‘ç»“æœæ¨¡å‹è®­ç»ƒã€‘\[å¼•ç”¨å¥\]"Transscending the traditional paradigm of identifying single dominant emotions, Anand et al. \[2023\] proposed SeMuL-PCD to enhance the granularity of affective perception in diverse social contexts; by leveraging a collaborative distillation mechanism that calibrates mode-specific feedback, their model robustly disentangles multi-label emotional co-occurrences across varying demographic backgrounds \(e.g., children and the elderly\), thereby providing a more nuanced foundation for socially adaptive agents."<br>\[ç¿»è¯‘\] â€œä¸ºäº†è¶…è¶Šè¯†åˆ«å•ä¸€ä¸»å¯¼æƒ…æ„Ÿçš„ä¼ ç»ŸèŒƒå¼ï¼ŒAnandç­‰äºº\[2023\]æå‡ºäº†SeMuL-PCDï¼Œæ—¨åœ¨å¢å¼ºä¸åŒç¤¾ä¼šè¯­å¢ƒä¸‹æƒ…æ„Ÿæ„ŸçŸ¥çš„ç²’åº¦ï¼›é€šè¿‡åˆ©ç”¨ä¸€ç§æ ¡å‡†æ¨¡æ€ç‰¹å®šåé¦ˆçš„åä½œè’¸é¦æœºåˆ¶ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒçš„äººå£ç»Ÿè®¡èƒŒæ™¯ï¼ˆå¦‚å„¿ç«¥å’Œè€äººï¼‰ä¸‹é²æ£’åœ°è§£è€¦å¤šæ ‡ç­¾æƒ…æ„Ÿçš„å…±ç°å…³ç³»ï¼Œä»è€Œä¸ºå…·å¤‡ç¤¾ä¼šé€‚åº”èƒ½åŠ›çš„æ™ºèƒ½ä½“æä¾›äº†æ›´ç²¾ç»†çš„æƒ…æ„Ÿç†è§£åŸºç¡€ã€‚â€</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/dess-mannheim/temporal-adapters.svg?style=social&label=Star)](https://github.com/dess-mannheim/temporal-adapters) [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Extracting affect aggregates from longitudinal social media data with temporal adapters for large...](https://ojs.aaai.org/index.php/ICWSM/article/view/35801) <br> Georg Ahnert, Max Pellert, David Garcia, Markus Strohmaier <br> 2025-06-07|å¯¹äºæ¯å‘¨ï¼Œè®­ç»ƒä¸€ä¸ªLoRAä½œä¸ºæ—¶é—´é€‚é…å™¨ï¼Œä½¿æ¨¡å‹è·å¾—äº†æ ¹æ®æ—¶é—´æ®µé¢„æµ‹æƒ…æ„Ÿçš„èƒ½åŠ›|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Temporal Adapters.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Temporal Adapters2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Addresses the temporal misalignment inherent in prompt-based in silico surveys and the scalability bottlenecks of traditional affective computing, which heavily relies on resource-intensive labeled datasets or static dictionaries. \[ç¿»è¯‘\] è§£å†³äº†åŸºäºæç¤ºè¯çš„in silicoï¼ˆè®¡ç®—æœºæ¨¡æ‹Ÿï¼‰è°ƒæŸ¥ä¸­å›ºæœ‰çš„æ—¶é—´é”™ä½é—®é¢˜ï¼Œä»¥åŠä¼ ç»Ÿæƒ…æ„Ÿè®¡ç®—ä¸¥é‡ä¾èµ–èµ„æºå¯†é›†å‹æ ‡æ³¨æ•°æ®é›†æˆ–é™æ€è¯å…¸çš„å¯æ‰©å±•æ€§ç“¶é¢ˆ **[innovation]** åˆ©ç”¨LoRAä½œä¸ºæ¨¡å—åŒ–å­¦ä¹ å…ƒä»¶çš„â€œæ—¶é—´é€‚é…å™¨â€ï¼Œä»¥æ•æ‰ç‰¹å®šæ—¶æœŸç‹¬æœ‰çš„æ—¶é—´ä¸è¯­è¨€ç‰¹å¾ã€‚é€šè¿‡å°†è¿™äº›è½»é‡çº§é€‚é…å™¨ä¸å†»ç»“åŸºåº§æ¨¡å‹çš„å›ºæœ‰æ¨ç†èƒ½åŠ›äº§ç”ŸååŒä½œç”¨ï¼Œè¯¥æ¡†æ¶å®ç°äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„çºµå‘æƒ…æ„Ÿé¢„æµ‹ã€‚ **[method]** Employs a two-stage framework: first, fine-tuning weekly LoRA adapters on longitudinal Twitter timelines via a self-supervised causal language modeling objective; second, probing the adapted models with standard psychometric questionnaires to extract aggregate affect via token probability distributions. \[ç¿»è¯‘\] é‡‡ç”¨åŒé˜¶æ®µæ¡†æ¶ï¼šé¦–å…ˆï¼Œé€šè¿‡è‡ªç›‘ç£çš„å› æœè¯­è¨€å»ºæ¨¡ç›®æ ‡åœ¨çºµå‘Twitteræ—¶é—´çº¿ä¸Šå¾®è°ƒæ¯å‘¨çš„LoRAé€‚é…å™¨ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨æ ‡å‡†å¿ƒç†æµ‹é‡é—®å·æ¢æµ‹é€‚é…åçš„æ¨¡å‹ï¼Œé€šè¿‡Tokenæ¦‚ç‡åˆ†å¸ƒæå–èšåˆæƒ…æ„Ÿ \[é€šä¿—æ ¸å¿ƒ\]åœ¨æ¯å‘¨åˆ†åˆ«è¿›è¡ŒLoRAè‡ªç›‘ç£å¾®è°ƒï¼Œè®©æ¨¡å‹çš„é¢„æµ‹å°½å¯èƒ½å’ŒåŸæ•°æ®ä¸€æ ·ã€‚ä½¿ç”¨ä¸“ä¸šé—®å·ä½œä¸ºpromptï¼Œæ¨¡æ‹Ÿæ¨¡å‹å›ç­”é—®å·ï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªæƒ…æ„Ÿæ¦‚ç‡éšæ—¶é—´çš„åˆ†å¸ƒï¼Œä¸å…¬ä¼—çœŸå®åˆ†å¸ƒå¯¹æ¯” **[conclusion/contribution]** Demonstrates strong, significant correlations with representative polling data \(YouGov\) during the COVID-19 pandemic, achieving performance comparable to supervised baselines \(e.g., TweetNLP\) while offering superior flexibility in querying diverse and complex collective attitudes. \[ç¿»è¯‘\] å±•ç¤ºäº†åœ¨COVID-19å¤§æµè¡ŒæœŸé—´ä¸ä»£è¡¨æ€§æ°‘è°ƒæ•°æ®ï¼ˆYouGovï¼‰çš„å¼ºæ˜¾è‘—ç›¸å…³æ€§ï¼Œå®ç°äº†ä¸ç›‘ç£åŸºçº¿æ¨¡å‹ï¼ˆå¦‚TweetNLPï¼‰ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶åœ¨æŸ¥è¯¢å¤šæ ·åŒ–ä¸”å¤æ‚çš„é›†ä½“æ€åº¦æ–¹é¢æä¾›äº†æ›´ä¼˜è¶Šçš„çµæ´»æ€§ã€‚ **[limitation/future]** Primarily effective for longitudinal trend analysis rather than absolute cross-sectional calibration, and the representativeness of the emergent sentiment is constrained by the demographic biases inherent in the social media training corpora. \[ç¿»è¯‘\] ä¸»è¦åœ¨çºµå‘è¶‹åŠ¿åˆ†æè€Œéç»å¯¹æ¨ªæˆªé¢æ ¡å‡†æ–¹é¢æœ‰æ•ˆï¼Œä¸”æ¶Œç°å‡ºçš„æƒ…æ„Ÿä»£è¡¨æ€§å—é™äºç¤¾äº¤åª’ä½“è®­ç»ƒè¯­æ–™åº“ä¸­å›ºæœ‰çš„äººå£ç»Ÿè®¡å­¦åå·®">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Addresses the temporal misalignment inherent in prompt-based in silico surveys and the scalability bottlenecks of traditional affective computing, which heavily relies on resource-intensive labeled datasets or static dictionaries.<br>\[ç¿»è¯‘\] è§£å†³äº†åŸºäºæç¤ºè¯çš„in silicoï¼ˆè®¡ç®—æœºæ¨¡æ‹Ÿï¼‰è°ƒæŸ¥ä¸­å›ºæœ‰çš„æ—¶é—´é”™ä½é—®é¢˜ï¼Œä»¥åŠä¼ ç»Ÿæƒ…æ„Ÿè®¡ç®—ä¸¥é‡ä¾èµ–èµ„æºå¯†é›†å‹æ ‡æ³¨æ•°æ®é›†æˆ–é™æ€è¯å…¸çš„å¯æ‰©å±•æ€§ç“¶é¢ˆ<br>**[innovation]** åˆ©ç”¨LoRAä½œä¸ºæ¨¡å—åŒ–å­¦ä¹ å…ƒä»¶çš„â€œæ—¶é—´é€‚é…å™¨â€ï¼Œä»¥æ•æ‰ç‰¹å®šæ—¶æœŸç‹¬æœ‰çš„æ—¶é—´ä¸è¯­è¨€ç‰¹å¾ã€‚é€šè¿‡å°†è¿™äº›è½»é‡çº§é€‚é…å™¨ä¸å†»ç»“åŸºåº§æ¨¡å‹çš„å›ºæœ‰æ¨ç†èƒ½åŠ›äº§ç”ŸååŒä½œç”¨ï¼Œè¯¥æ¡†æ¶å®ç°äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„çºµå‘æƒ…æ„Ÿé¢„æµ‹ã€‚<br>**[method]** Employs a two-stage framework: first, fine-tuning weekly LoRA adapters on longitudinal Twitter timelines via a self-supervised causal language modeling objective; second, probing the adapted models with standard psychometric questionnaires to extract aggregate affect via token probability distributions.<br>\[ç¿»è¯‘\] é‡‡ç”¨åŒé˜¶æ®µæ¡†æ¶ï¼šé¦–å…ˆï¼Œé€šè¿‡è‡ªç›‘ç£çš„å› æœè¯­è¨€å»ºæ¨¡ç›®æ ‡åœ¨çºµå‘Twitteræ—¶é—´çº¿ä¸Šå¾®è°ƒæ¯å‘¨çš„LoRAé€‚é…å™¨ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨æ ‡å‡†å¿ƒç†æµ‹é‡é—®å·æ¢æµ‹é€‚é…åçš„æ¨¡å‹ï¼Œé€šè¿‡Tokenæ¦‚ç‡åˆ†å¸ƒæå–èšåˆæƒ…æ„Ÿ<br>\[é€šä¿—æ ¸å¿ƒ\]åœ¨æ¯å‘¨åˆ†åˆ«è¿›è¡ŒLoRAè‡ªç›‘ç£å¾®è°ƒï¼Œè®©æ¨¡å‹çš„é¢„æµ‹å°½å¯èƒ½å’ŒåŸæ•°æ®ä¸€æ ·ã€‚ä½¿ç”¨ä¸“ä¸šé—®å·ä½œä¸ºpromptï¼Œæ¨¡æ‹Ÿæ¨¡å‹å›ç­”é—®å·ï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªæƒ…æ„Ÿæ¦‚ç‡éšæ—¶é—´çš„åˆ†å¸ƒï¼Œä¸å…¬ä¼—çœŸå®åˆ†å¸ƒå¯¹æ¯”<br>**[conclusion/contribution]** Demonstrates strong, significant correlations with representative polling data \(YouGov\) during the COVID-19 pandemic, achieving performance comparable to supervised baselines \(e.g., TweetNLP\) while offering superior flexibility in querying diverse and complex collective attitudes.<br>\[ç¿»è¯‘\] å±•ç¤ºäº†åœ¨COVID-19å¤§æµè¡ŒæœŸé—´ä¸ä»£è¡¨æ€§æ°‘è°ƒæ•°æ®ï¼ˆYouGovï¼‰çš„å¼ºæ˜¾è‘—ç›¸å…³æ€§ï¼Œå®ç°äº†ä¸ç›‘ç£åŸºçº¿æ¨¡å‹ï¼ˆå¦‚TweetNLPï¼‰ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶åœ¨æŸ¥è¯¢å¤šæ ·åŒ–ä¸”å¤æ‚çš„é›†ä½“æ€åº¦æ–¹é¢æä¾›äº†æ›´ä¼˜è¶Šçš„çµæ´»æ€§ã€‚<br>**[limitation/future]** Primarily effective for longitudinal trend analysis rather than absolute cross-sectional calibration, and the representativeness of the emergent sentiment is constrained by the demographic biases inherent in the social media training corpora.<br>\[ç¿»è¯‘\] ä¸»è¦åœ¨çºµå‘è¶‹åŠ¿åˆ†æè€Œéç»å¯¹æ¨ªæˆªé¢æ ¡å‡†æ–¹é¢æœ‰æ•ˆï¼Œä¸”æ¶Œç°å‡ºçš„æƒ…æ„Ÿä»£è¡¨æ€§å—é™äºç¤¾äº¤åª’ä½“è®­ç»ƒè¯­æ–™åº“ä¸­å›ºæœ‰çš„äººå£ç»Ÿè®¡å­¦åå·®</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">ã€é›†ä½“æƒ…æ„Ÿåˆ†æã€‘é€šè¿‡LoRAè‡ªç›‘ç£å­¦åˆ°çš„æ˜¯è¯¥ç‰¹å®šæ—¶é—´æ®µå†…å…¬ä¼—çš„è¯­è¨€é£æ ¼å’Œå…³æ³¨ç‚¹ï¼Œç»“åˆåŸºç¡€æ¨¡å‹çš„å›ºæœ‰èƒ½åŠ›è·å¾—äº†é¢„æµ‹ç‰¹å®šæ—¶é—´å†…å…¬ä¼—æƒ…æ„Ÿçš„èƒ½åŠ›ï¼Œå¾ˆç¥å¥‡ï¼Œè¿™æ˜¯ä¸€ä¸ªé€šç”¨æ–¹æ³•<br>\[å¼•ç”¨æ–‡\]Moving beyond traditional supervised classifiers, Ahnert et al. \(2025\) demonstrate a shift toward the social simulation paradigm by proposing Temporal Adapters. Instead of training models to explicitly recognize emotion patterns, they utilize self-supervised learning to train lightweight LoRA modules as learning components, aligning the frozen LLM with specific temporal and linguistic contexts derived from longitudinal social media data. This equips the model with the capability to predict public sentiment within specific timeframes. Their approach validates that scalable and accurate tracking of public opinion dynamic<br>\[ç¿»è¯‘\]<br>è¶…è¶Šäº†ä¼ ç»Ÿçš„ç›‘ç£åˆ†ç±»å™¨ï¼ŒAhnertç­‰äºº \(2025\) é€šè¿‡æå‡º â€œæ—¶é—´é€‚é…å™¨â€ å±•ç¤ºäº†å‘ç¤¾ä¼šä»¿çœŸèŒƒå¼çš„è½¬å˜ã€‚ä»–ä»¬ä¸å†è®­ç»ƒæ¨¡å‹å»æ˜¾å¼åœ°è¯†åˆ«æƒ…æ„Ÿæ¨¡å¼ï¼Œè€Œæ˜¯é€šè¿‡è‡ªç›‘ç£å­¦ä¹ è®­ç»ƒè½»é‡çº§çš„LoRAæ¨¡å—ä½œä¸ºå­¦ä¹ å…ƒä»¶ï¼Œå°†å†»ç»“çš„å¤§è¯­è¨€æ¨¡å‹ä¸æºè‡ªçºµå‘ç¤¾äº¤åª’ä½“æ•°æ®çš„ç‰¹å®šæ—¶é—´åŠè¯­è¨€è¯­å¢ƒç›¸å¯¹é½ã€‚ä½¿æ¨¡å‹è·å¾—äº†é¢„æµ‹ç‰¹å®šæ—¶é—´å†…å…¬ä¼—æƒ…æ„Ÿçš„èƒ½åŠ›ã€‚ä»–ä»¬çš„æ–¹æ³•è¯å®ï¼Œé€šè¿‡æ—¶é—´å¯¹é½è€Œéæ ‡ç­¾ç›‘ç£ï¼Œå³å¯å®ç°å¯¹æ°‘æ„åŠ¨æ€çš„å¯æ‰©å±•ä¸”å‡†ç¡®çš„è¿½è¸ªã€‚</div></details></div></div>|

### Malicious User Detection (1 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[BotSim: LLM-Powered Malicious Social Botnet Simulation](https://ojs.aaai.org/index.php/AAAI/article/view/33575) <br> Boyu Qiao, Kun Li\*, Wei Zhou, Shilong Li, Qianqian Lu, Songlin Hu <br> 2025-04-11|\[AI generated\] BotSim is like a digital petri dish for cultivating and studying intelligent malicious bots. \[ç¿»è¯‘\] BotSimå¦‚åŒä¸€ä¸ªæ•°å­—åŸ¹å…»çš¿ï¼Œç”¨äºåŸ¹è‚²å’Œç ”ç©¶æ™ºèƒ½æ¶æ„æœºå™¨äººã€‚|| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** \[AI generated\] To simulate and study the threat of LLM-powered malicious social botnets for improved detection. \[ç¿»è¯‘\] æ¨¡æ‹Ÿå’Œç ”ç©¶ç”±å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ¶æ„ç¤¾äº¤åƒµå°¸ç½‘ç»œçš„å¨èƒï¼Œä»¥æ”¹è¿›æ£€æµ‹ã€‚ **[innovation]** \[AI generated\] Proposes BotSim, an LLM-powered framework for simulating intelligent malicious botnets and generating realistic datasets for detection benchmarking. \[ç¿»è¯‘\] æå‡ºäº†BotSimï¼Œä¸€ä¸ªåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿæ™ºèƒ½æ¶æ„åƒµå°¸ç½‘ç»œå¹¶ç”Ÿæˆç”¨äºæ£€æµ‹åŸºå‡†æµ‹è¯•çš„çœŸå®æ•°æ®é›†çš„æ¡†æ¶ã€‚ **[method]** \[AI generated\] Proposes BotSim, an LLM-powered simulation framework that creates a virtual social network of intelligent agent bots and human users to model malicious botnet behavior and information dissemination patterns. \[ç¿»è¯‘\] æå‡ºäº†BotSimï¼Œä¸€ä¸ªç”±å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ä»¿çœŸæ¡†æ¶ï¼Œå®ƒåˆ›å»ºä¸€ä¸ªç”±æ™ºèƒ½ä»£ç†æœºå™¨äººå’ŒçœŸå®ç”¨æˆ·ç»„æˆçš„è™šæ‹Ÿç¤¾äº¤ç½‘ç»œï¼Œä»¥æ¨¡æ‹Ÿæ¶æ„åƒµå°¸ç½‘ç»œçš„è¡Œä¸ºå’Œä¿¡æ¯ä¼ æ’­æ¨¡å¼ã€‚ **[conclusion/contribution]** \[AI generated\] BotSim-24, a highly human-like bot dataset, reveals that traditional bot detection methods underperform against advanced LLM-powered bots, underscoring the need for new detection strategies. \[ç¿»è¯‘\] BotSim-24æ˜¯ä¸€ä¸ªé«˜åº¦ç±»äººçš„æœºå™¨äººæ•°æ®é›†ï¼Œå®ƒè¡¨æ˜ä¼ ç»Ÿçš„æœºå™¨äººæ£€æµ‹æ–¹æ³•åœ¨é¢å¯¹å…ˆè¿›çš„LLMé©±åŠ¨çš„æœºå™¨äººæ—¶è¡¨ç°ä¸ä½³ï¼Œå‡¸æ˜¾äº†å¯¹æ–°æ£€æµ‹ç­–ç•¥çš„éœ€æ±‚ã€‚ **[limitation/future]** \[AI generated\] The simulation relies on LLM capabilities and lacks real-world deployment validation. \[ç¿»è¯‘\] æ•´ä¸ªæ¨¡æ‹Ÿä¾èµ–LLMèƒ½åŠ›ï¼Œç¼ºä¹çœŸå®ä¸–ç•Œéƒ¨ç½²éªŒè¯ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** \[AI generated\] To simulate and study the threat of LLM-powered malicious social botnets for improved detection.<br>\[ç¿»è¯‘\]<br>æ¨¡æ‹Ÿå’Œç ”ç©¶ç”±å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ¶æ„ç¤¾äº¤åƒµå°¸ç½‘ç»œçš„å¨èƒï¼Œä»¥æ”¹è¿›æ£€æµ‹ã€‚<br>**[innovation]** \[AI generated\] Proposes BotSim, an LLM-powered framework for simulating intelligent malicious botnets and generating realistic datasets for detection benchmarking.<br>\[ç¿»è¯‘\]<br>æå‡ºäº†BotSimï¼Œä¸€ä¸ªåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿæ™ºèƒ½æ¶æ„åƒµå°¸ç½‘ç»œå¹¶ç”Ÿæˆç”¨äºæ£€æµ‹åŸºå‡†æµ‹è¯•çš„çœŸå®æ•°æ®é›†çš„æ¡†æ¶ã€‚<br>**[method]** \[AI generated\] Proposes BotSim, an LLM-powered simulation framework that creates a virtual social network of intelligent agent bots and human users to model malicious botnet behavior and information dissemination patterns.<br>\[ç¿»è¯‘\]<br>æå‡ºäº†BotSimï¼Œä¸€ä¸ªç”±å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ä»¿çœŸæ¡†æ¶ï¼Œå®ƒåˆ›å»ºä¸€ä¸ªç”±æ™ºèƒ½ä»£ç†æœºå™¨äººå’ŒçœŸå®ç”¨æˆ·ç»„æˆçš„è™šæ‹Ÿç¤¾äº¤ç½‘ç»œï¼Œä»¥æ¨¡æ‹Ÿæ¶æ„åƒµå°¸ç½‘ç»œçš„è¡Œä¸ºå’Œä¿¡æ¯ä¼ æ’­æ¨¡å¼ã€‚<br>**[conclusion/contribution]** \[AI generated\] BotSim-24, a highly human-like bot dataset, reveals that traditional bot detection methods underperform against advanced LLM-powered bots, underscoring the need for new detection strategies.<br>\[ç¿»è¯‘\]<br>BotSim-24æ˜¯ä¸€ä¸ªé«˜åº¦ç±»äººçš„æœºå™¨äººæ•°æ®é›†ï¼Œå®ƒè¡¨æ˜ä¼ ç»Ÿçš„æœºå™¨äººæ£€æµ‹æ–¹æ³•åœ¨é¢å¯¹å…ˆè¿›çš„LLMé©±åŠ¨çš„æœºå™¨äººæ—¶è¡¨ç°ä¸ä½³ï¼Œå‡¸æ˜¾äº†å¯¹æ–°æ£€æµ‹ç­–ç•¥çš„éœ€æ±‚ã€‚<br>**[limitation/future]** \[AI generated\] The simulation relies on LLM capabilities and lacks real-world deployment validation. \[ç¿»è¯‘\] æ•´ä¸ªæ¨¡æ‹Ÿä¾èµ–LLMèƒ½åŠ›ï¼Œç¼ºä¹çœŸå®ä¸–ç•Œéƒ¨ç½²éªŒè¯ã€‚</div></details></div>|

### | Understanding (6 papers)


### Event Extraction (6 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%202023%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing-blue)]()<br>[Event causality extraction via implicit cause-effect interactions](https://aclanthology.org/2023.emnlp-main.420) <br> Jintao Liu,Zequn Zhang,Kaiwen Wei,Zhi Guo,Xian Sun,Li Jin,Xiaoyu Li <br> 2023|é€šè¿‡OTå¼ºåˆ¶å­¦ç”Ÿæ¨¡å‹ä¸æ•™å¸ˆæ¨¡å‹å¯¹é½|<img width="1200" alt="pipeline" src="figures/ICE.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** ç°æœ‰ECEï¼ˆäº‹ä»¶å› æœå…³ç³»æŠ½å–ï¼‰æ–¹å¼æ²¡æœ‰å……åˆ†åˆ©ç”¨åŸå› äº‹ä»¶å’Œç»“æœäº‹ä»¶ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚è¿™æœ¬å¯ä»¥ä¸ºå› æœå…³ç³»æ¨ç†æä¾›å…³é”®çº¿ç´¢ **[innovation]** è®ºæ–‡è§£è€¦ECEçš„ä¸¤ä¸ªä»»åŠ¡ï¼ˆè®ºå…ƒæŠ½å–ã€ç»“æœäº‹ä»¶é¢„æµ‹ï¼‰ï¼Œå¹¶ä½¿ç”¨OTè¿›è¡Œæ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹çš„ç»†ç²’åº¦å¯¹é½ï¼Œå¢å¼ºäº†å› æœäº‹ä»¶ä¹‹é—´çš„éšå¼è”ç³» **[method]** åŸºäºæ¨¡æ¿çš„æ¡ä»¶ç”Ÿæˆï¼ˆè¾“å…¥åŸºäºæ¨¡æ¿é™„æœ‰ç‰¹å®šç‰¹æƒä¿¡æ¯çš„promptï¼Œä½¿é¢„è®­ç»ƒæ¨¡å‹BARTï¼ˆåŸºäºtransformerï¼‰è¾“å‡ºåŸºäºæ¨¡æ¿çš„ç»“æ„åŒ–çš„æ–‡æœ¬ï¼Œç”¨äºåç»­å¾®è°ƒï¼‰-&gt;æ•™å¸ˆ-å­¦ç”ŸçŸ¥è¯†è’¸é¦ï¼ˆå¾®è°ƒäº†ä¸¤ä¸ªæ•™å¸ˆæ¨¡å‹è´Ÿè´£ä¸åŒä»»åŠ¡ï¼šäº‹ä»¶è®ºå…ƒæŠ½å–ã€ç»“æœäº‹ä»¶é¢„æµ‹ï¼‰-&gt;å› æœæœ€ä¼˜ä¼ è¾“CEOTï¼ˆç›¸å…³æŸå¤±å¹¶å…¥è’¸é¦æŸå¤±ï¼Œå‚ä¸è’¸é¦è®­ç»ƒï¼Œå­¦ç”Ÿæ¨¡å‹ä¸æ•™å¸ˆæ¨¡å‹ç»†ç²’åº¦å¯¹é½ï¼‰ **[conclusion/contribution]** ECEä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼ŒECE-CCKSæ•°æ®é›†ä¸Šæ¯”æ­¤å‰æœ€ä¼˜æ–¹æ³•F1å€¼æé«˜äº†8.39% **[limitation/future]** å¤šæ•™å¸ˆè’¸é¦æœºåˆ¶å’Œå¤æ‚çš„OTè®¡ç®—æ˜¾è‘—å¢åŠ äº†æ¨¡å‹è®­ç»ƒé˜¶æ®µçš„æˆæœ¬">**[summary]**</summary><div style="margin-top:6px">**[motivation]** ç°æœ‰ECEï¼ˆäº‹ä»¶å› æœå…³ç³»æŠ½å–ï¼‰æ–¹å¼æ²¡æœ‰å……åˆ†åˆ©ç”¨åŸå› äº‹ä»¶å’Œç»“æœäº‹ä»¶ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚è¿™æœ¬å¯ä»¥ä¸ºå› æœå…³ç³»æ¨ç†æä¾›å…³é”®çº¿ç´¢<br>**[innovation]** è®ºæ–‡è§£è€¦ECEçš„ä¸¤ä¸ªä»»åŠ¡ï¼ˆè®ºå…ƒæŠ½å–ã€ç»“æœäº‹ä»¶é¢„æµ‹ï¼‰ï¼Œå¹¶ä½¿ç”¨OTè¿›è¡Œæ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹çš„ç»†ç²’åº¦å¯¹é½ï¼Œå¢å¼ºäº†å› æœäº‹ä»¶ä¹‹é—´çš„éšå¼è”ç³»<br>**[method]** åŸºäºæ¨¡æ¿çš„æ¡ä»¶ç”Ÿæˆï¼ˆè¾“å…¥åŸºäºæ¨¡æ¿é™„æœ‰ç‰¹å®šç‰¹æƒä¿¡æ¯çš„promptï¼Œä½¿é¢„è®­ç»ƒæ¨¡å‹BARTï¼ˆåŸºäºtransformerï¼‰è¾“å‡ºåŸºäºæ¨¡æ¿çš„ç»“æ„åŒ–çš„æ–‡æœ¬ï¼Œç”¨äºåç»­å¾®è°ƒï¼‰->æ•™å¸ˆ-å­¦ç”ŸçŸ¥è¯†è’¸é¦ï¼ˆå¾®è°ƒäº†ä¸¤ä¸ªæ•™å¸ˆæ¨¡å‹è´Ÿè´£ä¸åŒä»»åŠ¡ï¼šäº‹ä»¶è®ºå…ƒæŠ½å–ã€ç»“æœäº‹ä»¶é¢„æµ‹ï¼‰->å› æœæœ€ä¼˜ä¼ è¾“CEOTï¼ˆç›¸å…³æŸå¤±å¹¶å…¥è’¸é¦æŸå¤±ï¼Œå‚ä¸è’¸é¦è®­ç»ƒï¼Œå­¦ç”Ÿæ¨¡å‹ä¸æ•™å¸ˆæ¨¡å‹ç»†ç²’åº¦å¯¹é½ï¼‰<br>**[conclusion/contribution]** ECEä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼ŒECE-CCKSæ•°æ®é›†ä¸Šæ¯”æ­¤å‰æœ€ä¼˜æ–¹æ³•F1å€¼æé«˜äº†8.39%<br>**[limitation/future]** å¤šæ•™å¸ˆè’¸é¦æœºåˆ¶å’Œå¤æ‚çš„OTè®¡ç®—æ˜¾è‘—å¢åŠ äº†æ¨¡å‹è®­ç»ƒé˜¶æ®µçš„æˆæœ¬</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">â”è¿™ä¸ªæ–¹æ³•ä¸ºä»€ä¹ˆå¯ä»¥è§£å†³é—®é¢˜ï¼Ÿ<br>    æ ¸å¿ƒæ–¹æ³•æ˜¯ä½¿ç”¨ä¼˜ç§€çš„ä¸“å®¶æ¨¡å‹å¯¹å°æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œç»“åˆäº†5ä¸ªå°æŸå¤±å‡½æ•°ï¼ˆä¸¤ä¸ªæ¥æºäºOTï¼‰ï¼Œä»¥å°½å¯èƒ½ä¿è¯çŸ¥è¯†è¿ç§»æ•ˆæœ<br><br>â”æœ‰ä»€ä¹ˆå€¼å¾—æ³¨æ„çš„ç»†èŠ‚å—ï¼Ÿ<br>    ğŸ“è®ºæ–‡ä¸ºä»€ä¹ˆé€‰æ‹©è®­ç»ƒä¸¤ä¸ªæ‰¿æ‹…ä¸åŒä»»åŠ¡çš„æ•™å¸ˆæ¨¡å‹ï¼Œä¸€èµ·è’¸é¦å‡ºç›®æ ‡æ¨¡å‹çš„æ–¹æ³•<br>        è¿™å‡ ä¹æ˜¯è¿›è¡Œå¾®è°ƒç‰¹åŒ–ç”¨äºè¯¥ä¸‹æ¸¸ä»»åŠ¡çš„å¿…ç„¶é€‰æ‹©<br>        å› ä¸ºéœ€è¦è®­ç»ƒä¸¤ä¸ªèƒ½åŠ›ï¼ˆå­ä»»åŠ¡ï¼‰ï¼šæ–‡æœ¬è®ºå…ƒæŠ½å–èƒ½åŠ›ï¼ˆäº‹ä»¶å†…äº¤äº’ï¼‰å’Œäº‹ä»¶ç»“æœè”ç³»èƒ½åŠ›ï¼ˆäº‹ä»¶é—´ï¼‰<br>        ä¸¤ä¸ªå­ä»»åŠ¡éœ€è¦åˆ†åˆ«è°ƒæ•´æ•°æ®é›†çš„è¾“å…¥ï¼Œä¸ºä»–ä»¬åˆ†é…ä¸åŒçš„ç‰¹æƒä¿¡æ¯ï¼Œä»è€Œé¿å…æ··æ·†å’Œå‡ºç°â€œä½œå¼Šâ€ï¼ˆçœ‹åˆ°è¿™ä¸ªå­ä»»åŠ¡ä¸åº”çœ‹åˆ°çš„ç‰¹æƒä¿¡æ¯ï¼‰</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/social-info-lab/disaster_event_analysis.svg?style=social&label=Star)](https://github.com/social-info-lab/disaster_event_analysis) [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Identifying and Investigating Global News Coverage of Critical Events Such as Disasters and Terro...](https://ojs.aaai.org/index.php/ICWSM/article/view/35818) <br> Erica Cai1,Xi Chen1,Reagan Grey Keeney1,Ethan Zuckerman1,Brendan O'Connor1,Przemyslaw A.Grabowicz <br> 2025-06-07|ä¸¤çº§åŒ¹é…ç­›é€‰è¦æ±‚æ–°é—»ï¼Œå…³é”®è¯åŒ¹é…åˆæ­¥ç­›é€‰ï¼ˆå…³é”®è¯é€šè¿‡å¯å‘å¼æ–¹æ³•è·å¾—ï¼‰->äº‹ä»¶æŠ½å–|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/FAME.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/FAME2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Traditional computational studies of news coverage bias are hindered by the inability to efficiently and accurately identify articles discussing the same real-world event across massive, multilingual corpora without costly, language-specific training data. \[ç¿»è¯‘\] ä¼ ç»Ÿçš„æ–°é—»è¦†ç›–åè§è®¡ç®—ç ”ç©¶é¢ä¸´ä¸€ä¸ªç“¶é¢ˆï¼šéš¾ä»¥åœ¨ä¸ä¾èµ–æ˜‚è´µä¸”è¯­è¨€ç‰¹å®šçš„è®­ç»ƒæ•°æ®å‰æä¸‹ï¼Œé«˜æ•ˆã€ç²¾ç¡®åœ°ä»å¤§è§„æ¨¡å¤šè¯­è¨€è¯­æ–™åº“ä¸­è¯†åˆ«å‡ºè®¨è®ºåŒä¸€ç°å®äº‹ä»¶çš„æŠ¥é“ã€‚ **[innovation]** It introduces FAME, a scalable, zero-shot framework that utilizes minimalist â€œevent fingerprintsâ€ \(time, location, class\) to match news articles across languages via a two-stage screening pipeline, eliminating the need for annotated training data. \[ç¿»è¯‘\] å…¶æå‡ºäº†FAMEæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªå¯æ‰©å±•çš„é›¶æ ·æœ¬æ–¹æ³•ã€‚å®ƒåˆ©ç”¨æç®€çš„â€œäº‹ä»¶æŒ‡çº¹â€ï¼ˆæ—¶é—´ã€åœ°ç‚¹ã€ç±»åˆ«ï¼‰ï¼Œé€šè¿‡ä¸€ä¸ªä¸¤çº§ç­›é€‰æµç¨‹å®ç°è·¨è¯­è¨€æ–°é—»æ–‡ç« åŒ¹é…ï¼Œä»è€Œæ— éœ€æ ‡æ³¨è®­ç»ƒæ•°æ®ã€‚ **[method]** The method employs a two-stage pipeline: 1\) Heuristic keyword filtering to recall candidate articles within a time window, followed by 2\) a semantic filter using a large language model \(LLM\) for question-answering to achieve high-precision event-article matching. \[ç¿»è¯‘\] è¯¥æ–¹æ³•é‡‡ç”¨ä¸€ä¸ªä¸¤çº§å¤„ç†æµç¨‹ï¼š1ï¼‰åŸºäºå…³é”®è¯çš„å¯å‘å¼è¿‡æ»¤ï¼Œç”¨äºåœ¨æ—¶é—´çª—å£å†…å¬å›å€™é€‰æ–‡ç« ï¼›2ï¼‰åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œé—®ç­”çš„è¯­ä¹‰è¿‡æ»¤å™¨ï¼Œä»¥å®ç°é«˜ç²¾åº¦çš„äº‹ä»¶-æ–‡ç« åŒ¹é…ã€‚ **[conclusion/contribution]** FAME achieved state-of-the-art performance \(average F1 &gt; 94% across English, Spanish, and French\), and its application revealed that media attention to disasters and terrorist attacks is strongly correlated with death tolls, the GDP of the affected country, and bilateral trade volume. \[ç¿»è¯‘\] FAMEå–å¾—äº†å…ˆè¿›çš„æ€§èƒ½ï¼ˆåœ¨è‹±ã€è¥¿ã€æ³•è¯­ä¸Šå¹³å‡F1&gt;94%ï¼‰ã€‚åº”ç”¨è¯¥æ–¹æ³•å‘ç°ï¼Œåª’ä½“å¯¹ç¾å®³å’Œææ€–è¢­å‡»çš„å…³æ³¨åº¦ï¼Œä¸æ­»äº¡äººæ•°ã€å—å½±å“å›½å®¶çš„GDPä»¥åŠåŒè¾¹è´¸æ˜“é¢é«˜åº¦ç›¸å…³ã€‚ **[limitation/future]** The reliance on a two-stage screening pipeline depends on the quality of external event databases \(e.g., GTD\), and the minimalist fingerprint design, while enabling scalability, can lead to ambiguities for events with similar metadata. \[ç¿»è¯‘\] ä¸¤çº§ç­›é€‰æµç¨‹ä¾èµ–äºå¤–éƒ¨äº‹ä»¶æ•°æ®åº“ï¼ˆå¦‚GTDï¼‰çš„è´¨é‡ï¼Œä¸”æç®€çš„æŒ‡çº¹è®¾è®¡è™½ç„¶ä¿è¯äº†å¯æ‰©å±•æ€§ï¼Œä½†å¯èƒ½å¯¼è‡´å…·æœ‰ç›¸ä¼¼å…ƒæ•°æ®çš„äº‹ä»¶äº§ç”ŸåŒ¹é…æ­§ä¹‰ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Traditional computational studies of news coverage bias are hindered by the inability to efficiently and accurately identify articles discussing the same real-world event across massive, multilingual corpora without costly, language-specific training data.<br>\[ç¿»è¯‘\] ä¼ ç»Ÿçš„æ–°é—»è¦†ç›–åè§è®¡ç®—ç ”ç©¶é¢ä¸´ä¸€ä¸ªç“¶é¢ˆï¼šéš¾ä»¥åœ¨ä¸ä¾èµ–æ˜‚è´µä¸”è¯­è¨€ç‰¹å®šçš„è®­ç»ƒæ•°æ®å‰æä¸‹ï¼Œé«˜æ•ˆã€ç²¾ç¡®åœ°ä»å¤§è§„æ¨¡å¤šè¯­è¨€è¯­æ–™åº“ä¸­è¯†åˆ«å‡ºè®¨è®ºåŒä¸€ç°å®äº‹ä»¶çš„æŠ¥é“ã€‚<br>**[innovation]** It introduces FAME, a scalable, zero-shot framework that utilizes minimalist â€œevent fingerprintsâ€ \(time, location, class\) to match news articles across languages via a two-stage screening pipeline, eliminating the need for annotated training data.<br>\[ç¿»è¯‘\] å…¶æå‡ºäº†FAMEæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªå¯æ‰©å±•çš„é›¶æ ·æœ¬æ–¹æ³•ã€‚å®ƒåˆ©ç”¨æç®€çš„â€œäº‹ä»¶æŒ‡çº¹â€ï¼ˆæ—¶é—´ã€åœ°ç‚¹ã€ç±»åˆ«ï¼‰ï¼Œé€šè¿‡ä¸€ä¸ªä¸¤çº§ç­›é€‰æµç¨‹å®ç°è·¨è¯­è¨€æ–°é—»æ–‡ç« åŒ¹é…ï¼Œä»è€Œæ— éœ€æ ‡æ³¨è®­ç»ƒæ•°æ®ã€‚<br>**[method]** The method employs a two-stage pipeline: 1\) Heuristic keyword filtering to recall candidate articles within a time window, followed by 2\) a semantic filter using a large language model \(LLM\) for question-answering to achieve high-precision event-article matching.<br>\[ç¿»è¯‘\] è¯¥æ–¹æ³•é‡‡ç”¨ä¸€ä¸ªä¸¤çº§å¤„ç†æµç¨‹ï¼š1ï¼‰åŸºäºå…³é”®è¯çš„å¯å‘å¼è¿‡æ»¤ï¼Œç”¨äºåœ¨æ—¶é—´çª—å£å†…å¬å›å€™é€‰æ–‡ç« ï¼›2ï¼‰åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œé—®ç­”çš„è¯­ä¹‰è¿‡æ»¤å™¨ï¼Œä»¥å®ç°é«˜ç²¾åº¦çš„äº‹ä»¶-æ–‡ç« åŒ¹é…ã€‚<br>**[conclusion/contribution]** FAME achieved state-of-the-art performance \(average F1 > 94% across English, Spanish, and French\), and its application revealed that media attention to disasters and terrorist attacks is strongly correlated with death tolls, the GDP of the affected country, and bilateral trade volume.<br>\[ç¿»è¯‘\] FAMEå–å¾—äº†å…ˆè¿›çš„æ€§èƒ½ï¼ˆåœ¨è‹±ã€è¥¿ã€æ³•è¯­ä¸Šå¹³å‡F1>94%ï¼‰ã€‚åº”ç”¨è¯¥æ–¹æ³•å‘ç°ï¼Œåª’ä½“å¯¹ç¾å®³å’Œææ€–è¢­å‡»çš„å…³æ³¨åº¦ï¼Œä¸æ­»äº¡äººæ•°ã€å—å½±å“å›½å®¶çš„GDPä»¥åŠåŒè¾¹è´¸æ˜“é¢é«˜åº¦ç›¸å…³ã€‚<br>**[limitation/future]** The reliance on a two-stage screening pipeline depends on the quality of external event databases \(e.g., GTD\), and the minimalist fingerprint design, while enabling scalability, can lead to ambiguities for events with similar metadata.<br>\[ç¿»è¯‘\] ä¸¤çº§ç­›é€‰æµç¨‹ä¾èµ–äºå¤–éƒ¨äº‹ä»¶æ•°æ®åº“ï¼ˆå¦‚GTDï¼‰çš„è´¨é‡ï¼Œä¸”æç®€çš„æŒ‡çº¹è®¾è®¡è™½ç„¶ä¿è¯äº†å¯æ‰©å±•æ€§ï¼Œä½†å¯èƒ½å¯¼è‡´å…·æœ‰ç›¸ä¼¼å…ƒæ•°æ®çš„äº‹ä»¶äº§ç”ŸåŒ¹é…æ­§ä¹‰ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[å¼•ç”¨æ–‡\]Cai et al. \(2025\) propose the FAME framework, aiming to efficiently and accurately identify news reports on specific events from massive, multilingual news streams. Its innovation lies in a two-stage, zero-shot methodology. The framework first applies heuristic filtering using event â€œfingerprintsâ€ \(time, location, category\) to retrieve candidate articles, followed by a refinement step leveraging an LLM for precise event-article matching. This approach enables scalable, training-free analysis, successfully linking over 27,000 articles to 470 global events.<br>\[ç¿»è¯‘\]<br>Caiç­‰äºº\(2025\)æå‡ºçš„FAMEæ¡†æ¶ï¼Œæ—¨åœ¨ä»æµ·é‡ã€å¤šè¯­è¨€çš„æ–°é—»æµä¸­é«˜æ•ˆã€ç²¾ç¡®åœ°è¯†åˆ«å‡ºå…³äºç‰¹å®šäº‹ä»¶çš„æŠ¥é“ï¼Œå…¶åˆ›æ–°åœ¨äºä¸€ç§ä¸¤çº§ã€é›¶æ ·æœ¬çš„æ–¹æ³•ã€‚å®ƒé¦–å…ˆä½¿ç”¨äº‹ä»¶â€œæŒ‡çº¹â€ï¼ˆæ—¶é—´ã€åœ°ç‚¹ã€ç±»åˆ«ï¼‰è¿›è¡Œå¯å‘å¼è¿‡æ»¤ä»¥è·å–å€™é€‰æ–‡ç« ï¼Œéšåé€šè¿‡åŸºäºLLMè¿›è¡Œäº‹ä»¶åŒ¹é…ã€‚è¿™å®ç°äº†å¯æ‰©å±•çš„ã€å…è®­ç»ƒçš„åˆ†æï¼ŒæˆåŠŸå°†è¶…è¿‡2.7ä¸‡ç¯‡æ–‡ç« ä¸470ä¸ªå…¨çƒäº‹ä»¶å…³è”èµ·æ¥ã€‚</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/shiqinghuayi19/LLMforEvent.svg?style=social&label=Star)](https://github.com/shiqinghuayi19/LLMforEvent) [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[Is a Large Language Model a Good Annotator for Event Extraction?](https://ojs.aaai.org/index.php/AAAI/article/view/29730) <br> Ruirui Chen1,Chengwei Qin,Weifeng Jiang,Dongkyu Choi <br> 2024-03-24|\[AI generated\] This method uses LLMs as expert annotators to generate high-quality training data, akin to employing a master chef to prepare ingredients for a specialized dish. \[ç¿»è¯‘\]è¯¥æ–¹æ³•åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºä¸“å®¶æ ‡æ³¨å‘˜ç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ï¼Œå¦‚åŒè˜è¯·ä¸»å¨ä¸ºç‰¹è‰²èœè‚´å‡†å¤‡é£Ÿæã€‚|<img width="1200" alt="pipeline" src="figures/Annotator for Event Extraction.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** åœ¨æç¤ºä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡ç¤ºä¾‹æ¥å¼•å¯¼å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸ç›®æ ‡åŸºå‡†æ•°æ®é›†åˆ†å¸ƒå’Œæ ‡æ³¨æ¨¡å¼å¯¹é½çš„æ–°æ ·æœ¬ï¼Œä»è€Œç›´æ¥è§£å†³æ•°æ®ä¸å¹³è¡¡é—®é¢˜ã€‚ **[innovation]** \[AI generated\] Employing LLMs as expert annotators with in-context examples to generate distribution-aligned data, directly addressing data scarcity and imbalance. \[ç¿»è¯‘\] åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºä¸“å®¶æ ‡æ³¨å™¨ï¼Œç»“åˆä¸Šä¸‹æ–‡ç¤ºä¾‹ç”Ÿæˆåˆ†å¸ƒå¯¹é½çš„æ•°æ®ï¼Œç›´æ¥è§£å†³æ•°æ®ç¨€ç¼ºä¸ä¸å¹³è¡¡é—®é¢˜ã€‚ **[method]** é’ˆå¯¹â€œè®­ç»ƒæ ·æœ¬ç¨€å°‘çš„ï¼ˆé•¿å°¾ï¼‰äº‹ä»¶ç±»å‹ï¼Œä½¿ç”¨åˆé€‚çš„promptæ¨¡æ¿ï¼ˆåŒ…å«çœŸå®ä¾‹å­ï¼‰è¦æ±‚LLMç”Ÿæˆæ ‡æ³¨ï¼Œè¿›è¡Œè´¨é‡ç­›é€‰ï¼Œåˆå¹¶åˆ°åŸå§‹æ•°æ®é›†ï¼Œæœ€ç»ˆé€šè¿‡å®éªŒä¸åˆå¹¶å‰çš„æ•ˆæœæ¯”è¾ƒ **[conclusion/contribution]** Fine-tuning models like BERT-CRF on the GPT-4-augmented ACE 2005 data led to consistent F1-score improvements in both Event Detection and Argument Extraction tasks, proving the high utility of LLM-generated annotations as a training resource. \[ç¿»è¯‘\] åœ¨GPT-4å¢å¼ºçš„ACE 2005æ•°æ®ä¸Šå¾®è°ƒBERT-CRFç­‰æ¨¡å‹ï¼Œåœ¨äº‹ä»¶æ£€æµ‹å’Œè®ºå…ƒæŠ½å–ä»»åŠ¡ä¸­å‡å¸¦æ¥äº†F1åˆ†æ•°çš„æŒç»­æå‡ï¼Œè¯æ˜äº†LLMç”Ÿæˆçš„æ ‡æ³¨ä½œä¸ºè®­ç»ƒèµ„æºçš„é«˜æ•ˆç”¨ã€‚ **[limitation/future]** é«˜åº¦ä¾èµ–LLMè‡ªèº«èƒ½åŠ›">**[summary]**</summary><div style="margin-top:6px">**[motivation]** åœ¨æç¤ºä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡ç¤ºä¾‹æ¥å¼•å¯¼å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸ç›®æ ‡åŸºå‡†æ•°æ®é›†åˆ†å¸ƒå’Œæ ‡æ³¨æ¨¡å¼å¯¹é½çš„æ–°æ ·æœ¬ï¼Œä»è€Œç›´æ¥è§£å†³æ•°æ®ä¸å¹³è¡¡é—®é¢˜ã€‚<br>**[innovation]** \[AI generated\] Employing LLMs as expert annotators with in-context examples to generate distribution-aligned data, directly addressing data scarcity and imbalance.<br>\[ç¿»è¯‘\]<br>åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºä¸“å®¶æ ‡æ³¨å™¨ï¼Œç»“åˆä¸Šä¸‹æ–‡ç¤ºä¾‹ç”Ÿæˆåˆ†å¸ƒå¯¹é½çš„æ•°æ®ï¼Œç›´æ¥è§£å†³æ•°æ®ç¨€ç¼ºä¸ä¸å¹³è¡¡é—®é¢˜ã€‚<br>**[method]** é’ˆå¯¹â€œè®­ç»ƒæ ·æœ¬ç¨€å°‘çš„ï¼ˆé•¿å°¾ï¼‰äº‹ä»¶ç±»å‹ï¼Œä½¿ç”¨åˆé€‚çš„promptæ¨¡æ¿ï¼ˆåŒ…å«çœŸå®ä¾‹å­ï¼‰è¦æ±‚LLMç”Ÿæˆæ ‡æ³¨ï¼Œè¿›è¡Œè´¨é‡ç­›é€‰ï¼Œåˆå¹¶åˆ°åŸå§‹æ•°æ®é›†ï¼Œæœ€ç»ˆé€šè¿‡å®éªŒä¸åˆå¹¶å‰çš„æ•ˆæœæ¯”è¾ƒ<br>**[conclusion/contribution]** Fine-tuning models like BERT-CRF on the GPT-4-augmented ACE 2005 data led to consistent F1-score improvements in both Event Detection and Argument Extraction tasks, proving the high utility of LLM-generated annotations as a training resource.<br>\[ç¿»è¯‘\]<br>åœ¨GPT-4å¢å¼ºçš„ACE 2005æ•°æ®ä¸Šå¾®è°ƒBERT-CRFç­‰æ¨¡å‹ï¼Œåœ¨äº‹ä»¶æ£€æµ‹å’Œè®ºå…ƒæŠ½å–ä»»åŠ¡ä¸­å‡å¸¦æ¥äº†F1åˆ†æ•°çš„æŒç»­æå‡ï¼Œè¯æ˜äº†LLMç”Ÿæˆçš„æ ‡æ³¨ä½œä¸ºè®­ç»ƒèµ„æºçš„é«˜æ•ˆç”¨ã€‚<br>**[limitation/future]** é«˜åº¦ä¾èµ–LLMè‡ªèº«èƒ½åŠ›</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[å¼•ç”¨æ–‡\]To overcome data scarcity in specialized tasks within event extraction, large language models \(LLMs\) can be utilized as data augmentation tools. The work by Chen et al. \(2024\) exemplifies this by employing LLMs as structured annotators: using few-shot prompting with models such as GPT-4, they generate synthetic training data aligned with target schemas. This augmentation strategy effectively alleviates long-tail data imbalance and delivers measurable performance improvements for downstream extraction models.<br>\[ç¿»è¯‘\]<br>ä¸ºå…‹æœäº‹ä»¶æŠ½å–é¢†åŸŸä¸“ä¸šä»»åŠ¡ä¸­çš„æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œå¯ä»¥å°†å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºæ•°æ®å¢å¼ºå·¥å…·ã€‚Chenç­‰äºº\(2024\)çš„ç ”ç©¶é€šè¿‡å°†å¤§è¯­è¨€æ¨¡å‹ç”¨ä½œç»“æ„åŒ–æ ‡æ³¨å™¨æ¥å±•ç¤ºè¿™ä¸€ç‚¹ï¼šä»–ä»¬ä½¿ç”¨å°‘é‡ç¤ºä¾‹æç¤ºGPT-4ç­‰æ¨¡å‹ï¼Œç”Ÿæˆä¸ç›®æ ‡æ¨¡å¼å¯¹é½çš„åˆæˆè®­ç»ƒæ•°æ®ã€‚è¿™ç§å¢å¼ºç­–ç•¥æœ‰æ•ˆç¼“è§£äº†é•¿å°¾æ•°æ®ä¸å¹³è¡¡é—®é¢˜ï¼Œä¸ºä¸‹æ¸¸æŠ½å–æ¨¡å‹å¸¦æ¥äº†å¯è§‚çš„æ€§èƒ½æå‡ã€‚</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/RingBDStack/FinEvent.svg?style=social&label=Star)](https://github.com/RingBDStack/FinEvent) [![Publish](https://img.shields.io/badge/Conference-IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence-blue)]()<br>[Reinforced, Incremental and Cross-Lingual Event Detection From Social Messages](https://ieeexplore.ieee.org/document/9693189/) <br> Hao Peng,Ruitong Zhang,Shaoning Li,Yuwei Cao,Shirui Pan,Philip S. Yu <br> 2023-01-01|\[AI generated\] FinEvent is like a multilingual, self-optimizing news curator that continuously learns and adapts from live social media streams. \[ç¿»è¯‘\] FinEvent å¦‚åŒä¸€ä¸ªå¤šè¯­è¨€çš„ã€è‡ªä¼˜åŒ–çš„æ–°é—»ç­–å±•äººï¼Œèƒ½ä»å®æ—¶ç¤¾äº¤åª’ä½“æµä¸­æŒç»­å­¦ä¹ ä¸é€‚åº”ã€‚|<img width="1200" alt="pipeline" src="figures/FinEvent.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Event detection in social media streams is challenged by ambiguous event features, dispersed text content, multilingualism, and long-tail distribution, where traditional methods struggle in dynamic, incremental, and cross-lingual scenarios. \[ç¿»è¯‘\] ç¤¾äº¤åª’ä½“æµä¸­çš„äº‹ä»¶æ£€æµ‹é¢ä¸´äº‹ä»¶ç‰¹å¾æ¨¡ç³Šã€æ–‡æœ¬å†…å®¹åˆ†æ•£ã€å¤šè¯­è¨€å’Œé•¿å°¾åˆ†å¸ƒç­‰æŒ‘æˆ˜ï¼Œä¼ ç»Ÿæ–¹æ³•åœ¨åŠ¨æ€ã€å¢é‡å’Œè·¨è¯­è¨€åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ã€‚ **[innovation]** Its core advancement lies in enabling continuous, cross-lingual social event detection through a life-cycle mechanism that dynamically updates both the message graph and model without full retraining. \[ç¿»è¯‘\] å…¶æ ¸å¿ƒè¿›æ­¥åœ¨äºï¼Œé€šè¿‡ä¸€ä¸ªèƒ½åŠ¨æ€æ›´æ–°æ¶ˆæ¯å›¾ä¸æ¨¡å‹è€Œæ— éœ€å…¨é‡é‡è®­ç»ƒçš„ç”Ÿå‘½å‘¨æœŸæœºåˆ¶ï¼Œå®ç°äº†æŒç»­çš„ã€è·¨è¯­è¨€çš„ç¤¾äº¤äº‹ä»¶æ£€æµ‹ã€‚ **[method]** The pipeline includes: \(1\) constructing a weighted multi-relational graph from social messages; \(2\) using multi-agent reinforcement learning to learn relation-specific thresholds for neighbor selection and aggregation; \(3\) training with balanced sampling-based contrastive learning; \(4\) clustering via DRL-optimized DBSCAN; and \(5\) enabling incremental updates and cross-lingual transfer via parameter preservation. \[ç¿»è¯‘\] æµç¨‹åŒ…æ‹¬ï¼š\(1\) ä»ç¤¾äº¤æ¶ˆæ¯æ„å»ºåŠ æƒå¤šå…³ç³»å›¾ï¼›\(2\) ä½¿ç”¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å­¦ä¹ å…³ç³»ç‰¹å®šçš„é˜ˆå€¼ä»¥è¿›è¡Œé‚»å±…é€‰æ‹©å’Œèšåˆï¼›\(3\) é€šè¿‡åŸºäºå¹³è¡¡é‡‡æ ·çš„å¯¹æ¯”å­¦ä¹ è®­ç»ƒï¼›\(4\) ä½¿ç”¨DRLä¼˜åŒ–çš„DBSCANèšç±»ï¼›\(5\) é€šè¿‡å‚æ•°ä¿ç•™æ”¯æŒå¢é‡æ›´æ–°å’Œè·¨è¯­è¨€è¿ç§»ã€‚ **[conclusion/contribution]** On Twitter streams, FinEvent significantly outperforms baselines in offline, online, and cross-lingual detection tasks, with improvements of 14%-118% in NMI, 8%-170% in AMI, and 2%-21% in ARI, demonstrating robust performance across diverse settings. \[ç¿»è¯‘\] åœ¨Twitteræµæ•°æ®ä¸Šï¼ŒFinEventåœ¨ç¦»çº¿ã€åœ¨çº¿å’Œè·¨è¯­è¨€æ£€æµ‹ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼ŒNMIæå‡14%-118%ï¼ŒAMIæå‡8%-170%ï¼ŒARIæå‡2%-21%ï¼Œå±•ç°äº†åœ¨ä¸åŒè®¾ç½®ä¸‹çš„é²æ£’æ€§èƒ½ã€‚ **[limitation/future]** Limitations include high computational complexity, dependence on external translation for low-resource languages, potential knowledge forgetting during incremental updates, and limited generalization due to evaluation primarily on Twitter data. \[ç¿»è¯‘\] å±€é™æ€§åŒ…æ‹¬è®¡ç®—å¤æ‚åº¦é«˜ã€å¯¹ä½èµ„æºè¯­è¨€ä¾èµ–å¤–éƒ¨ç¿»è¯‘ã€å¢é‡æ›´æ–°ä¸­å¯èƒ½é—å¿˜æ—©æœŸçŸ¥è¯†ï¼Œä»¥åŠç”±äºä¸»è¦åŸºäºTwitteræ•°æ®è¯„ä¼°å¯¼è‡´çš„æ³›åŒ–æ€§æœ‰é™ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Event detection in social media streams is challenged by ambiguous event features, dispersed text content, multilingualism, and long-tail distribution, where traditional methods struggle in dynamic, incremental, and cross-lingual scenarios.<br>\[ç¿»è¯‘\]<br>ç¤¾äº¤åª’ä½“æµä¸­çš„äº‹ä»¶æ£€æµ‹é¢ä¸´äº‹ä»¶ç‰¹å¾æ¨¡ç³Šã€æ–‡æœ¬å†…å®¹åˆ†æ•£ã€å¤šè¯­è¨€å’Œé•¿å°¾åˆ†å¸ƒç­‰æŒ‘æˆ˜ï¼Œä¼ ç»Ÿæ–¹æ³•åœ¨åŠ¨æ€ã€å¢é‡å’Œè·¨è¯­è¨€åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ã€‚<br>**[innovation]** Its core advancement lies in enabling continuous, cross-lingual social event detection through a life-cycle mechanism that dynamically updates both the message graph and model without full retraining.<br>\[ç¿»è¯‘\]<br>å…¶æ ¸å¿ƒè¿›æ­¥åœ¨äºï¼Œé€šè¿‡ä¸€ä¸ªèƒ½åŠ¨æ€æ›´æ–°æ¶ˆæ¯å›¾ä¸æ¨¡å‹è€Œæ— éœ€å…¨é‡é‡è®­ç»ƒçš„ç”Ÿå‘½å‘¨æœŸæœºåˆ¶ï¼Œå®ç°äº†æŒç»­çš„ã€è·¨è¯­è¨€çš„ç¤¾äº¤äº‹ä»¶æ£€æµ‹ã€‚<br>**[method]** The pipeline includes: \(1\) constructing a weighted multi-relational graph from social messages; \(2\) using multi-agent reinforcement learning to learn relation-specific thresholds for neighbor selection and aggregation; \(3\) training with balanced sampling-based contrastive learning; \(4\) clustering via DRL-optimized DBSCAN; and \(5\) enabling incremental updates and cross-lingual transfer via parameter preservation.<br>\[ç¿»è¯‘\]<br>æµç¨‹åŒ…æ‹¬ï¼š\(1\) ä»ç¤¾äº¤æ¶ˆæ¯æ„å»ºåŠ æƒå¤šå…³ç³»å›¾ï¼›\(2\) ä½¿ç”¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å­¦ä¹ å…³ç³»ç‰¹å®šçš„é˜ˆå€¼ä»¥è¿›è¡Œé‚»å±…é€‰æ‹©å’Œèšåˆï¼›\(3\) é€šè¿‡åŸºäºå¹³è¡¡é‡‡æ ·çš„å¯¹æ¯”å­¦ä¹ è®­ç»ƒï¼›\(4\) ä½¿ç”¨DRLä¼˜åŒ–çš„DBSCANèšç±»ï¼›\(5\) é€šè¿‡å‚æ•°ä¿ç•™æ”¯æŒå¢é‡æ›´æ–°å’Œè·¨è¯­è¨€è¿ç§»ã€‚<br>**[conclusion/contribution]** On Twitter streams, FinEvent significantly outperforms baselines in offline, online, and cross-lingual detection tasks, with improvements of 14%-118% in NMI, 8%-170% in AMI, and 2%-21% in ARI, demonstrating robust performance across diverse settings.<br>\[ç¿»è¯‘\]<br>åœ¨Twitteræµæ•°æ®ä¸Šï¼ŒFinEventåœ¨ç¦»çº¿ã€åœ¨çº¿å’Œè·¨è¯­è¨€æ£€æµ‹ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼ŒNMIæå‡14%-118%ï¼ŒAMIæå‡8%-170%ï¼ŒARIæå‡2%-21%ï¼Œå±•ç°äº†åœ¨ä¸åŒè®¾ç½®ä¸‹çš„é²æ£’æ€§èƒ½ã€‚<br>**[limitation/future]** Limitations include high computational complexity, dependence on external translation for low-resource languages, potential knowledge forgetting during incremental updates, and limited generalization due to evaluation primarily on Twitter data.<br>\[ç¿»è¯‘\]<br>å±€é™æ€§åŒ…æ‹¬è®¡ç®—å¤æ‚åº¦é«˜ã€å¯¹ä½èµ„æºè¯­è¨€ä¾èµ–å¤–éƒ¨ç¿»è¯‘ã€å¢é‡æ›´æ–°ä¸­å¯èƒ½é—å¿˜æ—©æœŸçŸ¥è¯†ï¼Œä»¥åŠç”±äºä¸»è¦åŸºäºTwitteræ•°æ®è¯„ä¼°å¯¼è‡´çš„æ³›åŒ–æ€§æœ‰é™ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[å¼•ç”¨æ–‡\]Peng et al. \(2023\) proposed FinEvent, a reinforced, incremental, and cross-lingual detection architecture. Its core innovation lies in a life-cycle learning mechanism that supports incremental adaptation: the system dynamically updates a multi-relational message graph, employs multi-agent reinforcement learning to continuously optimize aggregation strategies, and utilizes a DRL-optimized clustering module to self-adjust parameters for each data blockâ€”enabling the model to co-evolve with the social data stream.<br><br>\[ç¿»è¯‘\]<br>Pengç­‰äººï¼ˆ2023ï¼‰æå‡ºäº†FinEventï¼Œä¸€ä¸ªå¼ºåŒ–çš„å¢é‡ä¸è·¨è¯­è¨€æ£€æµ‹æ¶æ„ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºä¸€ä¸ªæ”¯æŒå¢é‡é€‚åº”çš„ç”Ÿå‘½å‘¨æœŸå­¦ä¹ æœºåˆ¶ï¼šç³»ç»ŸåŠ¨æ€æ›´æ–°å¤šå…³ç³»æ¶ˆæ¯å›¾ï¼Œå¹¶é‡‡ç”¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æŒç»­ä¼˜åŒ–èšåˆç­–ç•¥ï¼ŒåŒæ—¶é€šè¿‡DRLä¼˜åŒ–çš„èšç±»æ¨¡å—å®ç°æ¯ä¸ªæ•°æ®å—çš„è‡ªè°ƒå‚ï¼Œä½¿æ¨¡å‹èƒ½éšç¤¾äº¤æ•°æ®æµå…±åŒæ¼”åŒ–ã€‚\[notes\]æ ¹æ®æ¶ˆæ¯é—´çš„å¤šç§è¯­ä¹‰å…³ç³»æ„å»ºå¼‚æ„æ¶ˆæ¯ç½‘ç»œç½‘ç»œ->é€šè¿‡å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å¾—åˆ°æ¯ä¸ªå…³ç³»çš„ä¿ç•™é˜ˆå€¼ï¼ˆå¤šæ™ºèƒ½ä½“å¼ºåŒ–æŒ‡çš„æ˜¯æ¯ä¸ªæ™ºèƒ½ä½“è´Ÿè´£ä¸€ä¸ªå…³ç³»ï¼‰ï¼Œå¯¹äºæ¯ä¸ªæ¶ˆæ¯èŠ‚ç‚¹çš„æ¯ä¸ªå…³ç³»å›¾ï¼Œé€šè¿‡ä¿ç•™é˜ˆå€¼å‰ªé™¤æ‰å¯¹èšåˆä½œç”¨ä½çš„é‚»å±…èŠ‚ç‚¹->å…ˆå›¾å†…èšåˆï¼Œå†å›¾é—´èšåˆå¾—åˆ°æ¯ä¸ªèŠ‚ç‚¹çš„ç‰¹å¾å‘é‡->ä½¿ç”¨Triplet Lossï¼ˆæ‹‰è¿‘åŒç±»æ¶ˆæ¯ã€æ¨è¿œå¼‚ç±»æ¶ˆæ¯ï¼‰å’ŒGlobal-Local Lossï¼ˆä¿æŒå›¾ç»“æ„çš„å…¨å±€ä¸€è‡´æ€§ï¼‰ä¸¤ä¸ªæŸå¤±å‡½æ•°è¿›è¡ŒGNNè®­ç»ƒï¼Œå¾—åˆ°ä¸åŒäº‹ä»¶åŒºåˆ†èƒ½åŠ›->ä½¿ç”¨DRL-DBSCANè¿›è¡Œè‡ªé€‚åº”èšç±»ï¼Œå¾—åˆ°äº‹ä»¶åˆ†ç±»è¾“å‡º->æ”¯æŒå¢é‡æ›´æ–°ä¸è·¨è¯­è¨€è¿ç§»</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[Towards Effective, Efficient and Unsupervised Social Event Detection in the Hyperbolic Space](https://ojs.aaai.org/index.php/AAAI/article/view/33430) <br> Xiaoyan Yu,Yifan Wei,Shuaishuai Zhou,Zhiwei Yang,Li Sun,Hao Peng,Liehuang Zhu\*,Philip S. Yu <br> 2025-04-11|é€šè¿‡ä¸¤å±‚å‹ç¼©å‡å°‘å¼€é”€ï¼ˆç®€åŒ–è¾¹ã€èŠ‚ç‚¹èšåˆä¸ºé”šç‚¹ï¼‰ï¼Œé€šè¿‡åˆ’åˆ†æ ‘è¡¨ç¤ºäº‹ä»¶èšç±»|<img width="1200" alt="pipeline" src="figures/HyperSED.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Social event detection on social media platforms faces significant challenges due to the large scale, dynamic nature, and complex relational structures inherent in user-generated content. Existing methods often suffer from inefficiency in processing massive message streams and limited expressive power in capturing hierarchical event structures. \[ç¿»è¯‘\]ï¼šç”±äºç”¨æˆ·ç”Ÿæˆå†…å®¹è§„æ¨¡åºå¤§ã€åŠ¨æ€æ€§å¼ºä¸”å…³ç³»ç»“æ„å¤æ‚ï¼Œç¤¾äº¤åª’ä½“å¹³å°ä¸Šçš„ç¤¾äº¤äº‹ä»¶æ£€æµ‹é¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æµ·é‡æ¶ˆæ¯æµæ—¶å¸¸æ•ˆç‡ä½ä¸‹ï¼Œä¸”åœ¨æ•æ‰å±‚æ¬¡åŒ–äº‹ä»¶ç»“æ„æ–¹é¢è¡¨è¾¾èƒ½åŠ›æœ‰é™ã€‚ **[innovation]** The paper introduces HyperSED, a novel unsupervised framework that reduces computational overhead through a two-stage compression mechanismâ€”semantic-based anchor construction and graph sparsificationâ€”and represents event clusters via a differentiable partitioning tree learned in hyperbolic space. This approach effectively captures hierarchical and nested event structures without requiring predefined cluster counts. \[ç¿»è¯‘\]ï¼šæœ¬æ–‡æå‡ºHyperSEDï¼Œä¸€ç§æ–°é¢–çš„æ— ç›‘ç£æ¡†æ¶ï¼Œé€šè¿‡åŸºäºè¯­ä¹‰çš„é”šç‚¹æ„å»ºä¸å›¾ç¨€ç–åŒ–ä¸¤é˜¶æ®µå‹ç¼©æœºåˆ¶é™ä½è®¡ç®—å¼€é”€ï¼Œå¹¶åˆ©ç”¨åœ¨åŒæ›²ç©ºé—´ä¸­å­¦ä¹ çš„å¯å¾®åˆ’åˆ†æ ‘è¡¨ç¤ºäº‹ä»¶èšç±»ã€‚è¯¥æ–¹æ³•æ— éœ€é¢„è®¾èšç±»æ•°é‡ï¼Œå³å¯æœ‰æ•ˆæ•æ‰å±‚æ¬¡åŒ–ä¸åµŒå¥—çš„äº‹ä»¶ç»“æ„ã€‚ **[method]** The framework first constructs a semantic anchor graph to compress message nodes and simplify relational edges. It then maps the anchor graph into hyperbolic space and employs a hyperbolic graph autoencoder to learn structure-aware representations. Finally, a partitioning tree is built and optimized via differentiable structural information minimization, yielding hierarchical event clusters. \[ç¿»è¯‘\]ï¼šè¯¥æ¡†æ¶é¦–å…ˆæ„å»ºè¯­ä¹‰é”šç‚¹å›¾ä»¥å‹ç¼©æ¶ˆæ¯èŠ‚ç‚¹å¹¶ç®€åŒ–å…³ç³»è¾¹ï¼Œéšåå°†é”šç‚¹å›¾æ˜ å°„è‡³åŒæ›²ç©ºé—´ï¼Œé‡‡ç”¨åŒæ›²å›¾è‡ªç¼–ç å™¨å­¦ä¹ ç»“æ„æ„ŸçŸ¥è¡¨ç¤ºï¼Œæœ€ç»ˆé€šè¿‡å¯å¾®ç»“æ„ä¿¡æ¯æœ€å°åŒ–æ„å»ºå¹¶ä¼˜åŒ–åˆ’åˆ†æ ‘ï¼Œå¾—åˆ°å±‚æ¬¡åŒ–äº‹ä»¶ç°‡ **[conclusion/contribution]** Experiments on real-world Twitter datasets demonstrate that HyperSED achieves competitive performance in normalized mutual information, adjusted mutual information, and adjusted Rand index, while improving computational efficiency by up to 37 times compared to state-of-the-art unsupervised baselines. \[ç¿»è¯‘\]ï¼šåœ¨çœŸå®Twitteræ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHyperSEDåœ¨å½’ä¸€åŒ–äº’ä¿¡æ¯ã€è°ƒæ•´äº’ä¿¡æ¯ä¸è°ƒæ•´å…°å¾·æŒ‡æ•°ä¸Šå‡å–å¾—å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶ç›¸æ¯”å‰æ²¿æ— ç›‘ç£åŸºçº¿ï¼Œè®¡ç®—æ•ˆç‡æå‡æœ€é«˜è¾¾37å€ã€‚ **[limitation/future]** The performance may marginally decline in some message blocks due to potential errors in anchor construction, where semantically distinct messages are incorrectly grouped. Additionally, the efficiency gains come with a slight trade-off in clustering granularity control. \[ç¿»è¯‘\]ï¼šç”±äºé”šç‚¹æ„å»ºä¸­å¯èƒ½å‡ºç°è¯­ä¹‰ä¸åŒæ¶ˆæ¯è¢«é”™è¯¯åˆ†ç»„çš„æƒ…å†µï¼Œè¯¥æ¨¡å‹åœ¨éƒ¨åˆ†æ¶ˆæ¯å—ä¸Šçš„æ€§èƒ½å¯èƒ½ç•¥æœ‰ä¸‹é™ã€‚æ­¤å¤–ï¼Œæ•ˆç‡æå‡åœ¨ä¸€å®šç¨‹åº¦ä¸Šä»¥èšç±»ç²’åº¦æ§åˆ¶çš„ç²¾ç»†åº¦ä¸ºä»£ä»·ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Social event detection on social media platforms faces significant challenges due to the large scale, dynamic nature, and complex relational structures inherent in user-generated content. Existing methods often suffer from inefficiency in processing massive message streams and limited expressive power in capturing hierarchical event structures.<br>\[ç¿»è¯‘\]ï¼šç”±äºç”¨æˆ·ç”Ÿæˆå†…å®¹è§„æ¨¡åºå¤§ã€åŠ¨æ€æ€§å¼ºä¸”å…³ç³»ç»“æ„å¤æ‚ï¼Œç¤¾äº¤åª’ä½“å¹³å°ä¸Šçš„ç¤¾äº¤äº‹ä»¶æ£€æµ‹é¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æµ·é‡æ¶ˆæ¯æµæ—¶å¸¸æ•ˆç‡ä½ä¸‹ï¼Œä¸”åœ¨æ•æ‰å±‚æ¬¡åŒ–äº‹ä»¶ç»“æ„æ–¹é¢è¡¨è¾¾èƒ½åŠ›æœ‰é™ã€‚<br>**[innovation]** The paper introduces HyperSED, a novel unsupervised framework that reduces computational overhead through a two-stage compression mechanismâ€”semantic-based anchor construction and graph sparsificationâ€”and represents event clusters via a differentiable partitioning tree learned in hyperbolic space. This approach effectively captures hierarchical and nested event structures without requiring predefined cluster counts.<br>\[ç¿»è¯‘\]ï¼šæœ¬æ–‡æå‡ºHyperSEDï¼Œä¸€ç§æ–°é¢–çš„æ— ç›‘ç£æ¡†æ¶ï¼Œé€šè¿‡åŸºäºè¯­ä¹‰çš„é”šç‚¹æ„å»ºä¸å›¾ç¨€ç–åŒ–ä¸¤é˜¶æ®µå‹ç¼©æœºåˆ¶é™ä½è®¡ç®—å¼€é”€ï¼Œå¹¶åˆ©ç”¨åœ¨åŒæ›²ç©ºé—´ä¸­å­¦ä¹ çš„å¯å¾®åˆ’åˆ†æ ‘è¡¨ç¤ºäº‹ä»¶èšç±»ã€‚è¯¥æ–¹æ³•æ— éœ€é¢„è®¾èšç±»æ•°é‡ï¼Œå³å¯æœ‰æ•ˆæ•æ‰å±‚æ¬¡åŒ–ä¸åµŒå¥—çš„äº‹ä»¶ç»“æ„ã€‚<br>**[method]** The framework first constructs a semantic anchor graph to compress message nodes and simplify relational edges. It then maps the anchor graph into hyperbolic space and employs a hyperbolic graph autoencoder to learn structure-aware representations. Finally, a partitioning tree is built and optimized via differentiable structural information minimization, yielding hierarchical event clusters.<br>\[ç¿»è¯‘\]ï¼šè¯¥æ¡†æ¶é¦–å…ˆæ„å»ºè¯­ä¹‰é”šç‚¹å›¾ä»¥å‹ç¼©æ¶ˆæ¯èŠ‚ç‚¹å¹¶ç®€åŒ–å…³ç³»è¾¹ï¼Œéšåå°†é”šç‚¹å›¾æ˜ å°„è‡³åŒæ›²ç©ºé—´ï¼Œé‡‡ç”¨åŒæ›²å›¾è‡ªç¼–ç å™¨å­¦ä¹ ç»“æ„æ„ŸçŸ¥è¡¨ç¤ºï¼Œæœ€ç»ˆé€šè¿‡å¯å¾®ç»“æ„ä¿¡æ¯æœ€å°åŒ–æ„å»ºå¹¶ä¼˜åŒ–åˆ’åˆ†æ ‘ï¼Œå¾—åˆ°å±‚æ¬¡åŒ–äº‹ä»¶ç°‡<br>**[conclusion/contribution]** Experiments on real-world Twitter datasets demonstrate that HyperSED achieves competitive performance in normalized mutual information, adjusted mutual information, and adjusted Rand index, while improving computational efficiency by up to 37 times compared to state-of-the-art unsupervised baselines.<br>\[ç¿»è¯‘\]ï¼šåœ¨çœŸå®Twitteræ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHyperSEDåœ¨å½’ä¸€åŒ–äº’ä¿¡æ¯ã€è°ƒæ•´äº’ä¿¡æ¯ä¸è°ƒæ•´å…°å¾·æŒ‡æ•°ä¸Šå‡å–å¾—å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶ç›¸æ¯”å‰æ²¿æ— ç›‘ç£åŸºçº¿ï¼Œè®¡ç®—æ•ˆç‡æå‡æœ€é«˜è¾¾37å€ã€‚<br>**[limitation/future]** The performance may marginally decline in some message blocks due to potential errors in anchor construction, where semantically distinct messages are incorrectly grouped. Additionally, the efficiency gains come with a slight trade-off in clustering granularity control.<br>\[ç¿»è¯‘\]ï¼šç”±äºé”šç‚¹æ„å»ºä¸­å¯èƒ½å‡ºç°è¯­ä¹‰ä¸åŒæ¶ˆæ¯è¢«é”™è¯¯åˆ†ç»„çš„æƒ…å†µï¼Œè¯¥æ¨¡å‹åœ¨éƒ¨åˆ†æ¶ˆæ¯å—ä¸Šçš„æ€§èƒ½å¯èƒ½ç•¥æœ‰ä¸‹é™ã€‚æ­¤å¤–ï¼Œæ•ˆç‡æå‡åœ¨ä¸€å®šç¨‹åº¦ä¸Šä»¥èšç±»ç²’åº¦æ§åˆ¶çš„ç²¾ç»†åº¦ä¸ºä»£ä»·ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[notes\]ä¸ºä»€ä¹ˆç”¨åŒæ›²ç©ºé—´ï¼Ÿ ç°å®ä¸–ç•Œçš„äº‹ä»¶å’Œè¯é¢˜å¾€å¾€å…·æœ‰å±‚æ¬¡ç»“æ„ï¼ˆå¦‚â€œä½“è‚² -> è¶³çƒ -> ä¸–ç•Œæ¯â€ï¼‰ã€‚åŒæ›²ç©ºé—´çš„å‡ ä½•ç‰¹æ€§ï¼ˆæŒ‡æ•°çº§å¢é•¿çš„ç©ºé—´ï¼‰èƒ½æ›´è‡ªç„¶ã€æ›´ç´§å‡‘åœ°åµŒå…¥è¿™ç§æ ‘çŠ¶æˆ–å±‚æ¬¡åŒ–æ•°æ®ã€‚<br>\[é€šä¿—æ ¸å¿ƒ\]é€šè¿‡æ¶ˆæ¯å„å±æ€§çš„ç›¸åŒæ€§ï¼ˆç”¨æˆ·ã€æ ‡ç­¾ï¼‰æ„å»ºç½‘ç»œï¼›é€šè¿‡æ–¹æ³•ç²¾ç®€ç½‘ç»œè¾¹ã€å‹ç¼©1ã€‘ï¼›æ ¹æ®ç›¸å…³æ€§å°†ç›¸ä¼¼ä¿¡æ¯èšç±»ä¸ºé”šç‚¹ï¼Œé”šç‚¹ä¹‹é—´æœ‰èŠ‚ç‚¹ç›¸è¿çš„æ„å»ºè¾¹ï¼Œå¾—åˆ°é”šç‚¹å›¾ã€å‹ç¼©2ã€‘ï¼›æ˜ å°„åˆ°åŒæ›²ç©ºé—´è¿›è¡Œè‡ªç›‘ç£é‡å»ºè®­ç»ƒï¼ˆå›¾è‡ªç¼–ç å™¨GAEï¼‰è·å¾—èšåˆæ¨¡å‹ï¼›æ¨¡å‹è¾“å‡ºæ ¹æ®ç‰¹å¾å‘é‡è·ç¦»è‡ªåº•å‘ä¸Šèšåˆå½¢æˆåˆ’åˆ†æ ‘ï¼Œè¯¥æ ‘å³è¡¨ç¤ºæ¶ˆæ¯å„å±‚çº§èšç±»å…³ç³»ã€‚æ¯ä¸ªèšç±»èŠ‚ç‚¹éƒ½ä»£è¡¨äº†ä¸€ä¸ªæŸå±‚çº§äº‹ä»¶ï¼ˆå¦‚ä½“è‚²ã€ä¸–ç•Œæ¯ã€æ–°å† ï¼‰\[å¼•ç”¨æ–‡\]HyperSED demonstrates how structural and geometric inductive biases can be integrated into scalable unsupervised learning \(Yu et al., 2025\). By compressing the message graph into semantic anchors and learning a partitioning tree in hyperbolic spaceâ€”where internal nodes formed through bottomâ€‘up aggregation represent concrete event categoriesâ€”the framework not only enhances detection efficiency but also captures the multiâ€‘scale organization of social events.<br><br>\[ç¿»è¯‘\]HyperSEDå±•ç¤ºäº†å¦‚ä½•å°†ç»“æ„ä¸å‡ ä½•å½’çº³åç½®èå…¥å¯æ‰©å±•çš„æ— ç›‘ç£å­¦ä¹ ï¼ˆYu et al., 2025ï¼‰ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†æ¶ˆæ¯å›¾å‹ç¼©ä¸ºè¯­ä¹‰é”šç‚¹ï¼Œå¹¶åœ¨åŒæ›²ç©ºé—´ä¸­å­¦ä¹ åˆ’åˆ†æ ‘â€”â€”å…¶ä¸­é€šè¿‡è‡ªåº•å‘ä¸Šèšåˆå½¢æˆçš„å†…éƒ¨èŠ‚ç‚¹ä»£è¡¨å…·ä½“çš„äº‹ä»¶ç±»åˆ«â€”â€”ä¸ä»…æå‡äº†æ£€æµ‹æ•ˆç‡ï¼Œè¿˜æ•æ‰äº†ç¤¾äº¤äº‹ä»¶çš„å¤šå°ºåº¦ç»„ç»‡ç‰¹å¾ã€‚</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-Neural%20Information%20Processing-blue)]()<br>[A Three-Stage Framework for Event-Event Relation Extraction with Large Language Model](https://link.springer.com/10.1007/978-981-99-8181-6_33) <br> Feng Huang,Qiang Huang,YueTong Zhao,ZhiXiao Qi,BingKun Wang,YongFeng Huang,SongBin Li <br> 2024|é€šè¿‡ç»“æ„åŒ–promptæ„å»ºçš„ï¼Œæ— è®­ç»ƒé›¶æ ·æœ¬çš„ï¼Œä¾èµ–äºæœ¬åœ°çŸ¥è¯†åº“çš„ï¼Œäº‹ä»¶æŠ½å–æ–¹æ³•|<img width="1200" alt="pipeline" src="figures/ThreeEERE.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Traditional event relation extraction methods rely heavily on annotated data, which is costly and difficult to scale. The zero-shot capability of large language models remains underexplored for temporal and causal relation tasks. \[ç¿»è¯‘\] ä¼ ç»Ÿäº‹ä»¶å…³ç³»æå–æ–¹æ³•ä¸¥é‡ä¾èµ–æ ‡æ³¨æ•°æ®ï¼Œæˆæœ¬é«˜ä¸”éš¾ä»¥æ‰©å±•ã€‚å¤§è¯­è¨€æ¨¡å‹åœ¨æ—¶åºä¸å› æœå…³ç³»ä»»åŠ¡ä¸­çš„é›¶æ ·æœ¬èƒ½åŠ›å°šæœªå……åˆ†æŒ–æ˜ã€‚ **[innovation]** A three-stage framework \(ThreeEERE\) is proposed, integrating an improved Auto-CoT prompting strategy with local knowledge retrieval to enable zero-shot event-event relation extraction without task-specific training. \[ç¿»è¯‘\] æå‡ºä¸‰é˜¶æ®µæ¡†æ¶ThreeEEREï¼Œèåˆæ”¹è¿›çš„Auto-CoTæç¤ºç­–ç•¥ä¸æœ¬åœ°çŸ¥è¯†æ£€ç´¢ï¼Œå®ç°æ— éœ€ä»»åŠ¡ç‰¹å®šè®­ç»ƒçš„é›¶æ ·æœ¬äº‹ä»¶-å…³ç³»æå–ã€‚ **[method]** æ„å»ºç¤ºèŒƒæ ·ä¾‹ï¼ˆåŒ…å«cotéƒ¨åˆ†ï¼‰-&gt;æ£€ç´¢æœ¬åœ°çŸ¥è¯†-&gt;å–é«˜äºé˜ˆå€¼çš„ç­”æ¡ˆ **[conclusion/contribution]** ThreeEERE outperforms standard prompting methods and matches or surpasses several supervised baselines in event, temporal, and causal relation extraction across multiple datasets. \[ç¿»è¯‘\] åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„äº‹ä»¶ã€æ—¶åºä¸å› æœå…³ç³»æå–ä»»åŠ¡ä¸­ï¼ŒThreeEEREä¼˜äºæ ‡å‡†æç¤ºæ–¹æ³•ï¼Œå¹¶è¾¾åˆ°æˆ–è¶…è¶Šè‹¥å¹²ç›‘ç£åŸºçº¿ã€‚ **[limitation/future]** Potential inconsistency between generated reasoning chains and gold answers in demonstrations may introduce noise and affect model stability.And it relies on the construction of a local knowledge base. \[ç¿»è¯‘\] ç¤ºèŒƒä¸­ç”Ÿæˆçš„æ¨ç†é“¾ä¸æ ‡å‡†ç­”æ¡ˆä¹‹é—´å¯èƒ½å­˜åœ¨ä¸ä¸€è‡´ï¼Œå¯èƒ½å¼•å…¥å™ªå£°å¹¶å½±å“æ¨¡å‹ç¨³å®šæ€§ã€‚ä¸”ä¾èµ–äºæœ¬åœ°çŸ¥è¯†åº“æ„å»º">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Traditional event relation extraction methods rely heavily on annotated data, which is costly and difficult to scale. The zero-shot capability of large language models remains underexplored for temporal and causal relation tasks.<br>\[ç¿»è¯‘\]<br>ä¼ ç»Ÿäº‹ä»¶å…³ç³»æå–æ–¹æ³•ä¸¥é‡ä¾èµ–æ ‡æ³¨æ•°æ®ï¼Œæˆæœ¬é«˜ä¸”éš¾ä»¥æ‰©å±•ã€‚å¤§è¯­è¨€æ¨¡å‹åœ¨æ—¶åºä¸å› æœå…³ç³»ä»»åŠ¡ä¸­çš„é›¶æ ·æœ¬èƒ½åŠ›å°šæœªå……åˆ†æŒ–æ˜ã€‚<br>**[innovation]** A three-stage framework \(ThreeEERE\) is proposed, integrating an improved Auto-CoT prompting strategy with local knowledge retrieval to enable zero-shot event-event relation extraction without task-specific training.<br>\[ç¿»è¯‘\]<br>æå‡ºä¸‰é˜¶æ®µæ¡†æ¶ThreeEEREï¼Œèåˆæ”¹è¿›çš„Auto-CoTæç¤ºç­–ç•¥ä¸æœ¬åœ°çŸ¥è¯†æ£€ç´¢ï¼Œå®ç°æ— éœ€ä»»åŠ¡ç‰¹å®šè®­ç»ƒçš„é›¶æ ·æœ¬äº‹ä»¶-å…³ç³»æå–ã€‚<br>**[method]** æ„å»ºç¤ºèŒƒæ ·ä¾‹ï¼ˆåŒ…å«cotéƒ¨åˆ†ï¼‰->æ£€ç´¢æœ¬åœ°çŸ¥è¯†->å–é«˜äºé˜ˆå€¼çš„ç­”æ¡ˆ<br>**[conclusion/contribution]** ThreeEERE outperforms standard prompting methods and matches or surpasses several supervised baselines in event, temporal, and causal relation extraction across multiple datasets.<br>\[ç¿»è¯‘\]<br>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„äº‹ä»¶ã€æ—¶åºä¸å› æœå…³ç³»æå–ä»»åŠ¡ä¸­ï¼ŒThreeEEREä¼˜äºæ ‡å‡†æç¤ºæ–¹æ³•ï¼Œå¹¶è¾¾åˆ°æˆ–è¶…è¶Šè‹¥å¹²ç›‘ç£åŸºçº¿ã€‚<br>**[limitation/future]** Potential inconsistency between generated reasoning chains and gold answers in demonstrations may introduce noise and affect model stability.And it relies on the construction of a local knowledge base.<br>\[ç¿»è¯‘\]<br>ç¤ºèŒƒä¸­ç”Ÿæˆçš„æ¨ç†é“¾ä¸æ ‡å‡†ç­”æ¡ˆä¹‹é—´å¯èƒ½å­˜åœ¨ä¸ä¸€è‡´ï¼Œå¯èƒ½å¼•å…¥å™ªå£°å¹¶å½±å“æ¨¡å‹ç¨³å®šæ€§ã€‚ä¸”ä¾èµ–äºæœ¬åœ°çŸ¥è¯†åº“æ„å»º</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[notes\]èšç±»åªæ˜¯ä¸ºäº†é€‰æ‹©æœ€æ¥è¿‘èšç±»ä¸­å¿ƒçš„æµ‹è¯•æ ·æœ¬ï¼Œä½œä¸ºç¤ºèŒƒæ ·ä¾‹ï¼ˆå› ä¸ºæ¥è¿‘ä¸­å¿ƒæ„å‘³ç€æ›´èƒ½ä»£è¡¨è¯¥èšç±»è¯­ä¹‰ç‰¹å¾ï¼‰ï¼Œä¹‹åçš„æ“ä½œå°±æ˜¯è¾“å…¥æµ‹è¯•æ ·ä¾‹å’Œè¿™äº›ç¤ºèŒƒæ ·ä¾‹ï¼ˆç­”æ¡ˆéƒ¨åˆ†æ›¿æ¢ä¸ºæ ‡å‡†ç­”æ¡ˆï¼‰ä»¥åŠæ£€ç´¢å¾—åˆ°çš„æœ¬åœ°çŸ¥è¯†ï¼Œæœ€ç»ˆå–è¶…è¿‡é˜ˆå€¼çš„ç»“æœ<br>\[å¼•ç”¨æ–‡\]The three-stage framework proposed by Huang et al. \(2024\) integrates chain-of-thought reasoning with localized knowledge, demonstrating the feasibility of eliciting zero-shot inference of complex event relations from large language models through meticulously designed prompts, without the need for supervised fine-tuning.<br>\[ç¿»è¯‘\]<br>Huangç­‰äººï¼ˆ2024ï¼‰æå‡ºçš„ä¸‰é˜¶æ®µæ¡†æ¶ï¼Œå°†æ€ç»´é“¾æ¨ç†ä¸æœ¬åœ°åŒ–çŸ¥è¯†ç›¸ç»“åˆï¼Œè¯æ˜äº†é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯ï¼Œæ— éœ€ç›‘ç£å¾®è°ƒå³å¯ä»å¤§è¯­è¨€æ¨¡å‹ä¸­æ¿€å‘å‡ºå¯¹å¤æ‚äº‹ä»¶å…³ç³»çš„é›¶æ ·æœ¬æ¨æ–­èƒ½åŠ›ã€‚</div></details></div></div>|

### | Generation (2 papers)


### Comment Generation (2 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
|[![Project](https://img.shields.io/badge/Project-View-blue)](https://netsys.surrey.ac.uk/datasets/slashdot/) [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Conversation Kernels: A Flexible Mechanism to Learn Relevant Context for Online Conversation Unde...](https://ojs.aaai.org/index.php/ICWSM/article/view/35800) <br> Vibhor Agarwal,Arjoo Gupta,Suparna De,Nishanth Sastry <br> 2025-06-07 <br> <span style="color:cyan">[multi-categoryï¼š[Base Techniques](#-Base-Techniques-2-papers), [Comment Generation](#Comment-Generation-2-papers)]</span>|A flexible, structural context discovery framework that enhances conversation understanding by learning to attend to relevant topological neighborhoods within conversation trees.\[ç¿»è¯‘\] ä¸€ä¸ªçµæ´»çš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡å‘ç°æ¡†æ¶ï¼Œé€šè¿‡å­¦ä¹ å…³æ³¨å¯¹è¯æ ‘å†…ç›¸å…³çš„æ‹“æ‰‘é‚»åŸŸæ¥å¢å¼ºå¯¹è¯ç†è§£èƒ½åŠ›ã€‚|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Conversation Kernels.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Conversation Kernels2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Addressing the sparsity and context-dependency of individual online utterances, where traditional models often fail to capture implicit dependencies within conversation trees or introduce noise through indiscriminate context inclusion. \[ç¿»è¯‘\] é’ˆå¯¹åœ¨çº¿è¨€è®ºå›ºæœ‰çš„ç¨€ç–æ€§å’Œè¯­å¢ƒä¾èµ–æ€§é—®é¢˜ï¼Œå³ä¼ ç»Ÿæ¨¡å‹å¾€å¾€éš¾ä»¥æ•æ‰å¯¹è¯æ ‘å†…çš„éšå¼ä¾èµ–å…³ç³»ï¼Œæˆ–å› æ— å·®åˆ«åœ°å¼•å…¥ä¸Šä¸‹æ–‡è€Œäº§ç”Ÿå™ªå£° **[innovation]** The proposal of &quot;Conversation Kernels,&quot; a general-purpose mechanism that employs flexible topological shapes to retrieve fine-grained, structured conversational context, distinguishing itself by identifying the &quot;right&quot; structural neighborhood rather than merely increasing context length. \[ç¿»è¯‘\] æå‡ºäº†â€œå¯¹è¯æ ¸â€è¿™ä¸€é€šç”¨æœºåˆ¶ï¼Œåˆ©ç”¨çµæ´»çš„æ‹“æ‰‘å½¢çŠ¶æ¥æ£€ç´¢ç»†ç²’åº¦çš„ç»“æ„åŒ–å¯¹è¯ä¸Šä¸‹æ–‡ï¼›å…¶ç‹¬åˆ°ä¹‹å¤„åœ¨äºé€šè¿‡è¯†åˆ«â€œæ­£ç¡®â€çš„ç»“æ„é‚»åŸŸè€Œéå•çº¯å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦æ¥ç†è§£å¯¹è¯ã€‚ **[method]** An end-to-end trained probabilistic framework that first retrieves relevant structural windows \(e.g., ancestors, neighbors\) via similarity scoring, and subsequently fuses these contexts through a weighted marginalization of the predictive distributions generated by a RoBERTa-based encoder. \[ç¿»è¯‘\] ä¸€ä¸ªç«¯åˆ°ç«¯è®­ç»ƒçš„æ¦‚ç‡æ¡†æ¶ï¼Œé¦–å…ˆé€šè¿‡ç›¸ä¼¼åº¦è¯„åˆ†æ£€ç´¢ç›¸å…³çš„ç»“æ„åŒ–çª—å£ï¼ˆå¦‚ç¥–å…ˆã€é‚»å±…ï¼‰ï¼Œéšåé€šè¿‡å¯¹RoBERTaç¼–ç å™¨ç”Ÿæˆçš„é¢„æµ‹åˆ†å¸ƒè¿›è¡ŒåŠ æƒæ±‚å’Œï¼ˆè¾¹ç¼˜åŒ–ï¼‰ï¼Œä»è€Œèåˆè¿™äº›ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\[é€šä¿—æ ¸å¿ƒ\]é’ˆå¯¹ç›®æ ‡è¯„è®ºæ„å»ºå›å¤æ ‘ï¼Œå–å‡ ä¸ªçª—å£ï¼ˆå¦‚çˆ¶è¯„è®ºçª—å£ã€1è·³çª—å£ï¼‰ï¼Œæ¯ä¸ªçª—å£ä¸­æ‰€æœ‰è¯„è®ºä¸åŸè¯„è®ºæ‹¼æ¥ï¼Œå¹¶è¿›è¡Œé¢„æµ‹ï¼Œæœ€åä¸åŒçª—å£ä¸åŸè¯„è®ºçš„ç›¸å…³æ€§ç»è¿‡softmaxä½œä¸ºæƒé‡ï¼Œå¯¹æ‰€æœ‰é¢„æµ‹ç½®ä¿¡åº¦åŠ æƒå’Œï¼Œå¾—åˆ°æœ€ç»ˆç»“æœ **[conclusion/contribution]** Extensive experiments on Slashdot data demonstrate that context-augmented kernels outperform baseline transformers by up to 20% in accuracy and surpass general-purpose LLMs \(GPT-3.5/4\) in specific categorization tasks, revealing that different tasks require distinct structural context patterns. \[ç¿»è¯‘\] åœ¨Slashdotæ•°æ®ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œä¸Šä¸‹æ–‡å¢å¼ºçš„æ ¸æœºåˆ¶åœ¨å‡†ç¡®ç‡ä¸Šæ¯”åŸºçº¿Transformeræ¨¡å‹é«˜å‡º20%ï¼Œå¹¶åœ¨ç‰¹å®šåˆ†ç±»ä»»åŠ¡ä¸­è¶…è¶Šäº†é€šç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆGPT-3.5/4ï¼‰ï¼Œæ­ç¤ºäº†ä¸åŒä»»åŠ¡éœ€è¦æˆªç„¶ä¸åŒçš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ¨¡å¼ã€‚ **[limitation/future]** The approach relies heavily on explicit tree-structured reply threads, limiting applicability in flat discussion formats, and may face cold-start challenges in early-stage conversations with sparse context. \[ç¿»è¯‘\] è¯¥æ–¹æ³•ä¸¥é‡ä¾èµ–æ˜¾å¼çš„æ ‘çŠ¶å›å¤çº¿ç´¢ï¼Œé™åˆ¶äº†å…¶åœ¨æ‰å¹³åŒ–è®¨è®ºå½¢å¼ä¸­çš„é€‚ç”¨æ€§ï¼Œå¹¶ä¸”åœ¨ä¸Šä¸‹æ–‡ç¨€ç–çš„å¯¹è¯æ—©æœŸé˜¶æ®µå¯èƒ½é¢ä¸´å†·å¯åŠ¨æŒ‘æˆ˜ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Addressing the sparsity and context-dependency of individual online utterances, where traditional models often fail to capture implicit dependencies within conversation trees or introduce noise through indiscriminate context inclusion.<br>\[ç¿»è¯‘\] é’ˆå¯¹åœ¨çº¿è¨€è®ºå›ºæœ‰çš„ç¨€ç–æ€§å’Œè¯­å¢ƒä¾èµ–æ€§é—®é¢˜ï¼Œå³ä¼ ç»Ÿæ¨¡å‹å¾€å¾€éš¾ä»¥æ•æ‰å¯¹è¯æ ‘å†…çš„éšå¼ä¾èµ–å…³ç³»ï¼Œæˆ–å› æ— å·®åˆ«åœ°å¼•å…¥ä¸Šä¸‹æ–‡è€Œäº§ç”Ÿå™ªå£°<br>**[innovation]** The proposal of "Conversation Kernels," a general-purpose mechanism that employs flexible topological shapes to retrieve fine-grained, structured conversational context, distinguishing itself by identifying the "right" structural neighborhood rather than merely increasing context length.<br>\[ç¿»è¯‘\] æå‡ºäº†â€œå¯¹è¯æ ¸â€è¿™ä¸€é€šç”¨æœºåˆ¶ï¼Œåˆ©ç”¨çµæ´»çš„æ‹“æ‰‘å½¢çŠ¶æ¥æ£€ç´¢ç»†ç²’åº¦çš„ç»“æ„åŒ–å¯¹è¯ä¸Šä¸‹æ–‡ï¼›å…¶ç‹¬åˆ°ä¹‹å¤„åœ¨äºé€šè¿‡è¯†åˆ«â€œæ­£ç¡®â€çš„ç»“æ„é‚»åŸŸè€Œéå•çº¯å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦æ¥ç†è§£å¯¹è¯ã€‚<br>**[method]** An end-to-end trained probabilistic framework that first retrieves relevant structural windows \(e.g., ancestors, neighbors\) via similarity scoring, and subsequently fuses these contexts through a weighted marginalization of the predictive distributions generated by a RoBERTa-based encoder.<br>\[ç¿»è¯‘\] ä¸€ä¸ªç«¯åˆ°ç«¯è®­ç»ƒçš„æ¦‚ç‡æ¡†æ¶ï¼Œé¦–å…ˆé€šè¿‡ç›¸ä¼¼åº¦è¯„åˆ†æ£€ç´¢ç›¸å…³çš„ç»“æ„åŒ–çª—å£ï¼ˆå¦‚ç¥–å…ˆã€é‚»å±…ï¼‰ï¼Œéšåé€šè¿‡å¯¹RoBERTaç¼–ç å™¨ç”Ÿæˆçš„é¢„æµ‹åˆ†å¸ƒè¿›è¡ŒåŠ æƒæ±‚å’Œï¼ˆè¾¹ç¼˜åŒ–ï¼‰ï¼Œä»è€Œèåˆè¿™äº›ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\[é€šä¿—æ ¸å¿ƒ\]é’ˆå¯¹ç›®æ ‡è¯„è®ºæ„å»ºå›å¤æ ‘ï¼Œå–å‡ ä¸ªçª—å£ï¼ˆå¦‚çˆ¶è¯„è®ºçª—å£ã€1è·³çª—å£ï¼‰ï¼Œæ¯ä¸ªçª—å£ä¸­æ‰€æœ‰è¯„è®ºä¸åŸè¯„è®ºæ‹¼æ¥ï¼Œå¹¶è¿›è¡Œé¢„æµ‹ï¼Œæœ€åä¸åŒçª—å£ä¸åŸè¯„è®ºçš„ç›¸å…³æ€§ç»è¿‡softmaxä½œä¸ºæƒé‡ï¼Œå¯¹æ‰€æœ‰é¢„æµ‹ç½®ä¿¡åº¦åŠ æƒå’Œï¼Œå¾—åˆ°æœ€ç»ˆç»“æœ<br>**[conclusion/contribution]** Extensive experiments on Slashdot data demonstrate that context-augmented kernels outperform baseline transformers by up to 20% in accuracy and surpass general-purpose LLMs \(GPT-3.5/4\) in specific categorization tasks, revealing that different tasks require distinct structural context patterns.<br>\[ç¿»è¯‘\] åœ¨Slashdotæ•°æ®ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œä¸Šä¸‹æ–‡å¢å¼ºçš„æ ¸æœºåˆ¶åœ¨å‡†ç¡®ç‡ä¸Šæ¯”åŸºçº¿Transformeræ¨¡å‹é«˜å‡º20%ï¼Œå¹¶åœ¨ç‰¹å®šåˆ†ç±»ä»»åŠ¡ä¸­è¶…è¶Šäº†é€šç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆGPT-3.5/4ï¼‰ï¼Œæ­ç¤ºäº†ä¸åŒä»»åŠ¡éœ€è¦æˆªç„¶ä¸åŒçš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ¨¡å¼ã€‚<br>**[limitation/future]** The approach relies heavily on explicit tree-structured reply threads, limiting applicability in flat discussion formats, and may face cold-start challenges in early-stage conversations with sparse context.<br>\[ç¿»è¯‘\] è¯¥æ–¹æ³•ä¸¥é‡ä¾èµ–æ˜¾å¼çš„æ ‘çŠ¶å›å¤çº¿ç´¢ï¼Œé™åˆ¶äº†å…¶åœ¨æ‰å¹³åŒ–è®¨è®ºå½¢å¼ä¸­çš„é€‚ç”¨æ€§ï¼Œå¹¶ä¸”åœ¨ä¸Šä¸‹æ–‡ç¨€ç–çš„å¯¹è¯æ—©æœŸé˜¶æ®µå¯èƒ½é¢ä¸´å†·å¯åŠ¨æŒ‘æˆ˜ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">ã€åŸºç¡€æŠ€æœ¯â€”ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ–¹æ³•ã€‘å¯ç”¨äºæ‰€æœ‰å†…å®¹ç†è§£ä»»åŠ¡ï¼Œè®ºæ–‡ä¸­çš„å®éªŒç”¨çš„æ˜¯æ˜¯å¦å—æ¬¢è¿äºŒåˆ†ç±»<br>\[å¼•ç”¨æ–‡\]To better bridge pattern recognition with social interaction structures, Agarwal et al. \(2025\) proposed Conversation Kernels, an end-to-end framework designed to extract fine-grained context from conversation trees. By dynamically retrieving and weighting specific topological neighborhoods \(e.g., ancestors or siblings\) rather than ingesting linear history, their method effectively filters noise inherent in social discussions. This structural selectivity demonstrates that incorporating explicit interaction topologies is crucial for accurately decoding the nature of online conversations, yielding performance that surpasses even general-purpose Large Language Models like GPT-4.<br>\[ç¿»è¯‘\]<br>ä¸ºäº†æ›´å¥½åœ°å°†æ¨¡å¼è¯†åˆ«ä¸ç¤¾ä¼šäº’åŠ¨ç»“æ„è”ç³»èµ·æ¥ï¼ŒAgarwalç­‰äºº \(2025\) æå‡ºäº†â€œå¯¹è¯æ ¸ï¼ˆConversation Kernelsï¼‰â€ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨ä»å¯¹è¯æ ‘ä¸­æå–ç»†ç²’åº¦ä¸Šä¸‹æ–‡çš„ç«¯åˆ°ç«¯æ¡†æ¶ã€‚é€šè¿‡åŠ¨æ€æ£€ç´¢å¹¶åŠ æƒç‰¹å®šçš„æ‹“æ‰‘é‚»åŸŸï¼ˆå¦‚ç¥–å…ˆæˆ–å…„å¼ŸèŠ‚ç‚¹ï¼‰è€Œéæ‘„å…¥çº¿æ€§å†å²ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°è¿‡æ»¤äº†ç¤¾ä¼šè®¨è®ºä¸­å›ºæœ‰çš„å™ªå£°ã€‚è¿™ç§ç»“æ„é€‰æ‹©æ€§è¯æ˜ï¼Œç»“åˆæ˜¾å¼çš„äº’åŠ¨æ‹“æ‰‘å¯¹äºå‡†ç¡®è§£è¯»åœ¨çº¿å¯¹è¯çš„æ€§è´¨è‡³å…³é‡è¦ï¼Œå…¶è¡¨ç°ç”šè‡³è¶…è¶Šäº†åƒ GPT-4 è¿™æ ·çš„é€šç”¨å¤§è¯­è¨€æ¨¡å‹ã€‚</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/ErxinYu/PopALM.svg?style=social&label=Star)](https://github.com/ErxinYu/PopALM) [![Publish](https://img.shields.io/badge/Conference-LREC--COLING%202024-blue)]()<br>[PopALM: Popularity-aligned language models for social media trendy response prediction](https://aclanthology.org/2024.lrec-main.1127/) <br> Erxin Yu1,Jing Li1âˆ—,Chunpu Xu <br> 2024-05|å…ˆç»ƒâ€œé€‰æ‰‹â€ï¼ˆSFTï¼‰ï¼Œå†ç»ƒâ€œè£åˆ¤â€ï¼ˆRMï¼‰ï¼Œæœ€åè®©â€œè£åˆ¤â€æŒ‡å¯¼â€œé€‰æ‰‹â€è®­ç»ƒï¼ˆRLï¼‰|<img width="1200" alt="pipeline" src="figures/PopALM.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Motivated by the need to simulate mainstream public reactions on social media, this study identifies response popularityâ€”quantified by &quot;like&quot; countsâ€”as a crucial yet noisy signal for aligning language models with collective preferences. \[ç¿»è¯‘\] å‡ºäºæ¨¡æ‹Ÿç¤¾äº¤åª’ä½“ä¸Šä¸»æµå…¬ä¼—ååº”çš„éœ€æ±‚ï¼Œæœ¬ç ”ç©¶å°†é€šè¿‡â€œç‚¹èµæ•°â€é‡åŒ–çš„å›å¤æµè¡Œåº¦è§†ä¸ºä¸€ç§å…³é”®ä¿¡å·ï¼Œæ—¨åœ¨å°†è¯­è¨€æ¨¡å‹ä¸ç¾¤ä½“åå¥½å¯¹é½ï¼Œå°½ç®¡è¯¥æŒ‡æ ‡æœ¬èº«å­˜åœ¨å™ªå£°ã€‚ **[innovation]** The authors propose PopALM, which introduces a curriculum learning-enhanced Proximal Policy Optimization \(CL-PPO\) strategy to robustly align generation with popularity by mitigating the significant noise inherent in \[ç¿»è¯‘\] ä½œè€…æå‡ºäº† PopALMï¼Œè¯¥æ¨¡å‹å¼•å…¥äº†ä¸€ç§å¢å¼ºäº†è¯¾ç¨‹å­¦ä¹ çš„è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆCL-PPOï¼‰ç­–ç•¥ï¼Œé€šè¿‡ç¼“è§£åŸå§‹äº’åŠ¨æŒ‡æ ‡ä¸­å­˜åœ¨çš„æ˜¾è‘—å™ªå£°ï¼Œç¨³å¥åœ°å°†ç”Ÿæˆå†…å®¹ä¸æµè¡Œåº¦å¯¹é½ã€‚ **[method]** The framework follows a sequential &quot;SFT-RM-RL&quot; pipeline, where the CL-PPO algorithm specifically incorporates reward enhancement, ranking, and self-paced sampling to transition training from high-confidence samples to complex scenarios, thereby filtering environmental noise. \[ç¿»è¯‘\] è¯¥æ¡†æ¶éµå¾ªé¡ºåºçš„â€œæœ‰ç›‘ç£å¾®è°ƒ-å¥–åŠ±å»ºæ¨¡-å¼ºåŒ–å­¦ä¹ â€æµç¨‹ï¼Œå…¶ä¸­CL-PPOç®—æ³•ç‰¹åˆ«ç»“åˆäº†å¥–åŠ±å¢å¼ºã€æ’åºå’Œè‡ªæ­¥é‡‡æ ·æœºåˆ¶ï¼Œä»¥å®ç°ä»é«˜ç½®ä¿¡åº¦æ ·æœ¬åˆ°å¤æ‚åœºæ™¯çš„è¿‡æ¸¡è®­ç»ƒï¼Œä»è€Œè¿‡æ»¤ç¯å¢ƒå™ªå£°ã€‚ **[conclusion/contribution]** Experiments on a large-scale Weibo benchmark demonstrate that PopALM outperforms state-of-the-art baselines in both automatic metrics and human evaluation, generating responses that are more specific and aligned with public sentiment. \[ç¿»è¯‘\] åœ¨å¤§è§„æ¨¡å¾®åšåŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPopALM åœ¨è‡ªåŠ¨æŒ‡æ ‡å’Œäººå·¥è¯„ä¼°æ–¹é¢å‡ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿æ¨¡å‹ï¼Œç”Ÿæˆçš„å›å¤æ›´åŠ å…·ä½“ä¸”ç¬¦åˆå…¬ä¼—æƒ…ç»ªã€‚ **[limitation/future]** A primary limitation lies in the reliance on &quot;like&quot; counts as the sole proxy for popularity, which may not fully capture multi-dimensional user engagement or generalize across different platform algorithms. \[ç¿»è¯‘\] ä¸€ä¸ªä¸»è¦çš„å±€é™æ€§åœ¨äºä¾èµ–â€œç‚¹èµæ•°â€ä½œä¸ºè¡¡é‡æµè¡Œåº¦çš„å•ä¸€ä»£ç†æŒ‡æ ‡ï¼Œè¿™å¯èƒ½æ— æ³•å®Œå…¨æ•æ‰å¤šç»´åº¦çš„ç”¨æˆ·å‚ä¸åº¦ï¼Œä¹Ÿéš¾ä»¥åœ¨ä¸åŒå¹³å°çš„ç®—æ³•é—´æ³›åŒ–ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Motivated by the need to simulate mainstream public reactions on social media, this study identifies response popularityâ€”quantified by "like" countsâ€”as a crucial yet noisy signal for aligning language models with collective preferences.<br>\[ç¿»è¯‘\] å‡ºäºæ¨¡æ‹Ÿç¤¾äº¤åª’ä½“ä¸Šä¸»æµå…¬ä¼—ååº”çš„éœ€æ±‚ï¼Œæœ¬ç ”ç©¶å°†é€šè¿‡â€œç‚¹èµæ•°â€é‡åŒ–çš„å›å¤æµè¡Œåº¦è§†ä¸ºä¸€ç§å…³é”®ä¿¡å·ï¼Œæ—¨åœ¨å°†è¯­è¨€æ¨¡å‹ä¸ç¾¤ä½“åå¥½å¯¹é½ï¼Œå°½ç®¡è¯¥æŒ‡æ ‡æœ¬èº«å­˜åœ¨å™ªå£°ã€‚<br>**[innovation]** The authors propose PopALM, which introduces a curriculum learning-enhanced Proximal Policy Optimization \(CL-PPO\) strategy to robustly align generation with popularity by mitigating the significant noise inherent in<br>\[ç¿»è¯‘\] ä½œè€…æå‡ºäº† PopALMï¼Œè¯¥æ¨¡å‹å¼•å…¥äº†ä¸€ç§å¢å¼ºäº†è¯¾ç¨‹å­¦ä¹ çš„è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆCL-PPOï¼‰ç­–ç•¥ï¼Œé€šè¿‡ç¼“è§£åŸå§‹äº’åŠ¨æŒ‡æ ‡ä¸­å­˜åœ¨çš„æ˜¾è‘—å™ªå£°ï¼Œç¨³å¥åœ°å°†ç”Ÿæˆå†…å®¹ä¸æµè¡Œåº¦å¯¹é½ã€‚<br>**[method]** The framework follows a sequential "SFT-RM-RL" pipeline, where the CL-PPO algorithm specifically incorporates reward enhancement, ranking, and self-paced sampling to transition training from high-confidence samples to complex scenarios, thereby filtering environmental noise.<br>\[ç¿»è¯‘\] è¯¥æ¡†æ¶éµå¾ªé¡ºåºçš„â€œæœ‰ç›‘ç£å¾®è°ƒ-å¥–åŠ±å»ºæ¨¡-å¼ºåŒ–å­¦ä¹ â€æµç¨‹ï¼Œå…¶ä¸­CL-PPOç®—æ³•ç‰¹åˆ«ç»“åˆäº†å¥–åŠ±å¢å¼ºã€æ’åºå’Œè‡ªæ­¥é‡‡æ ·æœºåˆ¶ï¼Œä»¥å®ç°ä»é«˜ç½®ä¿¡åº¦æ ·æœ¬åˆ°å¤æ‚åœºæ™¯çš„è¿‡æ¸¡è®­ç»ƒï¼Œä»è€Œè¿‡æ»¤ç¯å¢ƒå™ªå£°ã€‚<br>**[conclusion/contribution]** Experiments on a large-scale Weibo benchmark demonstrate that PopALM outperforms state-of-the-art baselines in both automatic metrics and human evaluation, generating responses that are more specific and aligned with public sentiment.<br>\[ç¿»è¯‘\] åœ¨å¤§è§„æ¨¡å¾®åšåŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPopALM åœ¨è‡ªåŠ¨æŒ‡æ ‡å’Œäººå·¥è¯„ä¼°æ–¹é¢å‡ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿æ¨¡å‹ï¼Œç”Ÿæˆçš„å›å¤æ›´åŠ å…·ä½“ä¸”ç¬¦åˆå…¬ä¼—æƒ…ç»ªã€‚<br>**[limitation/future]** A primary limitation lies in the reliance on "like" counts as the sole proxy for popularity, which may not fully capture multi-dimensional user engagement or generalize across different platform algorithms.<br>\[ç¿»è¯‘\] ä¸€ä¸ªä¸»è¦çš„å±€é™æ€§åœ¨äºä¾èµ–â€œç‚¹èµæ•°â€ä½œä¸ºè¡¡é‡æµè¡Œåº¦çš„å•ä¸€ä»£ç†æŒ‡æ ‡ï¼Œè¿™å¯èƒ½æ— æ³•å®Œå…¨æ•æ‰å¤šç»´åº¦çš„ç”¨æˆ·å‚ä¸åº¦ï¼Œä¹Ÿéš¾ä»¥åœ¨ä¸åŒå¹³å°çš„ç®—æ³•é—´æ³›åŒ–ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[å¤‡æ³¨\]è¯¥è®ºæ–‡åœ¨ä¼šè®®ä¸Šæ²¡æœ‰doiï¼Œä½¿ç”¨çš„æ˜¯arxivç‰ˆçš„doiã€ç»å…¸å¾®è°ƒ+RLèŒƒå¼ã€‘å™ªå£°æŒ‡çš„æ˜¯å—å„ç§å› ç´ å½±å“ï¼Œç‚¹èµæ•°çš„å…·ä½“å€¼éš¾ä»¥å…¬å¹³å¯¹æ¯”<br>\[å¼•ç”¨æ–‡\]<br>In the pursuit of simulating collective social behaviors rather than merely generating coherent text, aligning models with mainstream public sentiment becomes critical. However, social feedback signals, such as "like" counts, are often fraught with noise stemming from non-content factors like posting time or author influence. To address this, PopALM \(Yu et al., 2024\) proposes a PPO algorithm enhanced by curriculum learning. This approach operates on the premise that models should prioritize high-confidence samplesâ€”where popularity strongly correlates with content qualityâ€”to establish a robust foundation. By adopting a self-paced sampling strategy that transitions from easy-to-learn instances to noisier ones, PopALM effectively mitigates the significant noise inherent in using "like" counts as popularity indicators.<br>\[ç¿»è¯‘\]<br>åœ¨è¿½æ±‚æ¨¡æ‹Ÿç¾¤ä½“ç¤¾ä¼šè¡Œä¸ºè€Œéä»…ä»…ç”Ÿæˆè¿è´¯æ–‡æœ¬çš„è¿‡ç¨‹ä¸­ï¼Œå°†æ¨¡å‹ä¸ä¸»æµå…¬ä¼—æƒ…ç»ªå¯¹é½å˜å¾—è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œè¯¸å¦‚â€œç‚¹èµæ•°â€ä¹‹ç±»çš„ç¤¾ä¼šåé¦ˆä¿¡å·å¾€å¾€å……æ»¡äº†æºè‡ªéå†…å®¹å› ç´ ï¼ˆå¦‚å‘å¸ƒæ—¶é—´æˆ–ä½œè€…å½±å“åŠ›ï¼‰çš„å™ªå£°ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼ŒPopALM \(Yu et al., 2024\) æå‡ºäº†ä¸€ç§å¢å¼ºäº†è¯¾ç¨‹å­¦ä¹ çš„PPOç®—æ³•ã€‚è¯¥æ–¹æ³•åŸºäºè¿™æ ·ä¸€ä¸ªå‰æï¼šæ¨¡å‹åº”ä¼˜å…ˆå­¦ä¹ é‚£äº›ç½®ä¿¡åº¦é«˜ï¼ˆå³æµè¡Œåº¦ä¸å†…å®¹è´¨é‡å¼ºç›¸å…³ï¼‰çš„æ ·æœ¬ï¼Œä»è€Œæ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚é€šè¿‡é‡‡ç”¨ä¸€ç§ä»æ˜“å­¦æ ·æœ¬åˆ°å™ªå£°æ ·æœ¬è¿‡æ¸¡çš„è‡ªæ­¥é‡‡æ ·ç­–ç•¥ï¼ŒPopALM æœ‰æ•ˆç¼“è§£äº†ç‚¹èµæ•°ä½œä¸ºçƒ­åº¦æŒ‡æ ‡å­˜åœ¨å¤§é‡å™ªå£°çš„é—®é¢˜ã€‚</div></details></div></div>|

### | Simulation and Deduction (4 papers)


### Social Simulation (3 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[Understanding Online Polarization Through Human-Agent Interaction in a Synthetic LLM-Based Social...](https://ojs.aaai.org/index.php/ICWSM/article/view/35826) <br> Tim Donkers, JÃ¼rgen Ziegler <br> 2025-10-08 <br> <span style="color:cyan">[multi-categoryï¼š[Social Simulation](#Social-Simulation-3-papers), [Macrosocial Phenomena Analysis](#Macrosocial-Phenomena-Analysis-1-papers)]</span>|\[AI generated\] This study uses a digital petri dish of AI agents to observe how online echo chambers amplify human polarization. \[ç¿»è¯‘\] è¿™é¡¹ç ”ç©¶åˆ©ç”¨AIæ™ºèƒ½ä½“æ„æˆçš„æ•°å­—åŸ¹å…»çš¿ï¼Œè§‚å¯Ÿç½‘ç»œå›éŸ³å®¤å¦‚ä½•æ”¾å¤§äººç±»è§‚ç‚¹çš„æåŒ–ã€‚|| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** \[AI generated\] Investigating how polarized online environments influence individual perceptions and behaviors through controlled human-agent interaction. \[ç¿»è¯‘\] é€šè¿‡å—æ§çš„äººæœºäº¤äº’ï¼Œç ”ç©¶æåŒ–åœ¨çº¿ç¯å¢ƒå¦‚ä½•å½±å“ä¸ªä½“æ„ŸçŸ¥ä¸è¡Œä¸ºã€‚ **[innovation]** \[AI generated\] Proposes a novel human-agent interaction framework within a synthetic LLM-based social network to experimentally study polarization dynamics. \[ç¿»è¯‘\] æå‡ºäº†ä¸€ç§åœ¨åŸºäºLLMçš„åˆæˆç¤¾äº¤ç½‘ç»œä¸­è¿›è¡Œäººæœºäº¤äº’çš„æ–°é¢–æ¡†æ¶ï¼Œç”¨äºå®éªŒæ€§åœ°ç ”ç©¶æåŒ–åŠ¨æ€ã€‚ **[method]** \[AI generated\] A novel experimental framework that enables human participants to interact with LLM-based artificial agents within a controlled, synthetic social network simulation. \[ç¿»è¯‘\] ä¸€ç§æ–°é¢–çš„å®éªŒæ¡†æ¶ï¼Œä½¿äººç±»å‚ä¸è€…èƒ½å¤Ÿåœ¨å—æ§çš„åˆæˆç¤¾äº¤ç½‘ç»œæ¨¡æ‹Ÿä¸­ä¸åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„äººå·¥æ™ºèƒ½ä½“è¿›è¡Œäº’åŠ¨ã€‚ **[conclusion/contribution]** \[AI generated\] This study provides causal evidence that polarized online environments increase emotionality and group identity while reducing uncertainty, using a novel LLM-based social simulation. \[ç¿»è¯‘\] æœ¬ç ”ç©¶åˆ©ç”¨åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç¤¾äº¤æ¨¡æ‹Ÿï¼Œæä¾›äº†å› æœè¯æ®ï¼Œè¡¨æ˜æåŒ–çš„åœ¨çº¿ç¯å¢ƒä¼šå¢åŠ æƒ…ç»ªæ€§å’Œç¾¤ä½“è®¤åŒï¼ŒåŒæ—¶å‡å°‘ä¸ç¡®å®šæ€§ã€‚ **[limitation/future]** \[AI generated\] The study&#x27;s reliance on a synthetic, LLM-based simulation may limit the generalizability of its findings to real-world social media dynamics. \[ç¿»è¯‘\] è¯¥ç ”ç©¶ä¾èµ–åŸºäºLLMçš„åˆæˆæ¨¡æ‹Ÿï¼Œå…¶å‘ç°æ¨å¹¿åˆ°çœŸå®ä¸–ç•Œç¤¾äº¤åª’ä½“åŠ¨æ€çš„æ™®é€‚æ€§å¯èƒ½å—é™ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** \[AI generated\] Investigating how polarized online environments influence individual perceptions and behaviors through controlled human-agent interaction.<br>\[ç¿»è¯‘\]<br>é€šè¿‡å—æ§çš„äººæœºäº¤äº’ï¼Œç ”ç©¶æåŒ–åœ¨çº¿ç¯å¢ƒå¦‚ä½•å½±å“ä¸ªä½“æ„ŸçŸ¥ä¸è¡Œä¸ºã€‚<br>**[innovation]** \[AI generated\] Proposes a novel human-agent interaction framework within a synthetic LLM-based social network to experimentally study polarization dynamics.<br>\[ç¿»è¯‘\]<br>æå‡ºäº†ä¸€ç§åœ¨åŸºäºLLMçš„åˆæˆç¤¾äº¤ç½‘ç»œä¸­è¿›è¡Œäººæœºäº¤äº’çš„æ–°é¢–æ¡†æ¶ï¼Œç”¨äºå®éªŒæ€§åœ°ç ”ç©¶æåŒ–åŠ¨æ€ã€‚<br>**[method]** \[AI generated\] A novel experimental framework that enables human participants to interact with LLM-based artificial agents within a controlled, synthetic social network simulation.<br>\[ç¿»è¯‘\]<br>ä¸€ç§æ–°é¢–çš„å®éªŒæ¡†æ¶ï¼Œä½¿äººç±»å‚ä¸è€…èƒ½å¤Ÿåœ¨å—æ§çš„åˆæˆç¤¾äº¤ç½‘ç»œæ¨¡æ‹Ÿä¸­ä¸åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„äººå·¥æ™ºèƒ½ä½“è¿›è¡Œäº’åŠ¨ã€‚<br>**[conclusion/contribution]** \[AI generated\] This study provides causal evidence that polarized online environments increase emotionality and group identity while reducing uncertainty, using a novel LLM-based social simulation.<br>\[ç¿»è¯‘\]<br>æœ¬ç ”ç©¶åˆ©ç”¨åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç¤¾äº¤æ¨¡æ‹Ÿï¼Œæä¾›äº†å› æœè¯æ®ï¼Œè¡¨æ˜æåŒ–çš„åœ¨çº¿ç¯å¢ƒä¼šå¢åŠ æƒ…ç»ªæ€§å’Œç¾¤ä½“è®¤åŒï¼ŒåŒæ—¶å‡å°‘ä¸ç¡®å®šæ€§ã€‚<br>**[limitation/future]** \[AI generated\] The study's reliance on a synthetic, LLM-based simulation may limit the generalizability of its findings to real-world social media dynamics.<br>\[ç¿»è¯‘\]<br>è¯¥ç ”ç©¶ä¾èµ–åŸºäºLLMçš„åˆæˆæ¨¡æ‹Ÿï¼Œå…¶å‘ç°æ¨å¹¿åˆ°çœŸå®ä¸–ç•Œç¤¾äº¤åª’ä½“åŠ¨æ€çš„æ™®é€‚æ€§å¯èƒ½å—é™ã€‚</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-Political%20Analysis-blue)]()<br>[Out of one, many: Using language models to simulate human samples](https://www.cambridge.org/core/journals/political-analysis/article/out-of-one-many-using-language-models-to-simulate-human-samples/035D7C8A55B237942FB6DBAD7CAA4E49) <br> Lisa P. Argyle,Ethan C. Busby,Nancy Fulda2, Joshua R. Gubler,Christopher Rytting and David Wingate <br> 2023-07|è®©LLMæ¨¡ä»¿äººç±»è¿›è¡Œç¤¾ä¼šå­¦å®éªŒï¼Œé€šè¿‡ä¸çœŸå®æƒ…å†µå¯¹é½æ¥åˆ¤æ–­LLMç›¸å…³é¢„æµ‹èƒ½åŠ›|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Out of One, Many.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Out of One, Many2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** LLM&#x27;s well-documented propensity to replicate societal biases is often viewed as a liability, but this paper reconsiders it as a potential asset, suggesting these biases reflect the complex, fine-grained attitudinal distributions embedded within human subpopulations.  \[ç¿»è¯‘\]æ¨¡å‹å¤åˆ¶ç¤¾ä¼šåè§çš„å€¾å‘é€šå¸¸è¢«è§†ä¸ºç¼ºé™·ï¼Œä½†æœ¬æ–‡å°†å…¶é‡æ–°è§†ä¸ºä¸€ç§æ½œåœ¨ä¼˜åŠ¿ï¼Œè®¤ä¸ºè¿™äº›åè§åæ˜ äº†å†…åµŒäºäººç±»äºšç¾¤ä½“ä¸­å¤æ‚ã€ç»†ç²’åº¦çš„æ€åº¦åˆ†å¸ƒã€‚ **[innovation]** \(i\) proposing the novel concept of â€œalgorithmic fidelityâ€ and its four criteria, establishing a framework to quantify how well LLMs simulate human populations; \(ii\) introducing â€œsilicon sampling,â€ a method that conditions models on real demographic backstories to generate representative virtual samples \[ç¿»è¯‘\] \(i\) æå‡ºâ€œç®—æ³•ä¿çœŸåº¦â€æ–°æ¦‚å¿µåŠå…¶å››ä¸ªæ ‡å‡†ï¼Œå»ºç«‹äº†é‡åŒ–LLMæ¨¡æ‹Ÿäººç±»ç¾¤ä½“æ•ˆæœçš„æ¡†æ¶ï¼›\(ii\) å¼•å…¥â€œç¡…é‡‡æ ·â€æ–¹æ³•ï¼ŒåŸºäºçœŸå®äººå£èƒŒæ™¯æ•…äº‹å¯¹æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–ï¼Œä»¥ç”Ÿæˆæœ‰ä»£è¡¨æ€§çš„è™šæ‹Ÿæ ·æœ¬ **[method]** \(i\) extracting sociodemographic profiles from large-scale human surveys; \(ii\) constructing first-person narrative backstories as conditioning prompts; \(iii\) feeding these prompts into GPT-3 to generate responses \(â€œsilicon samplesâ€\) to specific questions; \(iv\) statistically comparing the generated data with original human data to validate algorithmic fidelity across various metrics.  \[ç¿»è¯‘\] \(i\) ä»å¤§è§„æ¨¡äººç±»è°ƒæŸ¥ä¸­æå–ç¤¾ä¼šäººå£å­¦ç‰¹å¾ï¼›\(ii\) æ„å»ºç¬¬ä¸€äººç§°å™äº‹èƒŒæ™¯æ•…äº‹ä½œä¸ºæ¡ä»¶åŒ–æç¤ºï¼›\(iii\) å°†è¿™äº›æç¤ºè¾“å…¥GPT-3ï¼Œä»¥ç”Ÿæˆé’ˆå¯¹ç‰¹å®šé—®é¢˜çš„å›ç­”ï¼ˆâ€œç¡…æ ·æœ¬â€ï¼‰ï¼›\(iv\) ä»å¤šç»´åº¦ç»Ÿè®¡ä¸Šæ¯”è¾ƒç”Ÿæˆæ•°æ®ä¸åŸå§‹äººç±»æ•°æ®ï¼Œä»¥éªŒè¯ç®—æ³•ä¿çœŸåº¦ã€‚\[é€šä¿—æ ¸å¿ƒ\]æ–¹æ³•å¾ˆç®€å•ï¼Œä½¿ç”¨æç¤ºè¯æ¨¡ç‰ˆå¡«å…¥ç¬¦åˆäººå£ç»Ÿè®¡ç‰¹å¾çš„å—è®¿è€…ç‰¹å¾ï¼Œè®©LLMè¾“å‡ºæŒ‡å®šå›ç­”ï¼Œä¸äººç±»æ ·æœ¬åšå¯¹é½ **[conclusion/contribution]** The study demonstrates that GPT-3 exhibits high algorithmic fidelity: human evaluators struggle to distinguish its outputs from human text, and its generated data closely replicates not only aggregate opinion distributions \(e.g., vote shares\) but also the complex correlational structures between demographics, attitudes, and behaviors found in real human data.  \[ç¿»è¯‘\] ç ”ç©¶è¡¨æ˜GPT-3è¡¨ç°å‡ºé«˜ç®—æ³•ä¿çœŸåº¦ï¼šäººç±»è¯„ä¼°è€…éš¾ä»¥åŒºåˆ†å…¶è¾“å‡ºä¸äººç±»æ–‡æœ¬ï¼Œå…¶ç”Ÿæˆçš„æ•°æ®ä¸ä»…ç´§å¯†å¤ç°äº†èšåˆæ„è§åˆ†å¸ƒï¼ˆå¦‚æŠ•ç¥¨ä»½é¢ï¼‰ï¼Œè¿˜å¤ç°äº†çœŸå®äººç±»æ•°æ®ä¸­äººå£ç‰¹å¾ã€æ€åº¦å’Œè¡Œä¸ºä¹‹é—´å¤æ‚çš„ç›¸å…³æ€§ç»“æ„ã€‚ **[limitation/future]** æç¤ºè¯ä¸­æ˜¾ç¤ºæ ‡æ˜è§’è‰²èº«ä»½ï¼Œä¼šè®©LLMè¿‡åº¦é‡è§†ï¼Œæœ‰èµ°æ·å¾„ä¹‹å«Œ">**[summary]**</summary><div style="margin-top:6px">**[motivation]** LLM's well-documented propensity to replicate societal biases is often viewed as a liability, but this paper reconsiders it as a potential asset, suggesting these biases reflect the complex, fine-grained attitudinal distributions embedded within human subpopulations.<br><br>\[ç¿»è¯‘\]æ¨¡å‹å¤åˆ¶ç¤¾ä¼šåè§çš„å€¾å‘é€šå¸¸è¢«è§†ä¸ºç¼ºé™·ï¼Œä½†æœ¬æ–‡å°†å…¶é‡æ–°è§†ä¸ºä¸€ç§æ½œåœ¨ä¼˜åŠ¿ï¼Œè®¤ä¸ºè¿™äº›åè§åæ˜ äº†å†…åµŒäºäººç±»äºšç¾¤ä½“ä¸­å¤æ‚ã€ç»†ç²’åº¦çš„æ€åº¦åˆ†å¸ƒã€‚<br>**[innovation]** \(i\) proposing the novel concept of â€œalgorithmic fidelityâ€ and its four criteria, establishing a framework to quantify how well LLMs simulate human populations; \(ii\) introducing â€œsilicon sampling,â€ a method that conditions models on real demographic backstories to generate representative virtual samples<br>\[ç¿»è¯‘\] \(i\) æå‡ºâ€œç®—æ³•ä¿çœŸåº¦â€æ–°æ¦‚å¿µåŠå…¶å››ä¸ªæ ‡å‡†ï¼Œå»ºç«‹äº†é‡åŒ–LLMæ¨¡æ‹Ÿäººç±»ç¾¤ä½“æ•ˆæœçš„æ¡†æ¶ï¼›\(ii\) å¼•å…¥â€œç¡…é‡‡æ ·â€æ–¹æ³•ï¼ŒåŸºäºçœŸå®äººå£èƒŒæ™¯æ•…äº‹å¯¹æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–ï¼Œä»¥ç”Ÿæˆæœ‰ä»£è¡¨æ€§çš„è™šæ‹Ÿæ ·æœ¬<br>**[method]** \(i\) extracting sociodemographic profiles from large-scale human surveys; \(ii\) constructing first-person narrative backstories as conditioning prompts; \(iii\) feeding these prompts into GPT-3 to generate responses \(â€œsilicon samplesâ€\) to specific questions; \(iv\) statistically comparing the generated data with original human data to validate algorithmic fidelity across various metrics.<br><br>\[ç¿»è¯‘\] \(i\) ä»å¤§è§„æ¨¡äººç±»è°ƒæŸ¥ä¸­æå–ç¤¾ä¼šäººå£å­¦ç‰¹å¾ï¼›\(ii\) æ„å»ºç¬¬ä¸€äººç§°å™äº‹èƒŒæ™¯æ•…äº‹ä½œä¸ºæ¡ä»¶åŒ–æç¤ºï¼›\(iii\) å°†è¿™äº›æç¤ºè¾“å…¥GPT-3ï¼Œä»¥ç”Ÿæˆé’ˆå¯¹ç‰¹å®šé—®é¢˜çš„å›ç­”ï¼ˆâ€œç¡…æ ·æœ¬â€ï¼‰ï¼›\(iv\) ä»å¤šç»´åº¦ç»Ÿè®¡ä¸Šæ¯”è¾ƒç”Ÿæˆæ•°æ®ä¸åŸå§‹äººç±»æ•°æ®ï¼Œä»¥éªŒè¯ç®—æ³•ä¿çœŸåº¦ã€‚\[é€šä¿—æ ¸å¿ƒ\]æ–¹æ³•å¾ˆç®€å•ï¼Œä½¿ç”¨æç¤ºè¯æ¨¡ç‰ˆå¡«å…¥ç¬¦åˆäººå£ç»Ÿè®¡ç‰¹å¾çš„å—è®¿è€…ç‰¹å¾ï¼Œè®©LLMè¾“å‡ºæŒ‡å®šå›ç­”ï¼Œä¸äººç±»æ ·æœ¬åšå¯¹é½<br>**[conclusion/contribution]** The study demonstrates that GPT-3 exhibits high algorithmic fidelity: human evaluators struggle to distinguish its outputs from human text, and its generated data closely replicates not only aggregate opinion distributions \(e.g., vote shares\) but also the complex correlational structures between demographics, attitudes, and behaviors found in real human data.<br><br>\[ç¿»è¯‘\] ç ”ç©¶è¡¨æ˜GPT-3è¡¨ç°å‡ºé«˜ç®—æ³•ä¿çœŸåº¦ï¼šäººç±»è¯„ä¼°è€…éš¾ä»¥åŒºåˆ†å…¶è¾“å‡ºä¸äººç±»æ–‡æœ¬ï¼Œå…¶ç”Ÿæˆçš„æ•°æ®ä¸ä»…ç´§å¯†å¤ç°äº†èšåˆæ„è§åˆ†å¸ƒï¼ˆå¦‚æŠ•ç¥¨ä»½é¢ï¼‰ï¼Œè¿˜å¤ç°äº†çœŸå®äººç±»æ•°æ®ä¸­äººå£ç‰¹å¾ã€æ€åº¦å’Œè¡Œä¸ºä¹‹é—´å¤æ‚çš„ç›¸å…³æ€§ç»“æ„ã€‚<br>**[limitation/future]** æç¤ºè¯ä¸­æ˜¾ç¤ºæ ‡æ˜è§’è‰²èº«ä»½ï¼Œä¼šè®©LLMè¿‡åº¦é‡è§†ï¼Œæœ‰èµ°æ·å¾„ä¹‹å«Œ</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[å¼•ç”¨æ–‡\]Argyle et al. \(2023\) represent a pivotal shift from viewing LLMs as mere pattern recognition tools to employing them as tools for social simulation. Their work provides a paradigmatic methodologyâ€”centered on the concept of â€œalgorithmic fidelityâ€â€”for experimentally testing whether and how the statistical predictions of an LLM align with nuanced human societal patterns. By conditioning GPT-3 on detailed demographic backstories within prompts \(â€œsilicon samplingâ€\), they demonstrated that the model itself could generate attitudes and internal correlations that closely mirror those of real human subgroups. This marks a transition from goal-oriented text generation to the study of simulated social emergence.<br><br>\[ç¿»è¯‘\]<br>Argyleç­‰äºº\(2023\)çš„ç ”ç©¶æ ‡å¿—ç€ä¸€ä¸ªå…³é”®è½¬å˜ï¼šä»å°†LLMè§†ä¸ºå•çº¯çš„æ¨¡å¼è¯†åˆ«å·¥å…·ï¼Œè½¬å‘å°†å…¶ç”¨ä½œç¤¾ä¼šä»¿çœŸçš„å·¥å…·ã€‚ä»–ä»¬çš„å·¥ä½œæä¾›äº†ä¸€ç§èŒƒå¼æ–¹æ³•â€”â€”å›´ç»•â€œç®—æ³•ä¿çœŸåº¦â€æ¦‚å¿µâ€”â€”æ¥å®éªŒæ€§åœ°æµ‹è¯•LLMçš„ç»Ÿè®¡é¢„æµ‹æ˜¯å¦åŠå¦‚ä½•ä¸äººç±»ç¤¾ä¼šæ¨¡å¼å¯¹é½ã€‚é€šè¿‡åœ¨æç¤ºè¯ä¸­ä¸ºGPT-3æ–½åŠ è¯¦ç»†çš„äººå£èƒŒæ™¯æ•…äº‹æ¡ä»¶ï¼ˆâ€œç¡…é‡‡æ ·â€ï¼‰ï¼Œä»–ä»¬è¯æ˜äº†è¯¥æ¨¡å‹èƒ½å¤Ÿæ¶Œç°å‡ºä¸çœŸå®äººç±»äºšç¾¤ä½“é«˜åº¦å»åˆçš„æ€åº¦åŠå†…éƒ¨å…³è”ã€‚æ ‡å¿—ç€ä»ç›®æ ‡å¯¼å‘çš„æ–‡æœ¬ç”Ÿæˆå‘æ¨¡æ‹Ÿç¤¾ä¼šæ¶Œç°ç ”ç©¶çš„è¿‡æ¸¡</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-EMNLP%20Findings-blue)]()<br>[Are Large Language Models \\(LLMs\\) Good Social Predictors?](https://aclanthology.org/2024.findings-emnlp.153) <br> Kaiqi Yang\*,Hang Li\*,Hongzhi Wen,Tai-Quan Peng,Jiliang Tang,Hui Liu <br> 2024|æ¶ˆèäº†æœ€èƒ½å½±å“é¢„æµ‹ç»“æœçš„â€œæ„è¯†å½¢æ€è‡ªæˆ‘å®šä½â€å’Œâ€œå…šæ´¾è®¤åŒâ€ï¼Œå‘ç°é¢„æµ‹èƒ½åŠ›æ¥è¿‘äºéšæœº|<img width="1200" alt="pipeline" src="figures/anti-Out of One, Many.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** è®ºæ–‡Out of one, many: Using language models to simulate human sampleså¯èƒ½åˆ©ç”¨äº†æ·å¾„ç‰¹æ€§ï¼Œä¸”èƒ½åŠ›éš¾ä»¥ä»å®è§‚ç»†åŒ–åˆ°ä¸ªä½“ **[innovation]** \[AI generated\] Proposes a novel social prediction benchmark \(Soc-PRF\) categorizing features by mutability to rigorously evaluate LLMs and reveals their reliance on input shortcuts. \[ç¿»è¯‘\]ï¼šæå‡ºäº†ä¸€ä¸ªæŒ‰ç‰¹å¾å¯å˜æ€§åˆ†ç±»çš„æ–°é¢–ç¤¾ä¼šé¢„æµ‹åŸºå‡†ï¼ˆSoc-PRFï¼‰ï¼Œä»¥ä¸¥æ ¼è¯„ä¼°LLMsï¼Œå¹¶æ­ç¤ºäº†å…¶å¯¹è¾“å…¥æ·å¾„çš„ä¾èµ–ã€‚ **[method]** First, a replication and ablation study on the ANES voting dataset quantifies the performance drop when removing highly correlated â€œshortcutâ€ inputs \(e.g., party ID\). Second, a new benchmark is constructed using Gallup World Poll data. Features are categorized by mutability \(low: demographics; high: attitudes/behaviors\). Three prediction settings are definedâ€”low-to-high, high-to-low, and high-to-highâ€”simulating realistic data collection scenarios. Multiple LLMs are evaluated under zero-shot prompting, with AUC as the primary metric. \[ç¿»è¯‘\]ï¼šé¦–å…ˆï¼Œåœ¨ANESæŠ•ç¥¨æ•°æ®é›†ä¸Šè¿›è¡Œå¤åˆ¶å’Œæ¶ˆèç ”ç©¶ï¼Œé‡åŒ–äº†ç§»é™¤é«˜åº¦ç›¸å…³çš„â€œæ·å¾„â€è¾“å…¥ï¼ˆå¦‚å…šæ´¾èº«ä»½ï¼‰åçš„æ€§èƒ½ä¸‹é™ã€‚å…¶æ¬¡ï¼Œä½¿ç”¨ç›–æ´›æ™®ä¸–ç•Œæ°‘æ„è°ƒæŸ¥æ•°æ®æ„å»ºäº†ä¸€ä¸ªæ–°åŸºå‡†ã€‚ç‰¹å¾æŒ‰å¯å˜æ€§åˆ†ç±»ï¼ˆä½ï¼šäººå£ç»Ÿè®¡å­¦ç‰¹å¾ï¼›é«˜ï¼šæ€åº¦/è¡Œä¸ºï¼‰ã€‚å®šä¹‰äº†ä¸‰ç§é¢„æµ‹è®¾å®šâ€”â€”ä½æ¨é«˜ã€é«˜æ¨ä½å’Œé«˜æ¨é«˜â€”â€”ä»¥æ¨¡æ‹Ÿç°å®çš„æ•°æ®æ”¶é›†åœºæ™¯ã€‚åœ¨é›¶æ ·æœ¬æç¤ºä¸‹è¯„ä¼°äº†å¤šç§LLMsï¼Œä»¥AUCä¸ºä¸»è¦æŒ‡æ ‡ã€‚ **[conclusion/contribution]** The high performance in prior voting prediction vanishes when shortcuts are removed, with accuracy dropping to near-random levels \(e.g., ~61% for GPT-3.5\). In the stringent Soc-PRF settings devoid of shortcuts, all tested LLMs \(including GPT-4\) perform no better than random guessing \(AUC ~50\). \[ç¿»è¯‘\]ï¼š å…ˆå‰æŠ•ç¥¨é¢„æµ‹ä¸­çš„é«˜æ€§èƒ½æ¶ˆå¤±ï¼Œå‡†ç¡®ç‡ä¸‹é™è‡³æ¥è¿‘éšæœºæ°´å¹³ï¼ˆä¾‹å¦‚ï¼ŒGPT-3.5çº¦ä¸º61%ï¼‰ã€‚åœ¨æ’é™¤æ·å¾„çš„ä¸¥æ ¼Soc-PRFè®¾å®šä¸­ï¼Œæ‰€æœ‰æµ‹è¯•çš„LLMsï¼ˆåŒ…æ‹¬GPT-4ï¼‰çš„è¡¨ç°å‡ä¸ä¼˜äºéšæœºçŒœæµ‹ï¼ˆAUC ~50ï¼‰ã€‚ **[limitation/future]** \[AI generated\] The promising performance of LLMs in social prediction heavily relies on unrealistic shortcut features, and their ability to generalize to real-world scenarios with ordinary inputs remains questionable. \[ç¿»è¯‘\]ï¼šLLMsåœ¨ç¤¾ä¼šé¢„æµ‹ä¸­çš„ä¼˜å¼‚è¡¨ç°ä¸¥é‡ä¾èµ–ä¸ç°å®çš„æ·å¾„ç‰¹å¾ï¼Œå…¶ä½¿ç”¨æ™®é€šè¾“å…¥æ³›åŒ–åˆ°çœŸå®åœºæ™¯çš„èƒ½åŠ›å­˜ç–‘ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** è®ºæ–‡Out of one, many: Using language models to simulate human sampleså¯èƒ½åˆ©ç”¨äº†æ·å¾„ç‰¹æ€§ï¼Œä¸”èƒ½åŠ›éš¾ä»¥ä»å®è§‚ç»†åŒ–åˆ°ä¸ªä½“<br>**[innovation]** \[AI generated\] Proposes a novel social prediction benchmark \(Soc-PRF\) categorizing features by mutability to rigorously evaluate LLMs and reveals their reliance on input shortcuts.<br>\[ç¿»è¯‘\]ï¼šæå‡ºäº†ä¸€ä¸ªæŒ‰ç‰¹å¾å¯å˜æ€§åˆ†ç±»çš„æ–°é¢–ç¤¾ä¼šé¢„æµ‹åŸºå‡†ï¼ˆSoc-PRFï¼‰ï¼Œä»¥ä¸¥æ ¼è¯„ä¼°LLMsï¼Œå¹¶æ­ç¤ºäº†å…¶å¯¹è¾“å…¥æ·å¾„çš„ä¾èµ–ã€‚<br>**[method]** First, a replication and ablation study on the ANES voting dataset quantifies the performance drop when removing highly correlated â€œshortcutâ€ inputs \(e.g., party ID\). Second, a new benchmark is constructed using Gallup World Poll data. Features are categorized by mutability \(low: demographics; high: attitudes/behaviors\). Three prediction settings are definedâ€”low-to-high, high-to-low, and high-to-highâ€”simulating realistic data collection scenarios. Multiple LLMs are evaluated under zero-shot prompting, with AUC as the primary metric.<br>\[ç¿»è¯‘\]ï¼šé¦–å…ˆï¼Œåœ¨ANESæŠ•ç¥¨æ•°æ®é›†ä¸Šè¿›è¡Œå¤åˆ¶å’Œæ¶ˆèç ”ç©¶ï¼Œé‡åŒ–äº†ç§»é™¤é«˜åº¦ç›¸å…³çš„â€œæ·å¾„â€è¾“å…¥ï¼ˆå¦‚å…šæ´¾èº«ä»½ï¼‰åçš„æ€§èƒ½ä¸‹é™ã€‚å…¶æ¬¡ï¼Œä½¿ç”¨ç›–æ´›æ™®ä¸–ç•Œæ°‘æ„è°ƒæŸ¥æ•°æ®æ„å»ºäº†ä¸€ä¸ªæ–°åŸºå‡†ã€‚ç‰¹å¾æŒ‰å¯å˜æ€§åˆ†ç±»ï¼ˆä½ï¼šäººå£ç»Ÿè®¡å­¦ç‰¹å¾ï¼›é«˜ï¼šæ€åº¦/è¡Œä¸ºï¼‰ã€‚å®šä¹‰äº†ä¸‰ç§é¢„æµ‹è®¾å®šâ€”â€”ä½æ¨é«˜ã€é«˜æ¨ä½å’Œé«˜æ¨é«˜â€”â€”ä»¥æ¨¡æ‹Ÿç°å®çš„æ•°æ®æ”¶é›†åœºæ™¯ã€‚åœ¨é›¶æ ·æœ¬æç¤ºä¸‹è¯„ä¼°äº†å¤šç§LLMsï¼Œä»¥AUCä¸ºä¸»è¦æŒ‡æ ‡ã€‚<br>**[conclusion/contribution]** The high performance in prior voting prediction vanishes when shortcuts are removed, with accuracy dropping to near-random levels \(e.g., ~61% for GPT-3.5\). In the stringent Soc-PRF settings devoid of shortcuts, all tested LLMs \(including GPT-4\) perform no better than random guessing \(AUC ~50\). \[ç¿»è¯‘\]ï¼š å…ˆå‰æŠ•ç¥¨é¢„æµ‹ä¸­çš„é«˜æ€§èƒ½æ¶ˆå¤±ï¼Œå‡†ç¡®ç‡ä¸‹é™è‡³æ¥è¿‘éšæœºæ°´å¹³ï¼ˆä¾‹å¦‚ï¼ŒGPT-3.5çº¦ä¸º61%ï¼‰ã€‚åœ¨æ’é™¤æ·å¾„çš„ä¸¥æ ¼Soc-PRFè®¾å®šä¸­ï¼Œæ‰€æœ‰æµ‹è¯•çš„LLMsï¼ˆåŒ…æ‹¬GPT-4ï¼‰çš„è¡¨ç°å‡ä¸ä¼˜äºéšæœºçŒœæµ‹ï¼ˆAUC ~50ï¼‰ã€‚<br>**[limitation/future]** \[AI generated\] The promising performance of LLMs in social prediction heavily relies on unrealistic shortcut features, and their ability to generalize to real-world scenarios with ordinary inputs remains questionable. \[ç¿»è¯‘\]ï¼šLLMsåœ¨ç¤¾ä¼šé¢„æµ‹ä¸­çš„ä¼˜å¼‚è¡¨ç°ä¸¥é‡ä¾èµ–ä¸ç°å®çš„æ·å¾„ç‰¹å¾ï¼Œå…¶ä½¿ç”¨æ™®é€šè¾“å…¥æ³›åŒ–åˆ°çœŸå®åœºæ™¯çš„èƒ½åŠ›å­˜ç–‘ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[å¼•ç”¨æ–‡\]As the field evolves from pattern recognition towards social simulation and emergent understanding, a critical reassessment of our tools is imperative. Yang et al. \(2024\) provide a pivotal corrective in this transition. Their work challenges the optimistic narrative that LLMs can serve as accurate social predictors. They demonstrate that previously reported successes in tasks like vote prediction critically depended on "shortcut features" \(e.g., using party identification to predict vote choice\) and, by introducing a novel shortcut-free benchmark \(Soc-PRF\), reveal a significant gap. In settings devoid of such shortcuts, even state-of-the-art LLMs perform at random levels. This finding underscores a fundamental limitation: while current LLMs are excellent pattern recognizers of surface correlations, they lack the deeper causal or contextual reasoning necessary for genuine social simulation and the emergence of robust socio-behavioral understanding. Their research suggests that achieving true social fidelity requires moving beyond exploiting statistical artifacts in data.<br><br>\[ç¿»è¯‘\]<br><br>éšç€è¯¥é¢†åŸŸä»æ¨¡å¼è¯†åˆ«å‘ç¤¾ä¼šä»¿çœŸä¸æ¶Œç°æ€§ç†è§£æ¼”è¿›ï¼Œå¯¹æˆ‘ä»¬çš„å·¥å…·è¿›è¡Œæ‰¹åˆ¤æ€§é‡ä¼°åŠ¿åœ¨å¿…è¡Œã€‚Yangç­‰äººï¼ˆ2024ï¼‰åœ¨è¿™ä¸€è½¬å˜ä¸­æä¾›äº†ä¸€ä¸ªå…³é”®ä¿®æ­£ã€‚ä»–ä»¬çš„å·¥ä½œæŒ‘æˆ˜äº†â€œLLMsèƒ½ä½œä¸ºå‡†ç¡®ç¤¾ä¼šé¢„æµ‹å™¨â€çš„ä¹è§‚è®ºè¿°ã€‚ä»–ä»¬è¯æ˜ï¼Œå…ˆå‰åœ¨æŠ•ç¥¨é¢„æµ‹ç­‰ä»»åŠ¡ä¸­æŠ¥å‘Šçš„æˆåŠŸï¼Œå…³é”®ä¾èµ–äºâ€œæ·å¾„ç‰¹å¾â€ï¼ˆä¾‹å¦‚ï¼Œç”¨å…šæ´¾èº«ä»½é¢„æµ‹æŠ•ç¥¨é€‰æ‹©ï¼‰ï¼Œå¹¶é€šè¿‡å¼•å…¥ä¸€ä¸ªæ–°é¢–çš„ã€æ— æ·å¾„çš„åŸºå‡†ï¼ˆSoc-PRFï¼‰ï¼Œæ­ç¤ºäº†ä¸€ä¸ªæ˜¾è‘—çš„å·®è·ã€‚åœ¨ç¼ºå°‘æ­¤ç±»æ·å¾„çš„è®¾å®šä¸­ï¼Œå³ä½¿æ˜¯æœ€å…ˆè¿›çš„LLMsè¡¨ç°ä¹Ÿå¤„äºéšæœºæ°´å¹³ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†ä¸€ä¸ªæ ¹æœ¬æ€§å±€é™ï¼šå½“å‰çš„LLMsè™½ç„¶æ˜¯ä¼˜ç§€çš„è¡¨é¢ç›¸å…³æ€§æ¨¡å¼è¯†åˆ«å™¨ï¼Œä½†ç¼ºä¹çœŸæ­£çš„ç¤¾ä¼šä»¿çœŸä»¥åŠæ¶Œç°å‡ºç¨³å¥ç¤¾ä¼šè¡Œä¸ºç†è§£æ‰€å¿…éœ€çš„ã€æ›´æ·±å±‚çš„å› æœæˆ–è¯­å¢ƒæ¨ç†èƒ½åŠ›ã€‚ä»–ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œè¦å®ç°çœŸæ­£çš„ç¤¾ä¼šæ‹ŸçœŸåº¦ï¼Œéœ€è¦è¶…è¶Šå¯¹æ•°æ®ä¸­ç»Ÿè®¡å‡è±¡çš„åˆ©ç”¨ã€‚</div></details></div></div>|

### Social Network Simulation (1 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[LIN: Latent Influence Network for Discovering Hidden Directed Influence Links on Social Media](https://ojs.aaai.org/index.php/ICWSM/article/view/35842) <br> Chenhao Gu, Zainab Razia Zaidi, Ling Luo, Shanika Karunasekera <br> 2025-06-07|\[AI generated\] LIN acts like a social X-ray, revealing hidden influence pathways by analyzing user behavior patterns.  <br>\[ç¿»è¯‘\]  <br>LINå¦‚åŒç¤¾äº¤Xå…‰ï¼Œé€šè¿‡åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼æ­ç¤ºéšè—çš„å½±å“åŠ›è·¯å¾„ã€‚|| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** \[AI generated\] To discover hidden and complex pathways of influence beyond apparent user interactions on social media. \[ç¿»è¯‘\] æ—¨åœ¨å‘ç°ç¤¾äº¤åª’ä½“ä¸Šè¶…è¶Šæ˜¾æ€§ç”¨æˆ·äº¤äº’çš„ã€éšè—ä¸”å¤æ‚çš„å½±å“è·¯å¾„ã€‚ **[innovation]** \[AI generated\] Proposes a Latent Influence Network \(LIN\) within the LIDET framework to discover hidden directed influence links from user behavior, significantly outperforming traditional models. \[ç¿»è¯‘\] æå‡ºäº†æ½œåœ¨å½±å“ç½‘ç»œï¼ˆLINï¼‰åŠLIDETæ¡†æ¶ï¼Œé€šè¿‡ç”¨æˆ·è¡Œä¸ºå‘ç°éšè—çš„æœ‰å‘å½±å“é“¾è·¯ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ¨¡å‹ã€‚ **[method]** \[AI generated\] Proposes the Latent Influence Network \(LIN\) within the LIDET framework, which identifies optimal network configurations based on user behavior labels to reveal hidden influence pathways. \[ç¿»è¯‘\] æå‡ºäº†æ½œåœ¨å½±å“ç½‘ç»œï¼ˆLINï¼‰åŠå…¶æ£€æµ‹æ¡†æ¶LIDETï¼Œè¯¥æ¡†æ¶åŸºäºç”¨æˆ·è¡Œä¸ºæ ‡ç­¾è¯†åˆ«æœ€ä¼˜ç½‘ç»œé…ç½®ï¼Œä»¥æ­ç¤ºéšè—çš„å½±å“è·¯å¾„ã€‚ **[conclusion/contribution]** \[AI generated\] LIN significantly outperforms traditional models in revealing hidden influence pathways, achieving 99% accuracy in a COVID-19 case study. \[ç¿»è¯‘\] LINåœ¨æ­ç¤ºéšè—å½±å“è·¯å¾„æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ¨¡å‹ï¼Œåœ¨COVID-19æ¡ˆä¾‹ç ”ç©¶ä¸­å®ç°äº†99%çš„åˆ†ç±»å‡†ç¡®ç‡ã€‚ **[limitation/future]** \[AI generated\] The framework&#x27;s performance heavily depends on the quality and granularity of user behavior labels, which may not always be available or reliable. \[ç¿»è¯‘\] è¯¥æ¡†æ¶çš„æ€§èƒ½ä¸¥é‡ä¾èµ–äºç”¨æˆ·è¡Œä¸ºæ ‡ç­¾çš„è´¨é‡å’Œç²’åº¦ï¼Œè€Œè¿™äº›æ ‡ç­¾å¯èƒ½å¹¶éæ€»æ˜¯å¯ç”¨æˆ–å¯é ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** \[AI generated\] To discover hidden and complex pathways of influence beyond apparent user interactions on social media.<br>\[ç¿»è¯‘\]<br>æ—¨åœ¨å‘ç°ç¤¾äº¤åª’ä½“ä¸Šè¶…è¶Šæ˜¾æ€§ç”¨æˆ·äº¤äº’çš„ã€éšè—ä¸”å¤æ‚çš„å½±å“è·¯å¾„ã€‚<br>**[innovation]** \[AI generated\] Proposes a Latent Influence Network \(LIN\) within the LIDET framework to discover hidden directed influence links from user behavior, significantly outperforming traditional models.<br>\[ç¿»è¯‘\]<br>æå‡ºäº†æ½œåœ¨å½±å“ç½‘ç»œï¼ˆLINï¼‰åŠLIDETæ¡†æ¶ï¼Œé€šè¿‡ç”¨æˆ·è¡Œä¸ºå‘ç°éšè—çš„æœ‰å‘å½±å“é“¾è·¯ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ¨¡å‹ã€‚<br>**[method]** \[AI generated\] Proposes the Latent Influence Network \(LIN\) within the LIDET framework, which identifies optimal network configurations based on user behavior labels to reveal hidden influence pathways.<br>\[ç¿»è¯‘\]<br>æå‡ºäº†æ½œåœ¨å½±å“ç½‘ç»œï¼ˆLINï¼‰åŠå…¶æ£€æµ‹æ¡†æ¶LIDETï¼Œè¯¥æ¡†æ¶åŸºäºç”¨æˆ·è¡Œä¸ºæ ‡ç­¾è¯†åˆ«æœ€ä¼˜ç½‘ç»œé…ç½®ï¼Œä»¥æ­ç¤ºéšè—çš„å½±å“è·¯å¾„ã€‚<br>**[conclusion/contribution]** \[AI generated\] LIN significantly outperforms traditional models in revealing hidden influence pathways, achieving 99% accuracy in a COVID-19 case study.<br>\[ç¿»è¯‘\]<br>LINåœ¨æ­ç¤ºéšè—å½±å“è·¯å¾„æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ¨¡å‹ï¼Œåœ¨COVID-19æ¡ˆä¾‹ç ”ç©¶ä¸­å®ç°äº†99%çš„åˆ†ç±»å‡†ç¡®ç‡ã€‚<br>**[limitation/future]** \[AI generated\] The framework's performance heavily depends on the quality and granularity of user behavior labels, which may not always be available or reliable.<br>\[ç¿»è¯‘\]<br>è¯¥æ¡†æ¶çš„æ€§èƒ½ä¸¥é‡ä¾èµ–äºç”¨æˆ·è¡Œä¸ºæ ‡ç­¾çš„è´¨é‡å’Œç²’åº¦ï¼Œè€Œè¿™äº›æ ‡ç­¾å¯èƒ½å¹¶éæ€»æ˜¯å¯ç”¨æˆ–å¯é ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">ã€ä¹‹å‰çš„ç²¾è¯»è®ºæ–‡ã€‘</div></details></div></div>|

### Macrosocial Phenomena Analysis (1 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[Understanding Online Polarization Through Human-Agent Interaction in a Synthetic LLM-Based Social...](https://ojs.aaai.org/index.php/ICWSM/article/view/35826) <br> Tim Donkers, JÃ¼rgen Ziegler <br> 2025-10-08 <br> <span style="color:cyan">[multi-categoryï¼š[Social Simulation](#Social-Simulation-3-papers), [Macrosocial Phenomena Analysis](#Macrosocial-Phenomena-Analysis-1-papers)]</span>|\[AI generated\] This study uses a digital petri dish of AI agents to observe how online echo chambers amplify human polarization. \[ç¿»è¯‘\] è¿™é¡¹ç ”ç©¶åˆ©ç”¨AIæ™ºèƒ½ä½“æ„æˆçš„æ•°å­—åŸ¹å…»çš¿ï¼Œè§‚å¯Ÿç½‘ç»œå›éŸ³å®¤å¦‚ä½•æ”¾å¤§äººç±»è§‚ç‚¹çš„æåŒ–ã€‚|| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** \[AI generated\] Investigating how polarized online environments influence individual perceptions and behaviors through controlled human-agent interaction. \[ç¿»è¯‘\] é€šè¿‡å—æ§çš„äººæœºäº¤äº’ï¼Œç ”ç©¶æåŒ–åœ¨çº¿ç¯å¢ƒå¦‚ä½•å½±å“ä¸ªä½“æ„ŸçŸ¥ä¸è¡Œä¸ºã€‚ **[innovation]** \[AI generated\] Proposes a novel human-agent interaction framework within a synthetic LLM-based social network to experimentally study polarization dynamics. \[ç¿»è¯‘\] æå‡ºäº†ä¸€ç§åœ¨åŸºäºLLMçš„åˆæˆç¤¾äº¤ç½‘ç»œä¸­è¿›è¡Œäººæœºäº¤äº’çš„æ–°é¢–æ¡†æ¶ï¼Œç”¨äºå®éªŒæ€§åœ°ç ”ç©¶æåŒ–åŠ¨æ€ã€‚ **[method]** \[AI generated\] A novel experimental framework that enables human participants to interact with LLM-based artificial agents within a controlled, synthetic social network simulation. \[ç¿»è¯‘\] ä¸€ç§æ–°é¢–çš„å®éªŒæ¡†æ¶ï¼Œä½¿äººç±»å‚ä¸è€…èƒ½å¤Ÿåœ¨å—æ§çš„åˆæˆç¤¾äº¤ç½‘ç»œæ¨¡æ‹Ÿä¸­ä¸åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„äººå·¥æ™ºèƒ½ä½“è¿›è¡Œäº’åŠ¨ã€‚ **[conclusion/contribution]** \[AI generated\] This study provides causal evidence that polarized online environments increase emotionality and group identity while reducing uncertainty, using a novel LLM-based social simulation. \[ç¿»è¯‘\] æœ¬ç ”ç©¶åˆ©ç”¨åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç¤¾äº¤æ¨¡æ‹Ÿï¼Œæä¾›äº†å› æœè¯æ®ï¼Œè¡¨æ˜æåŒ–çš„åœ¨çº¿ç¯å¢ƒä¼šå¢åŠ æƒ…ç»ªæ€§å’Œç¾¤ä½“è®¤åŒï¼ŒåŒæ—¶å‡å°‘ä¸ç¡®å®šæ€§ã€‚ **[limitation/future]** \[AI generated\] The study&#x27;s reliance on a synthetic, LLM-based simulation may limit the generalizability of its findings to real-world social media dynamics. \[ç¿»è¯‘\] è¯¥ç ”ç©¶ä¾èµ–åŸºäºLLMçš„åˆæˆæ¨¡æ‹Ÿï¼Œå…¶å‘ç°æ¨å¹¿åˆ°çœŸå®ä¸–ç•Œç¤¾äº¤åª’ä½“åŠ¨æ€çš„æ™®é€‚æ€§å¯èƒ½å—é™ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** \[AI generated\] Investigating how polarized online environments influence individual perceptions and behaviors through controlled human-agent interaction.<br>\[ç¿»è¯‘\]<br>é€šè¿‡å—æ§çš„äººæœºäº¤äº’ï¼Œç ”ç©¶æåŒ–åœ¨çº¿ç¯å¢ƒå¦‚ä½•å½±å“ä¸ªä½“æ„ŸçŸ¥ä¸è¡Œä¸ºã€‚<br>**[innovation]** \[AI generated\] Proposes a novel human-agent interaction framework within a synthetic LLM-based social network to experimentally study polarization dynamics.<br>\[ç¿»è¯‘\]<br>æå‡ºäº†ä¸€ç§åœ¨åŸºäºLLMçš„åˆæˆç¤¾äº¤ç½‘ç»œä¸­è¿›è¡Œäººæœºäº¤äº’çš„æ–°é¢–æ¡†æ¶ï¼Œç”¨äºå®éªŒæ€§åœ°ç ”ç©¶æåŒ–åŠ¨æ€ã€‚<br>**[method]** \[AI generated\] A novel experimental framework that enables human participants to interact with LLM-based artificial agents within a controlled, synthetic social network simulation.<br>\[ç¿»è¯‘\]<br>ä¸€ç§æ–°é¢–çš„å®éªŒæ¡†æ¶ï¼Œä½¿äººç±»å‚ä¸è€…èƒ½å¤Ÿåœ¨å—æ§çš„åˆæˆç¤¾äº¤ç½‘ç»œæ¨¡æ‹Ÿä¸­ä¸åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„äººå·¥æ™ºèƒ½ä½“è¿›è¡Œäº’åŠ¨ã€‚<br>**[conclusion/contribution]** \[AI generated\] This study provides causal evidence that polarized online environments increase emotionality and group identity while reducing uncertainty, using a novel LLM-based social simulation.<br>\[ç¿»è¯‘\]<br>æœ¬ç ”ç©¶åˆ©ç”¨åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç¤¾äº¤æ¨¡æ‹Ÿï¼Œæä¾›äº†å› æœè¯æ®ï¼Œè¡¨æ˜æåŒ–çš„åœ¨çº¿ç¯å¢ƒä¼šå¢åŠ æƒ…ç»ªæ€§å’Œç¾¤ä½“è®¤åŒï¼ŒåŒæ—¶å‡å°‘ä¸ç¡®å®šæ€§ã€‚<br>**[limitation/future]** \[AI generated\] The study's reliance on a synthetic, LLM-based simulation may limit the generalizability of its findings to real-world social media dynamics.<br>\[ç¿»è¯‘\]<br>è¯¥ç ”ç©¶ä¾èµ–åŸºäºLLMçš„åˆæˆæ¨¡æ‹Ÿï¼Œå…¶å‘ç°æ¨å¹¿åˆ°çœŸå®ä¸–ç•Œç¤¾äº¤åª’ä½“åŠ¨æ€çš„æ™®é€‚æ€§å¯èƒ½å—é™ã€‚</div></details></div>|

=====List End=====
## Acknowledgement