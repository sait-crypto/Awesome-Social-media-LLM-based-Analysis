# Awesome Social Media Analysis with LLM Method

> **Contributions**
>
> If you want to add your paper or update details like conference info or code URLs, please submit a pull request. You can generate the necessary markdown for each paper by filling out `generate_item.py` and running `python generate_item.py`. We greatly appreciate your contributions. Alternatively, you can email me ([Gmail](fscnkucs@gmail.com)) the links to your paper and code, and I will add your paper to the list as soon as possible.

---
<p align="center">
<img src="assets/taxonomy.png" width = "95%" alt="" align=center />
</p>


>For complete paper information, please refer to the paper_database.xlsx file.
 
>完整论文信息可以查看paper_database.xlsx文件
## Full paper list
### Quick Links

  - [Uncategorized](#Uncategorized)
  - [Hate Speech Analysis](#Hate-Speech-Analysis)
  - [Sentiment Analysis](#Sentiment-Analysis)
  - [Misinformation Analysis](#Misinformation-Analysis)
  - [Meme Analysis](#Meme-Analysis)
  - [Steganography Detection](#Steganography-Detection)
  - [Event Extraction](#Event-Extraction)
  - [Topic Modeling](#Topic-Modeling)
  - [User Opinion Mining](#User-Opinion-Mining)
  - [User Profiling](#User-Profiling)
  - [User Behavior Prediction](#User-Behavior-Prediction)
  - [Social Content Generation](#Social-Content-Generation)
  - [Information Diffusion Analysis](#Information-Diffusion-Analysis)
  - [Analysis of Collective Social Phenomena](#Analysis-of-Collective-Social-Phenomena)
  - [Other](#Other)


### Hate Speech Analysis

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-Proceedings_of_the_AAAI_Conference_on_Artificial_Intelligence-blue)]()<br>[TOT: Topology-Aware Optimal Transport for Multimodal Hate Detection](https://ojs.aaai.org/index.php/AAAI/article/view/25614) <br> Linhao Zhang，Li Jin，Xian Sun，Guangluan Xu，Zequn Zhang,Xiaoyu Li,Nayu Liu,Qing Liu,Shiyao Yan <br> 2023-06-26 00:00:00|强化恶意Meme的图像与文本之间的语义对齐，使用OT方法建立特征向量间的可解释联系|<img width="1000" alt="pipeline" src="figures/TOT.png">| <div style="line-height: 1.05;font-size: 0.5em"> <details><summary title="**[motivation]** 为了解决多模态仇恨检测中因” 隐式对齐” 和” 模态鸿沟” 导致的图像和文本跨模态语义对齐难题 **[innovation]** 将OT用于特征对齐，将句子级对齐细粒化至向量级，为后续工作提供了“显式对齐\+结构推理”的范式 **[method]** 最优传输 \+ 拓扑结构推理方法 TOT：CLIP 方法统一表征映射\-&gt;最优传输optimal transport \(OT\)将隐式联系细粒化为向量级（这是一个数学计算过程，不涉及需要学习的参数）\-&gt;类GNN迭代捕捉自身语义联系（类自注意力）（因为向量间距离意义明确）\-&gt;残差连接 **[conclusion/contribution]** 达成了在两个有害 Meme 检测数据集（Harm\-C, Harm\-P）上的最先进性能； **[limitation/future]** 对齐和推理仍局限于特征层面，未上升到语义单元（如事件、概念）层面，OT过程为冻结无法训练的，可以训练其参数以实现更好的对齐；对于幽默等类似隐式表达容易误判">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 为了解决多模态仇恨检测中因” 隐式对齐” 和” 模态鸿沟” 导致的图像和文本跨模态语义对齐难题<br>**[innovation]** 将OT用于特征对齐，将句子级对齐细粒化至向量级，为后续工作提供了“显式对齐\+结构推理”的范式<br>**[method]** 最优传输 \+ 拓扑结构推理方法 TOT：CLIP 方法统一表征映射\->最优传输optimal transport \(OT\)将隐式联系细粒化为向量级（这是一个数学计算过程，不涉及需要学习的参数）\->类GNN迭代捕捉自身语义联系（类自注意力）（因为向量间距离意义明确）\->残差连接<br>**[conclusion/contribution]** 达成了在两个有害 Meme 检测数据集（Harm\-C, Harm\-P）上的最先进性能；<br>**[limitation/future]** 对齐和推理仍局限于特征层面，未上升到语义单元（如事件、概念）层面，OT过程为冻结无法训练的，可以训练其参数以实现更好的对齐；对于幽默等类似隐式表达容易误判</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">最优传输OT负责回答“图片的哪个部分和文本的哪个词相关？”（实现统一且对齐的表示，从而建立跨模态的显式联系，OT方法是可解释的）。【即将CLIP生成的特征矩阵级别的对齐，细化为特征向量间的对齐，两个特征矩阵会更相像。这种显式对齐能力本质上来源于CLIP实现的隐对齐】；拓扑建模负责回答“这些相关的部分组合在一起，表达了什么更深层的含义？”（捕捉文本（图片）中互相有联系的token（patch），进行模态内的深度推理）。【这种类似GNN的方法本质上是更有层次性的自注意力机制，天然适用于处理关系型数据（图结构）】；本质上是将CLIP建立的隐式对齐细粒化为向量层级的显式对齐，进而得以使用图推理进一步学习内部联系</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-IEEE_Transactions_on_Multimedia-blue)]()<br>[Flexible optimal transport with contrastive graphical modeling for multimodal hate detection](https://ieeexplore.ieee.org/abstract/document/11045556) <br> Linhao Zhang，Li Jin，Xiaoyu Li,Xian Sun,Senior Member,IEEE,Xin Wang,Zequn Zhang,Jian Liu，Zhicong Lu，Graduate Student Member,IEEE,and Guangluan Xu <br> 2025|\[AI generated\] This method bridges multimodal gaps like a flexible translator, aligning implicit hateful memes through optimal transport and contrastive graphs\.|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="800" style="display:block;margin:6px auto" alt="pipeline" src="figures/FLOT1.png"><img width="800" style="display:block;margin:6px auto" alt="pipeline" src="figures/FLOT.png"></div>| <div style="line-height: 1.05;font-size: 0.5em"> <details><summary title="**[motivation]** 社媒中隐含仇恨内容检测困难，传统方法难以实现跨模态隐式对齐。 **[innovation]** 相对于同团队的TOT是改进 **[method]** 相对于同团队的TOT:1\.OT的目标域不再是另一模态的特征，而是可学习的统一嵌入（OT引入可学习的参数，它们是两个模态各自对应的目标特征矩阵 $T\_v$ 和 $T\_t$）；2\.引入了图对比学习损失，显式约束一致性（比较两个图的相似程度作为一个损失，之后才进行类GNN聚合（动态拓扑推理）） **[conclusion/contribution]** 在Harm\-C、Harm\-P、MET\-Meme三个数据集上取得SOTA，显著提升准确率与F1 **[limitation/future]** 对于幽默等类似隐式表达容易误判">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 社媒中隐含仇恨内容检测困难，传统方法难以实现跨模态隐式对齐。<br>**[innovation]** 相对于同团队的TOT是改进<br>**[method]** 相对于同团队的TOT:1\.OT的目标域不再是另一模态的特征，而是可学习的统一嵌入（OT引入可学习的参数，它们是两个模态各自对应的目标特征矩阵 $T\_v$ 和 $T\_t$）；2\.引入了图对比学习损失，显式约束一致性（比较两个图的相似程度作为一个损失，之后才进行类GNN聚合（动态拓扑推理））<br>**[conclusion/contribution]** 在Harm\-C、Harm\-P、MET\-Meme三个数据集上取得SOTA，显著提升准确率与F1<br>**[limitation/future]** 对于幽默等类似隐式表达容易误判</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-ACL_2024-blue)]()<br>[Improving Hateful Meme Detection through Retrieval-Guided Contrastive Learning](https://aclanthology.org/2024.acl-long.291) <br> Jingbiao Mei,Jinghong Chen,Weizhe Lin,Bill Byrne,Maarcus Tomalin <br> 2024|专题强化：难学样本单拉出来与正例进行对比学习，从而提高识别能力|| <div style="line-height: 1.05;font-size: 0.5em"> <details><summary title="**[motivation]** 现有CLIP等模型对仇恨表情包的图像\-文本的细微差异（如“混淆样本”）敏感度不足，导致的误判。 **[innovation]** 对于易混淆的难例（与当前样本相似度最高但标签相反的），使用\*\*动态检索\*\*方式单拉出来，与\*\*伪黄金正样本\*\*（和当前样本相似度最高的标签相同的）成对，作为正反例进行对比学习。从而解决问题 **[method]** 1\. 使用冻结的CLIP编码器提取图文特征； 2\. 通过Faiss检索动态获取同类相似样本（伪黄金正样本）与异类相似样本（困难负样本）作为正反例； 3\. 结合正反例对比损失（RGCLL）与交叉熵损失训练MLP； 4\. 实现逻辑分类与KNN检索分类两种分类器，后者通过相似度加权投票进行预测。 **[conclusion/contribution]** 在HatefulMemes数据集上达到 AUROC 87\.0%（SOTA），超越Flamingo\-80B等大型多模态模型 **[limitation/future]** 仇恨言论的定义具有争议性与文化依赖性；系统对 细微面部表情 识别能力有限；依赖数据标注质量，可能存在标注偏差。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 现有CLIP等模型对仇恨表情包的图像\-文本的细微差异（如“混淆样本”）敏感度不足，导致的误判。<br>**[innovation]** 对于易混淆的难例（与当前样本相似度最高但标签相反的），使用\*\*动态检索\*\*方式单拉出来，与\*\*伪黄金正样本\*\*（和当前样本相似度最高的标签相同的）成对，作为正反例进行对比学习。从而解决问题<br>**[method]** 1\. 使用冻结的CLIP编码器提取图文特征；<br>2\. 通过Faiss检索动态获取同类相似样本（伪黄金正样本）与异类相似样本（困难负样本）作为正反例；<br>3\. 结合正反例对比损失（RGCLL）与交叉熵损失训练MLP；<br>4\. 实现逻辑分类与KNN检索分类两种分类器，后者通过相似度加权投票进行预测。<br>**[conclusion/contribution]** 在HatefulMemes数据集上达到 AUROC 87\.0%（SOTA），超越Flamingo\-80B等大型多模态模型<br>**[limitation/future]** 仇恨言论的定义具有争议性与文化依赖性；系统对 细微面部表情 识别能力有限；依赖数据标注质量，可能存在标注偏差。</div></details></div>|

### Sentiment Analysis

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-Proceedings_of_the_AAAI_Conference_on_Artificial_Intelligence-blue)]()<br>[CAMEL: Capturing metaphorical alignment with context disentangling for multimodal emotion recogni...](https://ojs.aaai.org/index.php/AAAI/article/view/28787) <br> Linhao Zhang,Li Jin\*,Guangluan Xu,Xiaoyu Li,Cai Xu,Kaiwen Wei,Nayu Liu,Haonan Liu <br> 2024-03-24 00:00:00|\[AI generated\] CAMEL disentangles metaphorical alignment like a prism separating light, then adapts it to context for precise emotion recognition\.|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="800" style="display:block;margin:6px auto" alt="pipeline" src="figures/CAMEL1.png"><img width="800" style="display:block;margin:6px auto" alt="pipeline" src="figures/CAMEL.png"></div>| <div style="line-height: 1.05;font-size: 0.5em"> <details><summary title="**[motivation]** 为了解决多模态内容中因隐喻对齐导致\*\*情感误判\*\*的问题：之前的方法本质上无法理解隐喻,专注于直接的语义对齐，无法捕捉如文字“眼泪”与图片“河流”的这种隐式联系 **[innovation]** 将多模态间隐含联系的对齐思想应用于多模态情感识别领域 **[method]** 使用了基于条件生成与解耦上下文适应的CAMEL框架:隐喻对齐建模（条件生成）\(强制模型按照模版输出（CMT和SPV两种技术）；使用图片、标题、文本的交叉注意力机制，使用一个\[CLS\] token聚合全局信息）\-&gt;上下文语义适应（特征融合）（使用两个异构模型，分别输入字面特征（CAMEL\-C，CMT）和隐喻特征（CAMEL\-S，SPV）生成两个向量矩阵，通过隐喻查字面实现多头注意力）\-&gt;解耦对比匹配（上下文正则化）（确保不偏离语境。采用解耦学习思想，隐喻特征中分离出代表“主导上下文类别”的离散分布，通过对比学习，使字面特征推出的分布与之对齐） **[conclusion/contribution]** 达成了对隐含情感更精准、鲁棒的识别效果 **[limitation/future]** 整个方法框架复杂，模型所需的所有能力：找字面特征、找隐喻特征、两者对齐、根据融合特征生成情感分析，都是一次训练完成的，是否难以收敛（虽然论文使用了课程学习策略），是否能够在训练层面进行一定的解耦？分别训练各能力">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 为了解决多模态内容中因隐喻对齐导致\*\*情感误判\*\*的问题：之前的方法本质上无法理解隐喻,专注于直接的语义对齐，无法捕捉如文字“眼泪”与图片“河流”的这种隐式联系<br>**[innovation]** 将多模态间隐含联系的对齐思想应用于多模态情感识别领域<br>**[method]** 使用了基于条件生成与解耦上下文适应的CAMEL框架:隐喻对齐建模（条件生成）\(强制模型按照模版输出（CMT和SPV两种技术）；使用图片、标题、文本的交叉注意力机制，使用一个\[CLS\] token聚合全局信息）\->上下文语义适应（特征融合）（使用两个异构模型，分别输入字面特征（CAMEL\-C，CMT）和隐喻特征（CAMEL\-S，SPV）生成两个向量矩阵，通过隐喻查字面实现多头注意力）\->解耦对比匹配（上下文正则化）（确保不偏离语境。采用解耦学习思想，隐喻特征中分离出代表“主导上下文类别”的离散分布，通过对比学习，使字面特征推出的分布与之对齐）<br>**[conclusion/contribution]** 达成了对隐含情感更精准、鲁棒的识别效果<br>**[limitation/future]** 整个方法框架复杂，模型所需的所有能力：找字面特征、找隐喻特征、两者对齐、根据融合特征生成情感分析，都是一次训练完成的，是否难以收敛（虽然论文使用了课程学习策略），是否能够在训练层面进行一定的解耦？分别训练各能力</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">首先通过多头跨域注意力机制实现初步的对齐，然后让字面特征的分布与隐喻特征的分布对齐，进一步强化对齐；</div></details></div></div>|

### Misinformation Analysis

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-Proceedings_of_the_AAAI_Conference_on_Artificial_Intelligence-blue)]()<br>[GAMC: An Unsupervised Method for Fake News Detection Using Graph Autoencoder with Masking](https://ojs.aaai.org/index.php/AAAI/article/view/27788) <br> Shu Yin,Peican Zhu,Lianwei Wu,Chao Gao,Zhen Wang <br> 2024-03-24 00:00:00|自编码器方法处理类社交网络图结构|<img width="1000" alt="pipeline" src="figures/GAMC.png">| <div style="line-height: 1.05;font-size: 0.5em"> <details><summary title="**[motivation]** 现有方法多依赖新闻内容或需大量标注数据，难以有效利用传播上下文信息。 **[innovation]** 首个结合图自编码器、掩码与对比学习的无监督假新闻检测方法，同时利用传播结构与内容信息，无需标注数据 **[method]** 1\. 将新闻传播建模为图（新闻节点和用户节点，边表示转发关系，节点特征来自新闻内容和用户历史贴文）； 2\. 数据增强（节点特征掩码\+边丢弃）（随机选取节点将其特征替换为掩码标记，随机删除部分边）构造自监督特性； 3\. 图编码器（GIN）生成潜在表示； 4\. 图解码器重建特征； 5\. 损失函数组成（\*\*重建损失\*\*（使重建特征接近原始特征）\+\*\*对比损失\*\*（来自同一个原始图的两个增强图重建后应尽量相似））训练。 **[conclusion/contribution]** 在 FakeNewsNet 数据集上，GAMC 在无监督方法中表现最佳（如 GossipCop 准确率 0\.946），甚至接近或超越部分监督方法 **[limitation/future]** 需要新闻具有一定的传播量才能建模为图；早期传播阶段检测能力受限">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 现有方法多依赖新闻内容或需大量标注数据，难以有效利用传播上下文信息。<br>**[innovation]** 首个结合图自编码器、掩码与对比学习的无监督假新闻检测方法，同时利用传播结构与内容信息，无需标注数据<br>**[method]** 1\. 将新闻传播建模为图（新闻节点和用户节点，边表示转发关系，节点特征来自新闻内容和用户历史贴文）；<br>2\. 数据增强（节点特征掩码\+边丢弃）（随机选取节点将其特征替换为掩码标记，随机删除部分边）构造自监督特性；<br>3\. 图编码器（GIN）生成潜在表示；<br>4\. 图解码器重建特征；<br>5\. 损失函数组成（\*\*重建损失\*\*（使重建特征接近原始特征）\+\*\*对比损失\*\*（来自同一个原始图的两个增强图重建后应尽量相似））训练。<br>**[conclusion/contribution]** 在 FakeNewsNet 数据集上，GAMC 在无监督方法中表现最佳（如 GossipCop 准确率 0\.946），甚至接近或超越部分监督方法<br>**[limitation/future]** 需要新闻具有一定的传播量才能建模为图；早期传播阶段检测能力受限</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-Companion_Proceedings_of_the_Web_Conference_2021-blue)]()<br>[How does truth evolve into fake news? An empirical study of fake news evolution](https://dl.acm.org/doi/10.1145/3442442.3452328) <br> Mingfei Guo，Xiuying Chen，Juntao Li，Dongyan Zhao，Rui Yan <br> 2021-06-03 00:00:00|一个包含\[原始新闻、假新闻、演化后的假新闻\]三元组的数据集|<img width="1000" alt="pipeline" src="figures/FNE.png">| <div style="line-height: 1.05;font-size: 0.5em"> <details><summary title="**[motivation]** 而现有数据集多关注静态标注，缺乏对其假新闻演化过程的研究 **[innovation]** 给出了关注假新闻演化的数据集FNE，包含“真相\-虚假新闻\-演化虚假新闻”三元组 **[method]** 1\. 从 Snopes\.com\(一个辟谣网站\) 抓取truth文章； 2\. 通过其引文收集虚假新闻； 3\. 利用网页存档平台（如 Archive Today）获取演化后版本； 4\. 分析虚假信息技术分类（捏造、否认、混淆、歪曲四类、文本相似度、关键词、词性、情感等属性。 **[conclusion/contribution]** 演化后虚假新闻与原始虚假新闻相似度更高，情感更客观积极，更难以被现有分类模型检测；虚假信息技术中以“捏造”为主；词性和关键词在演化中保持稳定。 **[limitation/future]** 数据来源依赖单一事实核查网站（Snopes），可能引入偏见；仅关注文本新闻，未涵盖图像、视频等多模态演变；">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 而现有数据集多关注静态标注，缺乏对其假新闻演化过程的研究<br>**[innovation]** 给出了关注假新闻演化的数据集FNE，包含“真相\-虚假新闻\-演化虚假新闻”三元组<br>**[method]** 1\. 从 Snopes\.com\(一个辟谣网站\) 抓取truth文章；<br>2\. 通过其引文收集虚假新闻；<br>3\. 利用网页存档平台（如 Archive Today）获取演化后版本；<br>4\. 分析虚假信息技术分类（捏造、否认、混淆、歪曲四类、文本相似度、关键词、词性、情感等属性。<br>**[conclusion/contribution]** 演化后虚假新闻与原始虚假新闻相似度更高，情感更客观积极，更难以被现有分类模型检测；虚假信息技术中以“捏造”为主；词性和关键词在演化中保持稳定。<br>**[limitation/future]** 数据来源依赖单一事实核查网站（Snopes），可能引入偏见；仅关注文本新闻，未涵盖图像、视频等多模态演变；</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-Proceedings_of_the_AAAI_Conference_on_Artificial_Intelligence-blue)]()<br>[Learning Complex Heterogeneous Multimodal Fake News via Social Latent Network Inference](https://ojs.aaai.org/index.php/AAAI/article/view/32022) <br> Mingxin Li,Yuchen Zhang,Haowei Xu,Xianghua Li\*,Chao Gao,Zhen Wang <br> 2025-04-11 00:00:00|通过社交潜在网络推断与自监督多模态学习检测复杂异质多模态假新闻的GNN方法|<img width="1000" alt="pipeline" src="figures/HML.png">| <div style="line-height: 1.05;font-size: 0.5em"> <details><summary title="**[motivation]** 社交平台多元化导致新闻传播复杂、多模态，传统假新闻检测方法依赖显式传播关系（如转发），在抖音等平台难以直接获取，检测难度大。 **[innovation]** 提出“社交潜在网络推断Latent Network Inference”策略，无需真实传播关系，即可构建新闻间的潜在联系 **[method]** 1\. 社交潜在网络推断：基于Hawkes Process建模新闻影响力随时间变化，得到事件内部与事件间的影响强度，推断出潜在传播网络。 2\. 异质图构建：节点均为新闻，边类型基于各种相同或相似属性（如作者、标题、时间等）构建。使用\*\*注意力机制\*\*动态融合不同边类型，生成统一的异质图表示（每个类型的边看做一个“头”，利用多头注意力方法） 3\. 自监督多模态内容学习：损失函数：单模态增强（对同一模态进行掩码与重构）、跨模态对比学习（对齐不同模态（如文本与视频）的特征，通过对比学习拉近正样本、推开负样本） 4\. 个性化图表示与分类：使用图Transformer Encoder融合图结构与模态特征，进行分类。 **[conclusion/contribution]** FakeSV和FVC数据集上准确率均超89%，较SOTA提升0\.12%~4\.39%；在Twitter/微博作为插件也提升明显（最高\+10\.71% F1） **[limitation/future]** 依赖事件定义与时间序列假设，对实时性要求高；计算复杂度较高">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 社交平台多元化导致新闻传播复杂、多模态，传统假新闻检测方法依赖显式传播关系（如转发），在抖音等平台难以直接获取，检测难度大。<br>**[innovation]** 提出“社交潜在网络推断Latent Network Inference”策略，无需真实传播关系，即可构建新闻间的潜在联系<br>**[method]** 1\. 社交潜在网络推断：基于Hawkes Process建模新闻影响力随时间变化，得到事件内部与事件间的影响强度，推断出潜在传播网络。<br>2\. 异质图构建：节点均为新闻，边类型基于各种相同或相似属性（如作者、标题、时间等）构建。使用\*\*注意力机制\*\*动态融合不同边类型，生成统一的异质图表示（每个类型的边看做一个“头”，利用多头注意力方法）<br>3\. 自监督多模态内容学习：损失函数：单模态增强（对同一模态进行掩码与重构）、跨模态对比学习（对齐不同模态（如文本与视频）的特征，通过对比学习拉近正样本、推开负样本）<br>4\. 个性化图表示与分类：使用图Transformer Encoder融合图结构与模态特征，进行分类。<br>**[conclusion/contribution]** FakeSV和FVC数据集上准确率均超89%，较SOTA提升0\.12%~4\.39%；在Twitter/微博作为插件也提升明显（最高\+10\.71% F1）<br>**[limitation/future]** 依赖事件定义与时间序列假设，对实时性要求高；计算复杂度较高</div></details></div>|

### Event Extraction

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-Proceedings_of_the_2023_Conference_on_Empirical_Methods_in_Natural_Language_Processing-blue)]()<br>[Event causality extraction via implicit cause-effect interactions](https://aclanthology.org/2023.emnlp-main.420) <br> Jintao Liu,Zequn Zhang,Kaiwen Wei,Zhi Guo,Xian Sun,Li Jin,Xiaoyu Li <br> 2023|通过OT强制学生模型与教师模型对齐|<img width="1000" alt="pipeline" src="figures/ICE.png">| <div style="line-height: 1.05;font-size: 0.5em"> <details><summary title="**[motivation]** 现有ECE（事件因果关系抽取）方式没有充分利用原因事件和结果事件之间的相互作用。这本可以为因果关系推理提供关键线索 **[innovation]** 论文解耦ECE的两个任务（论元抽取、结果事件预测），并使用OT进行教师模型和学生模型的细粒度对齐，增强了因果事件之间的隐式联系 **[method]** 基于模板的条件生成（输入基于模板附有特定特权信息的prompt，使预训练模型BART（基于transformer）输出基于模板的结构化的文本，用于后续微调）\-&gt;教师\-学生知识蒸馏（微调了两个教师模型负责不同任务：事件论元抽取、结果事件预测）\-&gt;因果最优传输CEOT（相关损失并入蒸馏损失，参与蒸馏训练，学生模型与教师模型细粒度对齐） **[conclusion/contribution]** ECE任务中显著提升了性能，ECE\-CCKS数据集上比此前最优方法F1值提高了8\.39% **[limitation/future]** 多教师蒸馏机制和复杂的OT计算显著增加了模型训练阶段的成本">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 现有ECE（事件因果关系抽取）方式没有充分利用原因事件和结果事件之间的相互作用。这本可以为因果关系推理提供关键线索<br>**[innovation]** 论文解耦ECE的两个任务（论元抽取、结果事件预测），并使用OT进行教师模型和学生模型的细粒度对齐，增强了因果事件之间的隐式联系<br>**[method]** 基于模板的条件生成（输入基于模板附有特定特权信息的prompt，使预训练模型BART（基于transformer）输出基于模板的结构化的文本，用于后续微调）\->教师\-学生知识蒸馏（微调了两个教师模型负责不同任务：事件论元抽取、结果事件预测）\->因果最优传输CEOT（相关损失并入蒸馏损失，参与蒸馏训练，学生模型与教师模型细粒度对齐）<br>**[conclusion/contribution]** ECE任务中显著提升了性能，ECE\-CCKS数据集上比此前最优方法F1值提高了8\.39%<br>**[limitation/future]** 多教师蒸馏机制和复杂的OT计算显著增加了模型训练阶段的成本</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">❔这个方法为什么可以解决问题？<br>    核心方法是使用优秀的专家模型对小模型进行微调，结合了5个小损失函数（两个来源于OT），以尽可能保证知识迁移效果<br><br>❔有什么值得注意的细节吗？<br>    📝论文为什么选择训练两个承担不同任务的教师模型，一起蒸馏出目标模型的方法<br>        这几乎是进行微调特化用于该下游任务的必然选择<br>        因为需要训练两个能力（子任务）：文本论元抽取能力（事件内交互）和事件结果联系能力（事件间）<br>        两个子任务需要分别调整数据集的输入，为他们分配不同的特权信息，从而避免混淆和出现“作弊”（看到这个子任务不应看到的特权信息）</div></details></div></div>|

### Other

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
|[![Star](https://img.shields.io/github/stars/OpenBMB/IoA.svg?style=social&label=Star)](https://github.com/OpenBMB/IoA) [![Publish](https://img.shields.io/badge/Conference-The_Thirteenth_International_Conference_on_Learning_Representations-blue)]()<br>[Internet of agents: Weaving a web of heterogeneous agents for collaborative intelligence](https://openreview.net/forum?id=o1Et3MogPw) <br> Weize Chen\*, Ziming You\*, Ran Li\*, Yitong Guan\*, Chen Qian, Chenyang Zhao Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun <br> 2024-10-04 00:00:00|agent互联网，升级版ABM系统，采用类似互联网思想，C/S架构，分布化、服务化、平台化|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="800" style="display:block;margin:6px auto" alt="pipeline" src="figures/IoA.png"><img width="800" style="display:block;margin:6px auto" alt="pipeline" src="figures/IoA2.png"></div>| <div style="line-height: 1.05;font-size: 0.5em"> <details><summary title="**[motivation]** 先前的multi\-agent系统的局限性，系统化平台化程度不足（缺乏第三方集成支持，无法分布式，通信协议和状态转换依赖于硬编码） **[innovation]** 将互联网的开放、分布式、服务化思想引入，构建一种标准化、可扩展的支持分布式、异构的智能体集成与通信协议。 **[method]** 服务器：智能体注册（分发系统提示词）、管理已注册智能体（专家）、专家发现服务、群聊管理和消息传递；客户端：包装具体智能体，提供通信接口；三层结构；通信即可嵌套灵活群聊；群聊采用\*\*有限状态机\*\*管理流程；平台初始化与注册\-&gt;任务触发团队形成\-&gt;内部嵌套协作 **[conclusion/contribution]** 在 GAIA 基准测试中，仅使用四个基础 ReAct 智能体即达到最佳性能；在 RAG 任务中，基于 GPT\-3\.5 的 IoA 达到或超过 GPT\-4 的性能 **[limitation/future]** 实验中存在冗余消息，通信 Token 消耗增加近一倍，这证明agent作为对话者而非执行者的本质能力区别；单点服务器可能存在瓶颈；智能体通过注册获取提示词成为不同专家，仍高度依赖人工实验设计，且这种专家的能力是否可靠">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 先前的multi\-agent系统的局限性，系统化平台化程度不足（缺乏第三方集成支持，无法分布式，通信协议和状态转换依赖于硬编码）<br>**[innovation]** 将互联网的开放、分布式、服务化思想引入，构建一种标准化、可扩展的支持分布式、异构的智能体集成与通信协议。<br>**[method]** 服务器：智能体注册（分发系统提示词）、管理已注册智能体（专家）、专家发现服务、群聊管理和消息传递；客户端：包装具体智能体，提供通信接口；三层结构；通信即可嵌套灵活群聊；群聊采用\*\*有限状态机\*\*管理流程；平台初始化与注册\->任务触发团队形成\->内部嵌套协作<br>**[conclusion/contribution]** 在 GAIA 基准测试中，仅使用四个基础 ReAct 智能体即达到最佳性能；在 RAG 任务中，基于 GPT\-3\.5 的 IoA 达到或超过 GPT\-4 的性能<br>**[limitation/future]** 实验中存在冗余消息，通信 Token 消耗增加近一倍，这证明agent作为对话者而非执行者的本质能力区别；单点服务器可能存在瓶颈；智能体通过注册获取提示词成为不同专家，仍高度依赖人工实验设计，且这种专家的能力是否可靠</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">每个agent被一个客户端包装；服务器不是agent，它只做四件事：注册、发现、建群、路由；相对于传统ABM，这是一个更大型的服务系统，该方法通过基于任务的“群聊”方式组织问题解决，相对传统回合制方式更加自由。本身也是一个高度可扩展系统。问题在于智能体通过注册获取提示词成为不同专家，仍依赖手工设计，且这种专家的能力是否可靠。对于社会模拟任务相对于传统方法有何决定性优势仍未可知</div></details></div></div>|

=====List End=====
## Acknowledgement