# Awesome Social Media Analysis with LLM Method

> **Contributions**
>
> If you want to add your paper or update details like conference info or code URLs, please submit a pull request. You can generate the necessary markdown for each paper by filling out `generate_item.py` and running `python generate_item.py`. We greatly appreciate your contributions. Alternatively, you can email me ([Gmail](fscnkucs@gmail.com)) the links to your paper and code, and I will add your paper to the list as soon as possible.

---
<p align="center">
<img src="assets/taxonomy.png" width = "95%" alt="" align=center />
</p>

>For complete paper information, please refer to the paper_database.xlsx file.
><br>å®Œæ•´è®ºæ–‡ä¿¡æ¯å¯ä»¥æŸ¥çœ‹paper_database.xlsxæ–‡ä»¶

**Key Points for Table Usage**
- <b>Paper Link</b>: Please click the paper title
- <b>Paper Project Link</b>: Please click the GitHub icon or Project icon above the paper title
- <b>Summary</b> and <b>Notes</b> can be expanded by clicking

**è¡¨æ ¼ä½¿ç”¨è¦ç‚¹**
- <b>è®ºæ–‡é“¾æ¥</b>:è¯·ç‚¹å‡»è®ºæ–‡æ ‡é¢˜
- <b>è®ºæ–‡é¡¹ç›®é“¾æ¥</b>:è¯·ç‚¹å‡»è®ºæ–‡æ ‡é¢˜ä¸Šæ–¹çš„githubæ ‡æˆ–projectæ ‡
- <b>Summary</b>å’Œ<b>Notes</b>å¯ä»¥ç‚¹å‡»å±•å¼€

## Full paper list (19 papers)
### Quick Links

  - [Uncategorized](#-Uncategorized-0-papers) (0 papers)
  - [Base Techniques](#-Base-Techniques-2-papers) (2 papers)
  - [Perception and Classification](#-Perception-and-Classification-12-papers) (12 papers)
    - [Hate Speech Analysis](#Hate-Speech-Analysis-4-papers) (4 papers)
    - [Misinformation Analysis](#Misinformation-Analysis-5-papers) (5 papers)
    - [Sentiment Analysis](#Sentiment-Analysis-3-papers) (3 papers)
    - [Meme Analysis](#Meme-Analysis-0-papers) (0 papers)
    - [Steganography Detection](#Steganography-Detection-0-papers) (0 papers)
    - [User Stance Detection](#User-Stance-Detection-0-papers) (0 papers)
    - [Malicious Bot Detection](#Malicious-Bot-Detection-0-papers) (0 papers)
    - [User Behavior Prediction](#User-Behavior-Prediction-0-papers) (0 papers)
  - [Understanding](#-Understanding-3-papers) (3 papers)
    - [Event Extraction](#Event-Extraction-3-papers) (3 papers)
    - [Topic Modeling](#Topic-Modeling-0-papers) (0 papers)
    - [Social Psychological Phenomena Analysis](#Social-Psychological-Phenomena-Analysis-0-papers) (0 papers)
    - [Social Popularity Prediction](#Social-Popularity-Prediction-0-papers) (0 papers)
    - [User Identity Understanding](#User-Identity-Understanding-0-papers) (0 papers)
    - [User Profiling](#User-Profiling-0-papers) (0 papers)
  - [Generation](#-Generation-1-papers) (1 papers)
    - [Comment Generation](#Comment-Generation-1-papers) (1 papers)
    - [Debate Generation](#Debate-Generation-0-papers) (0 papers)
    - [Rumor Refutation Generation](#Rumor-Refutation-Generation-0-papers) (0 papers)
    - [Psychological Healing](#Psychological-Healing-0-papers) (0 papers)
    - [Misinformation Generation](#Misinformation-Generation-0-papers) (0 papers)
    - [Social Bots](#Social-Bots-0-papers) (0 papers)
  - [Simulation and Deduction](#-Simulation-and-Deduction-2-papers) (2 papers)
    - [Dynamic Community Analysis](#Dynamic-Community-Analysis-0-papers) (0 papers)
    - [Information Diffusion Analysis](#Information-Diffusion-Analysis-0-papers) (0 papers)
    - [Social Simulation](#Social-Simulation-2-papers) (2 papers)
    - [Social Network Simulation](#Social-Network-Simulation-0-papers) (0 papers)
    - [Town/Community Simulation](#TownCommunity-Simulation-0-papers) (0 papers)
    - [Game Simulation](#Game-Simulation-0-papers) (0 papers)
    - [Family Simulation](#Family-Simulation-0-papers) (0 papers)
    - [Macrosocial Phenomena Analysis](#Macrosocial-Phenomena-Analysis-0-papers) (0 papers)
    - [Frontier Applications](#Frontier-Applications-0-papers) (0 papers)
  - [Social Media Security](#-Social-Media-Security-0-papers) (0 papers)
  - [Other](#-Other-0-papers) (0 papers)


### | Base Techniques (2 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
|[![Project](https://img.shields.io/badge/Project-View-blue)](https://netsys.surrey.ac.uk/datasets/slashdot/) [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Conversation Kernels: A Flexible Mechanism to Learn Relevant Context for Online Conversation Unde...](https://ojs.aaai.org/index.php/ICWSM/article/view/35800) <br> to be filled in <br> 2025-06-07 <br> <span style="color:cyan">[multi-categoryï¼š[Base Techniques](#-Base-Techniques-2-papers), [Comment Generation](#Comment-Generation-1-papers)]</span>|A flexible, structural context discovery framework that enhances conversation understanding by learning to attend to relevant topological neighborhoods within conversation trees.\[ç¿»è¯‘\] ä¸€ä¸ªçµæ´»çš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡å‘ç°æ¡†æ¶ï¼Œé€šè¿‡å­¦ä¹ å…³æ³¨å¯¹è¯æ ‘å†…ç›¸å…³çš„æ‹“æ‰‘é‚»åŸŸæ¥å¢å¼ºå¯¹è¯ç†è§£èƒ½åŠ›ã€‚|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Conversation Kernels-Conversa-1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Conversation Kernels2-Conversa-1.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Addressing the sparsity and context-dependency of individual online utterances, where traditional models often fail to capture implicit dependencies within conversation trees or introduce noise through indiscriminate context inclusion. \[ç¿»è¯‘\] é’ˆå¯¹åœ¨çº¿è¨€è®ºå›ºæœ‰çš„ç¨€ç–æ€§å’Œè¯­å¢ƒä¾èµ–æ€§é—®é¢˜ï¼Œå³ä¼ ç»Ÿæ¨¡å‹å¾€å¾€éš¾ä»¥æ•æ‰å¯¹è¯æ ‘å†…çš„éšå¼ä¾èµ–å…³ç³»ï¼Œæˆ–å› æ— å·®åˆ«åœ°å¼•å…¥ä¸Šä¸‹æ–‡è€Œäº§ç”Ÿå™ªå£° **[innovation]** The proposal of &quot;Conversation Kernels,&quot; a general-purpose mechanism that employs flexible topological shapes to retrieve fine-grained, structured conversational context, distinguishing itself by identifying the &quot;right&quot; structural neighborhood rather than merely increasing context length. \[ç¿»è¯‘\] æå‡ºäº†â€œå¯¹è¯æ ¸â€è¿™ä¸€é€šç”¨æœºåˆ¶ï¼Œåˆ©ç”¨çµæ´»çš„æ‹“æ‰‘å½¢çŠ¶æ¥æ£€ç´¢ç»†ç²’åº¦çš„ç»“æ„åŒ–å¯¹è¯ä¸Šä¸‹æ–‡ï¼›å…¶ç‹¬åˆ°ä¹‹å¤„åœ¨äºé€šè¿‡è¯†åˆ«â€œæ­£ç¡®â€çš„ç»“æ„é‚»åŸŸè€Œéå•çº¯å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦æ¥ç†è§£å¯¹è¯ã€‚ **[method]** An end-to-end trained probabilistic framework that first retrieves relevant structural windows \(e.g., ancestors, neighbors\) via similarity scoring, and subsequently fuses these contexts through a weighted marginalization of the predictive distributions generated by a RoBERTa-based encoder. \[ç¿»è¯‘\] ä¸€ä¸ªç«¯åˆ°ç«¯è®­ç»ƒçš„æ¦‚ç‡æ¡†æ¶ï¼Œé¦–å…ˆé€šè¿‡ç›¸ä¼¼åº¦è¯„åˆ†æ£€ç´¢ç›¸å…³çš„ç»“æ„åŒ–çª—å£ï¼ˆå¦‚ç¥–å…ˆã€é‚»å±…ï¼‰ï¼Œéšåé€šè¿‡å¯¹RoBERTaç¼–ç å™¨ç”Ÿæˆçš„é¢„æµ‹åˆ†å¸ƒè¿›è¡ŒåŠ æƒæ±‚å’Œï¼ˆè¾¹ç¼˜åŒ–ï¼‰ï¼Œä»è€Œèåˆè¿™äº›ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\[é€šä¿—æ ¸å¿ƒ\]é’ˆå¯¹ç›®æ ‡è¯„è®ºæ„å»ºå›å¤æ ‘ï¼Œå–å‡ ä¸ªçª—å£ï¼ˆå¦‚çˆ¶è¯„è®ºçª—å£ã€1è·³çª—å£ï¼‰ï¼Œæ¯ä¸ªçª—å£ä¸­æ‰€æœ‰è¯„è®ºä¸åŸè¯„è®ºæ‹¼æ¥ï¼Œå¹¶è¿›è¡Œé¢„æµ‹ï¼Œæœ€åä¸åŒçª—å£ä¸åŸè¯„è®ºçš„ç›¸å…³æ€§ç»è¿‡softmaxä½œä¸ºæƒé‡ï¼Œå¯¹æ‰€æœ‰é¢„æµ‹ç½®ä¿¡åº¦åŠ æƒå’Œï¼Œå¾—åˆ°æœ€ç»ˆç»“æœ **[conclusion/contribution]** Extensive experiments on Slashdot data demonstrate that context-augmented kernels outperform baseline transformers by up to 20% in accuracy and surpass general-purpose LLMs \(GPT-3.5/4\) in specific categorization tasks, revealing that different tasks require distinct structural context patterns. \[ç¿»è¯‘\] åœ¨Slashdotæ•°æ®ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œä¸Šä¸‹æ–‡å¢å¼ºçš„æ ¸æœºåˆ¶åœ¨å‡†ç¡®ç‡ä¸Šæ¯”åŸºçº¿Transformeræ¨¡å‹é«˜å‡º20%ï¼Œå¹¶åœ¨ç‰¹å®šåˆ†ç±»ä»»åŠ¡ä¸­è¶…è¶Šäº†é€šç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆGPT-3.5/4ï¼‰ï¼Œæ­ç¤ºäº†ä¸åŒä»»åŠ¡éœ€è¦æˆªç„¶ä¸åŒçš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ¨¡å¼ã€‚ **[limitation/future]** The approach relies heavily on explicit tree-structured reply threads, limiting applicability in flat discussion formats, and may face cold-start challenges in early-stage conversations with sparse context. \[ç¿»è¯‘\] è¯¥æ–¹æ³•ä¸¥é‡ä¾èµ–æ˜¾å¼çš„æ ‘çŠ¶å›å¤çº¿ç´¢ï¼Œé™åˆ¶äº†å…¶åœ¨æ‰å¹³åŒ–è®¨è®ºå½¢å¼ä¸­çš„é€‚ç”¨æ€§ï¼Œå¹¶ä¸”åœ¨ä¸Šä¸‹æ–‡ç¨€ç–çš„å¯¹è¯æ—©æœŸé˜¶æ®µå¯èƒ½é¢ä¸´å†·å¯åŠ¨æŒ‘æˆ˜ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Addressing the sparsity and context-dependency of individual online utterances, where traditional models often fail to capture implicit dependencies within conversation trees or introduce noise through indiscriminate context inclusion.<br>\[ç¿»è¯‘\] é’ˆå¯¹åœ¨çº¿è¨€è®ºå›ºæœ‰çš„ç¨€ç–æ€§å’Œè¯­å¢ƒä¾èµ–æ€§é—®é¢˜ï¼Œå³ä¼ ç»Ÿæ¨¡å‹å¾€å¾€éš¾ä»¥æ•æ‰å¯¹è¯æ ‘å†…çš„éšå¼ä¾èµ–å…³ç³»ï¼Œæˆ–å› æ— å·®åˆ«åœ°å¼•å…¥ä¸Šä¸‹æ–‡è€Œäº§ç”Ÿå™ªå£°<br>**[innovation]** The proposal of "Conversation Kernels," a general-purpose mechanism that employs flexible topological shapes to retrieve fine-grained, structured conversational context, distinguishing itself by identifying the "right" structural neighborhood rather than merely increasing context length.<br>\[ç¿»è¯‘\] æå‡ºäº†â€œå¯¹è¯æ ¸â€è¿™ä¸€é€šç”¨æœºåˆ¶ï¼Œåˆ©ç”¨çµæ´»çš„æ‹“æ‰‘å½¢çŠ¶æ¥æ£€ç´¢ç»†ç²’åº¦çš„ç»“æ„åŒ–å¯¹è¯ä¸Šä¸‹æ–‡ï¼›å…¶ç‹¬åˆ°ä¹‹å¤„åœ¨äºé€šè¿‡è¯†åˆ«â€œæ­£ç¡®â€çš„ç»“æ„é‚»åŸŸè€Œéå•çº¯å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦æ¥ç†è§£å¯¹è¯ã€‚<br>**[method]** An end-to-end trained probabilistic framework that first retrieves relevant structural windows \(e.g., ancestors, neighbors\) via similarity scoring, and subsequently fuses these contexts through a weighted marginalization of the predictive distributions generated by a RoBERTa-based encoder.<br>\[ç¿»è¯‘\] ä¸€ä¸ªç«¯åˆ°ç«¯è®­ç»ƒçš„æ¦‚ç‡æ¡†æ¶ï¼Œé¦–å…ˆé€šè¿‡ç›¸ä¼¼åº¦è¯„åˆ†æ£€ç´¢ç›¸å…³çš„ç»“æ„åŒ–çª—å£ï¼ˆå¦‚ç¥–å…ˆã€é‚»å±…ï¼‰ï¼Œéšåé€šè¿‡å¯¹RoBERTaç¼–ç å™¨ç”Ÿæˆçš„é¢„æµ‹åˆ†å¸ƒè¿›è¡ŒåŠ æƒæ±‚å’Œï¼ˆè¾¹ç¼˜åŒ–ï¼‰ï¼Œä»è€Œèåˆè¿™äº›ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\[é€šä¿—æ ¸å¿ƒ\]é’ˆå¯¹ç›®æ ‡è¯„è®ºæ„å»ºå›å¤æ ‘ï¼Œå–å‡ ä¸ªçª—å£ï¼ˆå¦‚çˆ¶è¯„è®ºçª—å£ã€1è·³çª—å£ï¼‰ï¼Œæ¯ä¸ªçª—å£ä¸­æ‰€æœ‰è¯„è®ºä¸åŸè¯„è®ºæ‹¼æ¥ï¼Œå¹¶è¿›è¡Œé¢„æµ‹ï¼Œæœ€åä¸åŒçª—å£ä¸åŸè¯„è®ºçš„ç›¸å…³æ€§ç»è¿‡softmaxä½œä¸ºæƒé‡ï¼Œå¯¹æ‰€æœ‰é¢„æµ‹ç½®ä¿¡åº¦åŠ æƒå’Œï¼Œå¾—åˆ°æœ€ç»ˆç»“æœ<br>**[conclusion/contribution]** Extensive experiments on Slashdot data demonstrate that context-augmented kernels outperform baseline transformers by up to 20% in accuracy and surpass general-purpose LLMs \(GPT-3.5/4\) in specific categorization tasks, revealing that different tasks require distinct structural context patterns.<br>\[ç¿»è¯‘\] åœ¨Slashdotæ•°æ®ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œä¸Šä¸‹æ–‡å¢å¼ºçš„æ ¸æœºåˆ¶åœ¨å‡†ç¡®ç‡ä¸Šæ¯”åŸºçº¿Transformeræ¨¡å‹é«˜å‡º20%ï¼Œå¹¶åœ¨ç‰¹å®šåˆ†ç±»ä»»åŠ¡ä¸­è¶…è¶Šäº†é€šç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆGPT-3.5/4ï¼‰ï¼Œæ­ç¤ºäº†ä¸åŒä»»åŠ¡éœ€è¦æˆªç„¶ä¸åŒçš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ¨¡å¼ã€‚<br>**[limitation/future]** The approach relies heavily on explicit tree-structured reply threads, limiting applicability in flat discussion formats, and may face cold-start challenges in early-stage conversations with sparse context.<br>\[ç¿»è¯‘\] è¯¥æ–¹æ³•ä¸¥é‡ä¾èµ–æ˜¾å¼çš„æ ‘çŠ¶å›å¤çº¿ç´¢ï¼Œé™åˆ¶äº†å…¶åœ¨æ‰å¹³åŒ–è®¨è®ºå½¢å¼ä¸­çš„é€‚ç”¨æ€§ï¼Œå¹¶ä¸”åœ¨ä¸Šä¸‹æ–‡ç¨€ç–çš„å¯¹è¯æ—©æœŸé˜¶æ®µå¯èƒ½é¢ä¸´å†·å¯åŠ¨æŒ‘æˆ˜ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">ã€åŸºç¡€æŠ€æœ¯â€”ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ–¹æ³•ã€‘å¯ç”¨äºæ‰€æœ‰å†…å®¹ç†è§£ä»»åŠ¡ï¼Œè®ºæ–‡ä¸­çš„å®éªŒç”¨çš„æ˜¯æ˜¯å¦å—æ¬¢è¿äºŒåˆ†ç±»<br>\[å¼•ç”¨æ–‡\]To better bridge pattern recognition with social interaction structures, Agarwal et al. \(2025\) proposed Conversation Kernels, an end-to-end framework designed to extract fine-grained context from conversation trees. By dynamically retrieving and weighting specific topological neighborhoods \(e.g., ancestors or siblings\) rather than ingesting linear history, their method effectively filters noise inherent in social discussions. This structural selectivity demonstrates that incorporating explicit interaction topologies is crucial for accurately decoding the nature of online conversations, yielding performance that surpasses even general-purpose Large Language Models like GPT-4.<br>\[ç¿»è¯‘\]<br>ä¸ºäº†æ›´å¥½åœ°å°†æ¨¡å¼è¯†åˆ«ä¸ç¤¾ä¼šäº’åŠ¨ç»“æ„è”ç³»èµ·æ¥ï¼ŒAgarwalç­‰äºº \(2025\) æå‡ºäº†â€œå¯¹è¯æ ¸ï¼ˆConversation Kernelsï¼‰â€ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨ä»å¯¹è¯æ ‘ä¸­æå–ç»†ç²’åº¦ä¸Šä¸‹æ–‡çš„ç«¯åˆ°ç«¯æ¡†æ¶ã€‚é€šè¿‡åŠ¨æ€æ£€ç´¢å¹¶åŠ æƒç‰¹å®šçš„æ‹“æ‰‘é‚»åŸŸï¼ˆå¦‚ç¥–å…ˆæˆ–å…„å¼ŸèŠ‚ç‚¹ï¼‰è€Œéæ‘„å…¥çº¿æ€§å†å²ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°è¿‡æ»¤äº†ç¤¾ä¼šè®¨è®ºä¸­å›ºæœ‰çš„å™ªå£°ã€‚è¿™ç§ç»“æ„é€‰æ‹©æ€§è¯æ˜ï¼Œç»“åˆæ˜¾å¼çš„äº’åŠ¨æ‹“æ‰‘å¯¹äºå‡†ç¡®è§£è¯»åœ¨çº¿å¯¹è¯çš„æ€§è´¨è‡³å…³é‡è¦ï¼Œå…¶è¡¨ç°ç”šè‡³è¶…è¶Šäº†åƒ GPT-4 è¿™æ ·çš„é€šç”¨å¤§è¯­è¨€æ¨¡å‹ã€‚</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/OpenBMB/IoA.svg?style=social&label=Star)](https://github.com/OpenBMB/IoA) [![Publish](https://img.shields.io/badge/Conference-The%20Thirteenth%20International%20Conference%20on%20Learning%20Representations-blue)]()<br>[Internet of agents: Weaving a web of heterogeneous agents for collaborative intelligence](https://openreview.net/forum?id=o1Et3MogPw) <br> Weize Chen\*, Ziming You\*, Ran Li\*, Yitong Guan\*, Chen Qian, Chenyang Zhao Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun <br> 2024-10-04|agentäº’è”ç½‘ï¼Œå‡çº§ç‰ˆABMç³»ç»Ÿï¼Œé‡‡ç”¨ç±»ä¼¼äº’è”ç½‘æ€æƒ³ï¼ŒC/Sæ¶æ„ï¼Œåˆ†å¸ƒåŒ–ã€æœåŠ¡åŒ–ã€å¹³å°åŒ–|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/IoA-Internet-1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/IoA2-Internet-1.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** å…ˆå‰çš„multi-agentç³»ç»Ÿçš„å±€é™æ€§ï¼Œç³»ç»ŸåŒ–å¹³å°åŒ–ç¨‹åº¦ä¸è¶³ï¼ˆç¼ºä¹ç¬¬ä¸‰æ–¹é›†æˆæ”¯æŒï¼Œæ— æ³•åˆ†å¸ƒå¼ï¼Œé€šä¿¡åè®®å’ŒçŠ¶æ€è½¬æ¢ä¾èµ–äºç¡¬ç¼–ç ï¼‰ **[innovation]** å°†äº’è”ç½‘çš„å¼€æ”¾ã€åˆ†å¸ƒå¼ã€æœåŠ¡åŒ–æ€æƒ³å¼•å…¥ï¼Œæ„å»ºä¸€ç§æ ‡å‡†åŒ–ã€å¯æ‰©å±•çš„æ”¯æŒåˆ†å¸ƒå¼ã€å¼‚æ„çš„æ™ºèƒ½ä½“é›†æˆä¸é€šä¿¡åè®®ã€‚ **[method]** æœåŠ¡å™¨ï¼šæ™ºèƒ½ä½“æ³¨å†Œï¼ˆåˆ†å‘ç³»ç»Ÿæç¤ºè¯ï¼‰ã€ç®¡ç†å·²æ³¨å†Œæ™ºèƒ½ä½“ï¼ˆä¸“å®¶ï¼‰ã€ä¸“å®¶å‘ç°æœåŠ¡ã€ç¾¤èŠç®¡ç†å’Œæ¶ˆæ¯ä¼ é€’ï¼›å®¢æˆ·ç«¯ï¼šåŒ…è£…å…·ä½“æ™ºèƒ½ä½“ï¼Œæä¾›é€šä¿¡æ¥å£ï¼›ä¸‰å±‚ç»“æ„ï¼›é€šä¿¡å³å¯åµŒå¥—çµæ´»ç¾¤èŠï¼›ç¾¤èŠé‡‡ç”¨**æœ‰é™çŠ¶æ€æœº**ç®¡ç†æµç¨‹ï¼›å¹³å°åˆå§‹åŒ–ä¸æ³¨å†Œ-&gt;ä»»åŠ¡è§¦å‘å›¢é˜Ÿå½¢æˆ-&gt;å†…éƒ¨åµŒå¥—åä½œ **[conclusion/contribution]** åœ¨ GAIA åŸºå‡†æµ‹è¯•ä¸­ï¼Œä»…ä½¿ç”¨å››ä¸ªåŸºç¡€ ReAct æ™ºèƒ½ä½“å³è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼›åœ¨ RAG ä»»åŠ¡ä¸­ï¼ŒåŸºäº GPT-3.5 çš„ IoA è¾¾åˆ°æˆ–è¶…è¿‡ GPT-4 çš„æ€§èƒ½ **[limitation/future]** å®éªŒä¸­å­˜åœ¨å†—ä½™æ¶ˆæ¯ï¼Œé€šä¿¡ Token æ¶ˆè€—å¢åŠ è¿‘ä¸€å€ï¼Œè¿™è¯æ˜agentä½œä¸ºå¯¹è¯è€…è€Œéæ‰§è¡Œè€…çš„æœ¬è´¨èƒ½åŠ›åŒºåˆ«ï¼›å•ç‚¹æœåŠ¡å™¨å¯èƒ½å­˜åœ¨ç“¶é¢ˆï¼›æ™ºèƒ½ä½“é€šè¿‡æ³¨å†Œè·å–æç¤ºè¯æˆä¸ºä¸åŒä¸“å®¶ï¼Œä»é«˜åº¦ä¾èµ–äººå·¥å®éªŒè®¾è®¡ï¼Œä¸”è¿™ç§ä¸“å®¶çš„èƒ½åŠ›æ˜¯å¦å¯é ">**[summary]**</summary><div style="margin-top:6px">**[motivation]** å…ˆå‰çš„multi-agentç³»ç»Ÿçš„å±€é™æ€§ï¼Œç³»ç»ŸåŒ–å¹³å°åŒ–ç¨‹åº¦ä¸è¶³ï¼ˆç¼ºä¹ç¬¬ä¸‰æ–¹é›†æˆæ”¯æŒï¼Œæ— æ³•åˆ†å¸ƒå¼ï¼Œé€šä¿¡åè®®å’ŒçŠ¶æ€è½¬æ¢ä¾èµ–äºç¡¬ç¼–ç ï¼‰<br>**[innovation]** å°†äº’è”ç½‘çš„å¼€æ”¾ã€åˆ†å¸ƒå¼ã€æœåŠ¡åŒ–æ€æƒ³å¼•å…¥ï¼Œæ„å»ºä¸€ç§æ ‡å‡†åŒ–ã€å¯æ‰©å±•çš„æ”¯æŒåˆ†å¸ƒå¼ã€å¼‚æ„çš„æ™ºèƒ½ä½“é›†æˆä¸é€šä¿¡åè®®ã€‚<br>**[method]** æœåŠ¡å™¨ï¼šæ™ºèƒ½ä½“æ³¨å†Œï¼ˆåˆ†å‘ç³»ç»Ÿæç¤ºè¯ï¼‰ã€ç®¡ç†å·²æ³¨å†Œæ™ºèƒ½ä½“ï¼ˆä¸“å®¶ï¼‰ã€ä¸“å®¶å‘ç°æœåŠ¡ã€ç¾¤èŠç®¡ç†å’Œæ¶ˆæ¯ä¼ é€’ï¼›å®¢æˆ·ç«¯ï¼šåŒ…è£…å…·ä½“æ™ºèƒ½ä½“ï¼Œæä¾›é€šä¿¡æ¥å£ï¼›ä¸‰å±‚ç»“æ„ï¼›é€šä¿¡å³å¯åµŒå¥—çµæ´»ç¾¤èŠï¼›ç¾¤èŠé‡‡ç”¨**æœ‰é™çŠ¶æ€æœº**ç®¡ç†æµç¨‹ï¼›å¹³å°åˆå§‹åŒ–ä¸æ³¨å†Œ->ä»»åŠ¡è§¦å‘å›¢é˜Ÿå½¢æˆ->å†…éƒ¨åµŒå¥—åä½œ<br>**[conclusion/contribution]** åœ¨ GAIA åŸºå‡†æµ‹è¯•ä¸­ï¼Œä»…ä½¿ç”¨å››ä¸ªåŸºç¡€ ReAct æ™ºèƒ½ä½“å³è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼›åœ¨ RAG ä»»åŠ¡ä¸­ï¼ŒåŸºäº GPT-3.5 çš„ IoA è¾¾åˆ°æˆ–è¶…è¿‡ GPT-4 çš„æ€§èƒ½<br>**[limitation/future]** å®éªŒä¸­å­˜åœ¨å†—ä½™æ¶ˆæ¯ï¼Œé€šä¿¡ Token æ¶ˆè€—å¢åŠ è¿‘ä¸€å€ï¼Œè¿™è¯æ˜agentä½œä¸ºå¯¹è¯è€…è€Œéæ‰§è¡Œè€…çš„æœ¬è´¨èƒ½åŠ›åŒºåˆ«ï¼›å•ç‚¹æœåŠ¡å™¨å¯èƒ½å­˜åœ¨ç“¶é¢ˆï¼›æ™ºèƒ½ä½“é€šè¿‡æ³¨å†Œè·å–æç¤ºè¯æˆä¸ºä¸åŒä¸“å®¶ï¼Œä»é«˜åº¦ä¾èµ–äººå·¥å®éªŒè®¾è®¡ï¼Œä¸”è¿™ç§ä¸“å®¶çš„èƒ½åŠ›æ˜¯å¦å¯é </div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">æ¯ä¸ªagentè¢«ä¸€ä¸ªå®¢æˆ·ç«¯åŒ…è£…ï¼›æœåŠ¡å™¨ä¸æ˜¯agentï¼Œå®ƒåªåšå››ä»¶äº‹ï¼šæ³¨å†Œã€å‘ç°ã€å»ºç¾¤ã€è·¯ç”±ï¼›ç›¸å¯¹äºä¼ ç»ŸABMï¼Œè¿™æ˜¯ä¸€ä¸ªæ›´å¤§å‹çš„æœåŠ¡ç³»ç»Ÿï¼Œè¯¥æ–¹æ³•é€šè¿‡åŸºäºä»»åŠ¡çš„â€œç¾¤èŠâ€æ–¹å¼ç»„ç»‡é—®é¢˜è§£å†³ï¼Œç›¸å¯¹ä¼ ç»Ÿå›åˆåˆ¶æ–¹å¼æ›´åŠ è‡ªç”±ã€‚æœ¬èº«ä¹Ÿæ˜¯ä¸€ä¸ªé«˜åº¦å¯æ‰©å±•ç³»ç»Ÿã€‚é—®é¢˜åœ¨äºæ™ºèƒ½ä½“é€šè¿‡æ³¨å†Œè·å–æç¤ºè¯æˆä¸ºä¸åŒä¸“å®¶ï¼Œä»ä¾èµ–æ‰‹å·¥è®¾è®¡ï¼Œä¸”è¿™ç§ä¸“å®¶çš„èƒ½åŠ›æ˜¯å¦å¯é ã€‚å¯¹äºç¤¾ä¼šæ¨¡æ‹Ÿä»»åŠ¡ç›¸å¯¹äºä¼ ç»Ÿæ–¹æ³•æœ‰ä½•å†³å®šæ€§ä¼˜åŠ¿ä»æœªå¯çŸ¥</div></details></div></div>|

### | Perception and Classification (12 papers)


### Hate Speech Analysis (4 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic Analysis of Annotators and T...](https://ojs.aaai.org/index.php/ICWSM/article/view/35837) <br> Tommaso Giorgi\*,Lorenzo Cima\*,Tiziano Fagni,Marco Avvenuti,Stefano Cresci <br> 2025-06-07|ä»‡æ¨è¨€è®ºåˆ†æä¸­çš„æ•°æ®é›†æ ‡æ³¨å¦‚ä½•å—ä¸»è§‚åè§å½±å“ï¼Œæç¤ºè¯å¼•å¯¼çš„è§’è‰²æ‰®æ¼”LLMèƒ½å¦å¤åˆ»è¿™ç§åè§|<img width="1200" alt="pipeline" src="figures/HateAnaBias.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** è¯¥é¢†åŸŸéœ€è¦å¤§é‡äººå·¥æ ‡æ³¨ï¼Œå­˜åœ¨å›ºæœ‰çš„ä¸»è§‚æ€§biasé—®é¢˜ï¼Œéœ€è¦ç³»ç»Ÿæ€§çš„ç ”ç©¶ **[innovation]** The authors introduce a novel methodological framework on the Measuring Hate Speech corpus that quantifies bias through &quot;Intensity&quot; and &quot;Prevalence&quot; metrics without relying on ground truth, uniquely isolating the interplay between specific annotator profiles and target groups. \[ç¿»è¯‘\] æŒ‡æ ‡è®¾è®¡ï¼šæå‡ºäº†åå·®å¼ºåº¦ï¼ˆIntensity, ğ¼ï¼‰å’Œåå·®æ™®éæ€§ï¼ˆPrevalence, ğ‘ƒï¼‰ï¼Œæ— éœ€Ground Truthå³å¯è¡¡é‡ç›¸å¯¹åå·®ï¼ˆå°†**å…¶ä½™æ‰€æœ‰æ ‡æ³¨è€…ï¼ˆReference Groupï¼‰**çš„å…±è¯†ä½œä¸ºåŸºå‡†ï¼‰ã€‚ LLMå¯¹é½åˆ†æï¼šè¯„ä¼°äº†è§’è‰²æ‰®æ¼”LLMåœ¨â€œå¤ç°æ ‡æ³¨åå·®â€ä»»åŠ¡ä¸Šçš„èƒ½åŠ› **[method]** Leveraging a large-scale dataset with rich demographic attributes, the methodology employs a comparative analysis using confusion matrices to measure relative labeling discrepancies between demographic groups, subsequently evaluating open-source LLMs via role-playing prompts to assess their alignment with human bias patterns. \[ç¿»è¯‘\]é€šè¿‡**æ··æ·†çŸ©é˜µ**ï¼ˆè¡Œä»£è¡¨ä¸å…·å¤‡è¯¥å±æ€§ï¼Œåˆ—ä»£è¡¨å…·å¤‡è¯¥å±æ€§ï¼‰å¯¹æ¯”ç‰¹å®šå±æ€§ç¾¤ä½“åœ¨è¯„ä»·ç‰¹å®šå±æ€§å—å®³è€…æ—¶çš„æ ‡ç­¾å·®å¼‚ã€‚è®¡ç®—åå·®å¼ºåº¦å’Œæ™®éæ€§\\nä½¿ç”¨**prompt**å¼•å¯¼LLMè¿›è¡Œç›¸åŒä»»åŠ¡ä»¥å¯¹æ¯” **[conclusion/contribution]** Quantitative analysis reveals that while human annotators exhibit significant &quot;in-group&quot; hypersensitivity and demographic-specific labeling variations, persona-based LLMs demonstrate a limited correlation with these human biases, failing to accurately mirror the complex social prejudices inherent in human data. \[ç¿»è¯‘\] äººç±»åå·®ï¼šå­˜åœ¨æ˜¾è‘—çš„â€œç»„å†…é«˜æ•åº¦â€ï¼ˆå³å€¾å‘äºé«˜ä¼°é’ˆå¯¹è‡ªèº«ç¾¤ä½“çš„ä»‡æ¨ï¼‰ï¼Œå—äººå£ç»Ÿè®¡å­¦äº¤äº’å½±å“ä¸¥é‡ï¼ˆå¦‚å¹´è½»äººå€¾å‘ä½ä¼°ä»‡æ¨ï¼Œè€å¹´äººå€¾å‘é«˜ä¼°ï¼‰ã€‚ LLMè¡¨ç°ï¼šMè¡¨ç°å‡ºè‡ªèº«åå·®ï¼Œä½†æœªèƒ½æœ‰æ•ˆå¤ç°äººç±»çš„ç‰¹å®šåå·®ï¼ˆç›¸å…³æ€§æä½ï¼‰ï¼Œ**æ¬ ç¼ºå¯¹é½èƒ½åŠ›**ï¼ˆé«˜ä¼°ä»£è¡¨æ›´æ•æ„Ÿï¼‰ **[limitation/future]** The study&#x27;s limitations include data scarcity for specific minority groups which constrains statistical significance, and a reliance solely on prompting strategies without fine-tuning, which may restrict the models&#x27; capacity for deep behavioral mimicry. \[ç¿»è¯‘\] è¯¥ç ”ç©¶çš„å±€é™æ€§åŒ…æ‹¬ç‰¹å®šå°‘æ•°ç¾¤ä½“çš„æ•°æ®ç¨€ç¼ºé™åˆ¶äº†ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œä»¥åŠä»…ä»…ä¾èµ–æç¤ºç­–ç•¥è€Œæ²¡æœ‰è¿›è¡Œå¾®è°ƒï¼Œè¿™å¯èƒ½é™åˆ¶äº†æ¨¡å‹çš„æ·±åº¦è¡Œä¸ºæ¨¡ä»¿èƒ½åŠ›ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** è¯¥é¢†åŸŸéœ€è¦å¤§é‡äººå·¥æ ‡æ³¨ï¼Œå­˜åœ¨å›ºæœ‰çš„ä¸»è§‚æ€§biasé—®é¢˜ï¼Œéœ€è¦ç³»ç»Ÿæ€§çš„ç ”ç©¶<br>**[innovation]** The authors introduce a novel methodological framework on the Measuring Hate Speech corpus that quantifies bias through "Intensity" and "Prevalence" metrics without relying on ground truth, uniquely isolating the interplay between specific annotator profiles and target groups.<br>\[ç¿»è¯‘\] æŒ‡æ ‡è®¾è®¡ï¼šæå‡ºäº†åå·®å¼ºåº¦ï¼ˆIntensity, ğ¼ï¼‰å’Œåå·®æ™®éæ€§ï¼ˆPrevalence, ğ‘ƒï¼‰ï¼Œæ— éœ€Ground Truthå³å¯è¡¡é‡ç›¸å¯¹åå·®ï¼ˆå°†**å…¶ä½™æ‰€æœ‰æ ‡æ³¨è€…ï¼ˆReference Groupï¼‰**çš„å…±è¯†ä½œä¸ºåŸºå‡†ï¼‰ã€‚<br>LLMå¯¹é½åˆ†æï¼šè¯„ä¼°äº†è§’è‰²æ‰®æ¼”LLMåœ¨â€œå¤ç°æ ‡æ³¨åå·®â€ä»»åŠ¡ä¸Šçš„èƒ½åŠ›<br>**[method]** Leveraging a large-scale dataset with rich demographic attributes, the methodology employs a comparative analysis using confusion matrices to measure relative labeling discrepancies between demographic groups, subsequently evaluating open-source LLMs via role-playing prompts to assess their alignment with human bias patterns.<br>\[ç¿»è¯‘\]é€šè¿‡**æ··æ·†çŸ©é˜µ**ï¼ˆè¡Œä»£è¡¨ä¸å…·å¤‡è¯¥å±æ€§ï¼Œåˆ—ä»£è¡¨å…·å¤‡è¯¥å±æ€§ï¼‰å¯¹æ¯”ç‰¹å®šå±æ€§ç¾¤ä½“åœ¨è¯„ä»·ç‰¹å®šå±æ€§å—å®³è€…æ—¶çš„æ ‡ç­¾å·®å¼‚ã€‚è®¡ç®—åå·®å¼ºåº¦å’Œæ™®éæ€§\\nä½¿ç”¨**prompt**å¼•å¯¼LLMè¿›è¡Œç›¸åŒä»»åŠ¡ä»¥å¯¹æ¯”<br>**[conclusion/contribution]** Quantitative analysis reveals that while human annotators exhibit significant "in-group" hypersensitivity and demographic-specific labeling variations, persona-based LLMs demonstrate a limited correlation with these human biases, failing to accurately mirror the complex social prejudices inherent in human data.<br>\[ç¿»è¯‘\] äººç±»åå·®ï¼šå­˜åœ¨æ˜¾è‘—çš„â€œç»„å†…é«˜æ•åº¦â€ï¼ˆå³å€¾å‘äºé«˜ä¼°é’ˆå¯¹è‡ªèº«ç¾¤ä½“çš„ä»‡æ¨ï¼‰ï¼Œå—äººå£ç»Ÿè®¡å­¦äº¤äº’å½±å“ä¸¥é‡ï¼ˆå¦‚å¹´è½»äººå€¾å‘ä½ä¼°ä»‡æ¨ï¼Œè€å¹´äººå€¾å‘é«˜ä¼°ï¼‰ã€‚<br>LLMè¡¨ç°ï¼šMè¡¨ç°å‡ºè‡ªèº«åå·®ï¼Œä½†æœªèƒ½æœ‰æ•ˆå¤ç°äººç±»çš„ç‰¹å®šåå·®ï¼ˆç›¸å…³æ€§æä½ï¼‰ï¼Œ**æ¬ ç¼ºå¯¹é½èƒ½åŠ›**ï¼ˆé«˜ä¼°ä»£è¡¨æ›´æ•æ„Ÿï¼‰<br>**[limitation/future]** The study's limitations include data scarcity for specific minority groups which constrains statistical significance, and a reliance solely on prompting strategies without fine-tuning, which may restrict the models' capacity for deep behavioral mimicry.<br>\[ç¿»è¯‘\] è¯¥ç ”ç©¶çš„å±€é™æ€§åŒ…æ‹¬ç‰¹å®šå°‘æ•°ç¾¤ä½“çš„æ•°æ®ç¨€ç¼ºé™åˆ¶äº†ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œä»¥åŠä»…ä»…ä¾èµ–æç¤ºç­–ç•¥è€Œæ²¡æœ‰è¿›è¡Œå¾®è°ƒï¼Œè¿™å¯èƒ½é™åˆ¶äº†æ¨¡å‹çš„æ·±åº¦è¡Œä¸ºæ¨¡ä»¿èƒ½åŠ›ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[å¼•ç”¨å¥\]Serving as a foundational critique within the transition from static classification to dynamic social simulation, Giorgi et al. \(2025\) demonstrate that although human perception of hate speech is fundamentally shaped by the interplay between annotator and target demographics, current persona-based LLMs fail to faithfully emulate these emergent sociological biases, highlighting a critical gap in the development of realistic AI agents.<br>\[ç¿»è¯‘\] ä½œä¸ºä»é™æ€åˆ†ç±»å‘åŠ¨æ€ç¤¾ä¼šä»¿çœŸè¿‡æ¸¡è¿‡ç¨‹ä¸­çš„ä¸€é¡¹åŸºç¡€æ€§æ‰¹åˆ¤ç ”ç©¶ï¼ŒGiorgiç­‰äººï¼ˆ2025ï¼‰è¯æ˜ï¼Œå°½ç®¡äººç±»å¯¹ä»‡æ¨è¨€è®ºçš„æ„ŸçŸ¥ä»æ ¹æœ¬ä¸Šå—æ ‡æ³¨è€…ä¸ç›®æ ‡äººå£ç»Ÿè®¡ç‰¹å¾äº¤äº’ä½œç”¨çš„å½±å“ï¼Œä½†å½“å‰çš„åŸºäºè§’è‰²çš„LLMæ— æ³•å¿ å®åœ°æ¨¡æ‹Ÿè¿™äº›æ¶Œç°çš„ç¤¾ä¼šå­¦åå·®ï¼Œçªæ˜¾äº†æ„å»ºé€¼çœŸAIæ™ºèƒ½ä½“æ–¹é¢çš„ä¸€ä¸ªå…³é”®å·®è·ã€‚</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence-blue)]()<br>[TOT: Topology-Aware Optimal Transport for Multimodal Hate Detection](https://ojs.aaai.org/index.php/AAAI/article/view/25614) <br> Linhao Zhangï¼ŒLi Jinï¼ŒXian Sunï¼ŒGuangluan Xuï¼ŒZequn Zhang,Xiaoyu Li,Nayu Liu,Qing Liu,Shiyao Yan <br> 2023-06-26|å¼ºåŒ–æ¶æ„Memeçš„å›¾åƒä¸æ–‡æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ï¼Œä½¿ç”¨OTæ–¹æ³•å»ºç«‹ç‰¹å¾å‘é‡é—´çš„å¯è§£é‡Šè”ç³»|<img width="1200" alt="pipeline" src="figures/TOT-TOTTop-1.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** ä¸ºäº†è§£å†³å¤šæ¨¡æ€ä»‡æ¨æ£€æµ‹ä¸­å› â€ éšå¼å¯¹é½â€ å’Œâ€ æ¨¡æ€é¸¿æ²Ÿâ€ å¯¼è‡´çš„å›¾åƒå’Œæ–‡æœ¬è·¨æ¨¡æ€è¯­ä¹‰å¯¹é½éš¾é¢˜ **[innovation]** å°†OTç”¨äºç‰¹å¾å¯¹é½ï¼Œå°†å¥å­çº§å¯¹é½ç»†ç²’åŒ–è‡³å‘é‡çº§ï¼Œä¸ºåç»­å·¥ä½œæä¾›äº†â€œæ˜¾å¼å¯¹é½+ç»“æ„æ¨ç†â€çš„èŒƒå¼ **[method]** æœ€ä¼˜ä¼ è¾“ + æ‹“æ‰‘ç»“æ„æ¨ç†æ–¹æ³• TOTï¼šCLIP æ–¹æ³•ç»Ÿä¸€è¡¨å¾æ˜ å°„-&gt;æœ€ä¼˜ä¼ è¾“optimal transport \(OT\)å°†éšå¼è”ç³»ç»†ç²’åŒ–ä¸ºå‘é‡çº§ï¼ˆè¿™æ˜¯ä¸€ä¸ªæ•°å­¦è®¡ç®—è¿‡ç¨‹ï¼Œä¸æ¶‰åŠéœ€è¦å­¦ä¹ çš„å‚æ•°ï¼‰-&gt;ç±»GNNè¿­ä»£æ•æ‰è‡ªèº«è¯­ä¹‰è”ç³»ï¼ˆç±»è‡ªæ³¨æ„åŠ›ï¼‰ï¼ˆå› ä¸ºå‘é‡é—´è·ç¦»æ„ä¹‰æ˜ç¡®ï¼‰-&gt;æ®‹å·®è¿æ¥ **[conclusion/contribution]** è¾¾æˆäº†åœ¨ä¸¤ä¸ªæœ‰å®³ Meme æ£€æµ‹æ•°æ®é›†ï¼ˆHarm-C, Harm-Pï¼‰ä¸Šçš„æœ€å…ˆè¿›æ€§èƒ½ï¼› **[limitation/future]** å¯¹é½å’Œæ¨ç†ä»å±€é™äºç‰¹å¾å±‚é¢ï¼Œæœªä¸Šå‡åˆ°è¯­ä¹‰å•å…ƒï¼ˆå¦‚äº‹ä»¶ã€æ¦‚å¿µï¼‰å±‚é¢ï¼ŒOTè¿‡ç¨‹ä¸ºå†»ç»“æ— æ³•è®­ç»ƒçš„ï¼Œå¯ä»¥è®­ç»ƒå…¶å‚æ•°ä»¥å®ç°æ›´å¥½çš„å¯¹é½ï¼›å¯¹äºå¹½é»˜ç­‰ç±»ä¼¼éšå¼è¡¨è¾¾å®¹æ˜“è¯¯åˆ¤">**[summary]**</summary><div style="margin-top:6px">**[motivation]** ä¸ºäº†è§£å†³å¤šæ¨¡æ€ä»‡æ¨æ£€æµ‹ä¸­å› â€ éšå¼å¯¹é½â€ å’Œâ€ æ¨¡æ€é¸¿æ²Ÿâ€ å¯¼è‡´çš„å›¾åƒå’Œæ–‡æœ¬è·¨æ¨¡æ€è¯­ä¹‰å¯¹é½éš¾é¢˜<br>**[innovation]** å°†OTç”¨äºç‰¹å¾å¯¹é½ï¼Œå°†å¥å­çº§å¯¹é½ç»†ç²’åŒ–è‡³å‘é‡çº§ï¼Œä¸ºåç»­å·¥ä½œæä¾›äº†â€œæ˜¾å¼å¯¹é½+ç»“æ„æ¨ç†â€çš„èŒƒå¼<br>**[method]** æœ€ä¼˜ä¼ è¾“ + æ‹“æ‰‘ç»“æ„æ¨ç†æ–¹æ³• TOTï¼šCLIP æ–¹æ³•ç»Ÿä¸€è¡¨å¾æ˜ å°„->æœ€ä¼˜ä¼ è¾“optimal transport \(OT\)å°†éšå¼è”ç³»ç»†ç²’åŒ–ä¸ºå‘é‡çº§ï¼ˆè¿™æ˜¯ä¸€ä¸ªæ•°å­¦è®¡ç®—è¿‡ç¨‹ï¼Œä¸æ¶‰åŠéœ€è¦å­¦ä¹ çš„å‚æ•°ï¼‰->ç±»GNNè¿­ä»£æ•æ‰è‡ªèº«è¯­ä¹‰è”ç³»ï¼ˆç±»è‡ªæ³¨æ„åŠ›ï¼‰ï¼ˆå› ä¸ºå‘é‡é—´è·ç¦»æ„ä¹‰æ˜ç¡®ï¼‰->æ®‹å·®è¿æ¥<br>**[conclusion/contribution]** è¾¾æˆäº†åœ¨ä¸¤ä¸ªæœ‰å®³ Meme æ£€æµ‹æ•°æ®é›†ï¼ˆHarm-C, Harm-Pï¼‰ä¸Šçš„æœ€å…ˆè¿›æ€§èƒ½ï¼›<br>**[limitation/future]** å¯¹é½å’Œæ¨ç†ä»å±€é™äºç‰¹å¾å±‚é¢ï¼Œæœªä¸Šå‡åˆ°è¯­ä¹‰å•å…ƒï¼ˆå¦‚äº‹ä»¶ã€æ¦‚å¿µï¼‰å±‚é¢ï¼ŒOTè¿‡ç¨‹ä¸ºå†»ç»“æ— æ³•è®­ç»ƒçš„ï¼Œå¯ä»¥è®­ç»ƒå…¶å‚æ•°ä»¥å®ç°æ›´å¥½çš„å¯¹é½ï¼›å¯¹äºå¹½é»˜ç­‰ç±»ä¼¼éšå¼è¡¨è¾¾å®¹æ˜“è¯¯åˆ¤</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">æœ€ä¼˜ä¼ è¾“OTè´Ÿè´£å›ç­”â€œå›¾ç‰‡çš„å“ªä¸ªéƒ¨åˆ†å’Œæ–‡æœ¬çš„å“ªä¸ªè¯ç›¸å…³ï¼Ÿâ€ï¼ˆå®ç°ç»Ÿä¸€ä¸”å¯¹é½çš„è¡¨ç¤ºï¼Œä»è€Œå»ºç«‹è·¨æ¨¡æ€çš„æ˜¾å¼è”ç³»ï¼ŒOTæ–¹æ³•æ˜¯å¯è§£é‡Šçš„ï¼‰ã€‚ã€å³å°†CLIPç”Ÿæˆçš„ç‰¹å¾çŸ©é˜µçº§åˆ«çš„å¯¹é½ï¼Œç»†åŒ–ä¸ºç‰¹å¾å‘é‡é—´çš„å¯¹é½ï¼Œä¸¤ä¸ªç‰¹å¾çŸ©é˜µä¼šæ›´ç›¸åƒã€‚è¿™ç§æ˜¾å¼å¯¹é½èƒ½åŠ›æœ¬è´¨ä¸Šæ¥æºäºCLIPå®ç°çš„éšå¯¹é½ã€‘ï¼›æ‹“æ‰‘å»ºæ¨¡è´Ÿè´£å›ç­”â€œè¿™äº›ç›¸å…³çš„éƒ¨åˆ†ç»„åˆåœ¨ä¸€èµ·ï¼Œè¡¨è¾¾äº†ä»€ä¹ˆæ›´æ·±å±‚çš„å«ä¹‰ï¼Ÿâ€ï¼ˆæ•æ‰æ–‡æœ¬ï¼ˆå›¾ç‰‡ï¼‰ä¸­äº’ç›¸æœ‰è”ç³»çš„tokenï¼ˆpatchï¼‰ï¼Œè¿›è¡Œæ¨¡æ€å†…çš„æ·±åº¦æ¨ç†ï¼‰ã€‚ã€è¿™ç§ç±»ä¼¼GNNçš„æ–¹æ³•æœ¬è´¨ä¸Šæ˜¯æ›´æœ‰å±‚æ¬¡æ€§çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå¤©ç„¶é€‚ç”¨äºå¤„ç†å…³ç³»å‹æ•°æ®ï¼ˆå›¾ç»“æ„ï¼‰ã€‘ï¼›æœ¬è´¨ä¸Šæ˜¯å°†CLIPå»ºç«‹çš„éšå¼å¯¹é½ç»†ç²’åŒ–ä¸ºå‘é‡å±‚çº§çš„æ˜¾å¼å¯¹é½ï¼Œè¿›è€Œå¾—ä»¥ä½¿ç”¨å›¾æ¨ç†è¿›ä¸€æ­¥å­¦ä¹ å†…éƒ¨è”ç³»</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-IEEE%20Transactions%20on%20Multimedia-blue)]()<br>[Flexible optimal transport with contrastive graphical modeling for multimodal hate detection](https://ieeexplore.ieee.org/abstract/document/11045556) <br> Linhao Zhangï¼ŒLi Jinï¼ŒXiaoyu Li,Xian Sun,Senior Member,IEEE,Xin Wang,Zequn Zhang,Jian Liuï¼ŒZhicong Luï¼ŒGraduate Student Member,IEEE,and Guangluan Xu <br> 2025|\[AI generated\] This method bridges multimodal gaps like a flexible translator, aligning implicit hateful memes through optimal transport and contrastive graphs. \[ç¿»è¯‘\]è¯¥æ–¹æ³•é€šè¿‡æœ€ä¼˜ä¼ è¾“å’Œå›¾å¯¹æ¯”å­¦ä¹ ï¼Œåƒçµæ´»çš„ç¿»è¯‘å®˜ä¸€æ ·å¼¥åˆæ¨¡æ€é¸¿æ²Ÿï¼Œå¯¹é½éšå«ä»‡æ¨è¡¨æƒ…åŒ…ã€‚|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/FLOT1-Flexible-1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/FLOT-Flexible-1.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** ç¤¾åª’ä¸­éšå«ä»‡æ¨å†…å®¹æ£€æµ‹å›°éš¾ï¼Œä¼ ç»Ÿæ–¹æ³•éš¾ä»¥å®ç°è·¨æ¨¡æ€éšå¼å¯¹é½ã€‚ **[innovation]** ç›¸å¯¹äºåŒå›¢é˜Ÿçš„TOTæ˜¯æ”¹è¿› **[method]** ç›¸å¯¹äºåŒå›¢é˜Ÿçš„TOT:1.OTçš„ç›®æ ‡åŸŸä¸å†æ˜¯å¦ä¸€æ¨¡æ€çš„ç‰¹å¾ï¼Œè€Œæ˜¯å¯å­¦ä¹ çš„ç»Ÿä¸€åµŒå…¥ï¼ˆOTå¼•å…¥å¯å­¦ä¹ çš„å‚æ•°ï¼Œå®ƒä»¬æ˜¯ä¸¤ä¸ªæ¨¡æ€å„è‡ªå¯¹åº”çš„ç›®æ ‡ç‰¹å¾çŸ©é˜µ $T_v$ å’Œ $T_t$ï¼‰ï¼›2.å¼•å…¥äº†å›¾å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼Œæ˜¾å¼çº¦æŸä¸€è‡´æ€§ï¼ˆæ¯”è¾ƒä¸¤ä¸ªå›¾çš„ç›¸ä¼¼ç¨‹åº¦ä½œä¸ºä¸€ä¸ªæŸå¤±ï¼Œä¹‹åæ‰è¿›è¡Œç±»GNNèšåˆï¼ˆåŠ¨æ€æ‹“æ‰‘æ¨ç†ï¼‰ï¼‰ **[conclusion/contribution]** åœ¨Harm-Cã€Harm-Pã€MET-Memeä¸‰ä¸ªæ•°æ®é›†ä¸Šå–å¾—SOTAï¼Œæ˜¾è‘—æå‡å‡†ç¡®ç‡ä¸F1 **[limitation/future]** å¯¹äºå¹½é»˜ç­‰ç±»ä¼¼éšå¼è¡¨è¾¾å®¹æ˜“è¯¯åˆ¤">**[summary]**</summary><div style="margin-top:6px">**[motivation]** ç¤¾åª’ä¸­éšå«ä»‡æ¨å†…å®¹æ£€æµ‹å›°éš¾ï¼Œä¼ ç»Ÿæ–¹æ³•éš¾ä»¥å®ç°è·¨æ¨¡æ€éšå¼å¯¹é½ã€‚<br>**[innovation]** ç›¸å¯¹äºåŒå›¢é˜Ÿçš„TOTæ˜¯æ”¹è¿›<br>**[method]** ç›¸å¯¹äºåŒå›¢é˜Ÿçš„TOT:1.OTçš„ç›®æ ‡åŸŸä¸å†æ˜¯å¦ä¸€æ¨¡æ€çš„ç‰¹å¾ï¼Œè€Œæ˜¯å¯å­¦ä¹ çš„ç»Ÿä¸€åµŒå…¥ï¼ˆOTå¼•å…¥å¯å­¦ä¹ çš„å‚æ•°ï¼Œå®ƒä»¬æ˜¯ä¸¤ä¸ªæ¨¡æ€å„è‡ªå¯¹åº”çš„ç›®æ ‡ç‰¹å¾çŸ©é˜µ $T_v$ å’Œ $T_t$ï¼‰ï¼›2.å¼•å…¥äº†å›¾å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼Œæ˜¾å¼çº¦æŸä¸€è‡´æ€§ï¼ˆæ¯”è¾ƒä¸¤ä¸ªå›¾çš„ç›¸ä¼¼ç¨‹åº¦ä½œä¸ºä¸€ä¸ªæŸå¤±ï¼Œä¹‹åæ‰è¿›è¡Œç±»GNNèšåˆï¼ˆåŠ¨æ€æ‹“æ‰‘æ¨ç†ï¼‰ï¼‰<br>**[conclusion/contribution]** åœ¨Harm-Cã€Harm-Pã€MET-Memeä¸‰ä¸ªæ•°æ®é›†ä¸Šå–å¾—SOTAï¼Œæ˜¾è‘—æå‡å‡†ç¡®ç‡ä¸F1<br>**[limitation/future]** å¯¹äºå¹½é»˜ç­‰ç±»ä¼¼éšå¼è¡¨è¾¾å®¹æ˜“è¯¯åˆ¤</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-ACL%202024-blue)]()<br>[Improving Hateful Meme Detection through Retrieval-Guided Contrastive Learning](https://aclanthology.org/2024.acl-long.291) <br> Jingbiao Mei,Jinghong Chen,Weizhe Lin,Bill Byrne,Maarcus Tomalin <br> 2024|ä¸“é¢˜å¼ºåŒ–ï¼šéš¾å­¦æ ·æœ¬å•æ‹‰å‡ºæ¥ä¸æ­£ä¾‹è¿›è¡Œå¯¹æ¯”å­¦ä¹ ï¼Œä»è€Œæé«˜è¯†åˆ«èƒ½åŠ›|<img width="1200" alt="pipeline" src="figures/RGCL-Improvin-1.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** ç°æœ‰CLIPç­‰æ¨¡å‹å¯¹ä»‡æ¨è¡¨æƒ…åŒ…çš„å›¾åƒ-æ–‡æœ¬çš„ç»†å¾®å·®å¼‚ï¼ˆå¦‚â€œæ··æ·†æ ·æœ¬â€ï¼‰æ•æ„Ÿåº¦ä¸è¶³ï¼Œå¯¼è‡´çš„è¯¯åˆ¤ã€‚ **[innovation]** å¯¹äºæ˜“æ··æ·†çš„éš¾ä¾‹ï¼ˆä¸å½“å‰æ ·æœ¬ç›¸ä¼¼åº¦æœ€é«˜ä½†æ ‡ç­¾ç›¸åçš„ï¼‰ï¼Œä½¿ç”¨**åŠ¨æ€æ£€ç´¢**æ–¹å¼å•æ‹‰å‡ºæ¥ï¼Œä¸**ä¼ªé»„é‡‘æ­£æ ·æœ¬**ï¼ˆå’Œå½“å‰æ ·æœ¬ç›¸ä¼¼åº¦æœ€é«˜çš„æ ‡ç­¾ç›¸åŒçš„ï¼‰æˆå¯¹ï¼Œä½œä¸ºæ­£åä¾‹è¿›è¡Œå¯¹æ¯”å­¦ä¹ ã€‚ä»è€Œè§£å†³é—®é¢˜ **[method]** 1. ä½¿ç”¨å†»ç»“çš„CLIPç¼–ç å™¨æå–å›¾æ–‡ç‰¹å¾ï¼› 2. é€šè¿‡Faissæ£€ç´¢åŠ¨æ€è·å–åŒç±»ç›¸ä¼¼æ ·æœ¬ï¼ˆä¼ªé»„é‡‘æ­£æ ·æœ¬ï¼‰ä¸å¼‚ç±»ç›¸ä¼¼æ ·æœ¬ï¼ˆå›°éš¾è´Ÿæ ·æœ¬ï¼‰ä½œä¸ºæ­£åä¾‹ï¼› 3. ç»“åˆæ­£åä¾‹å¯¹æ¯”æŸå¤±ï¼ˆRGCLLï¼‰ä¸äº¤å‰ç†µæŸå¤±è®­ç»ƒMLPï¼› 4. å®ç°é€»è¾‘åˆ†ç±»ä¸KNNæ£€ç´¢åˆ†ç±»ä¸¤ç§åˆ†ç±»å™¨ï¼Œåè€…é€šè¿‡ç›¸ä¼¼åº¦åŠ æƒæŠ•ç¥¨è¿›è¡Œé¢„æµ‹ã€‚ **[conclusion/contribution]** åœ¨HatefulMemesæ•°æ®é›†ä¸Šè¾¾åˆ° AUROC 87.0%ï¼ˆSOTAï¼‰ï¼Œè¶…è¶ŠFlamingo-80Bç­‰å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ **[limitation/future]** ä»‡æ¨è¨€è®ºçš„å®šä¹‰å…·æœ‰äº‰è®®æ€§ä¸æ–‡åŒ–ä¾èµ–æ€§ï¼›ç³»ç»Ÿå¯¹ ç»†å¾®é¢éƒ¨è¡¨æƒ… è¯†åˆ«èƒ½åŠ›æœ‰é™ï¼›ä¾èµ–æ•°æ®æ ‡æ³¨è´¨é‡ï¼Œå¯èƒ½å­˜åœ¨æ ‡æ³¨åå·®ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** ç°æœ‰CLIPç­‰æ¨¡å‹å¯¹ä»‡æ¨è¡¨æƒ…åŒ…çš„å›¾åƒ-æ–‡æœ¬çš„ç»†å¾®å·®å¼‚ï¼ˆå¦‚â€œæ··æ·†æ ·æœ¬â€ï¼‰æ•æ„Ÿåº¦ä¸è¶³ï¼Œå¯¼è‡´çš„è¯¯åˆ¤ã€‚<br>**[innovation]** å¯¹äºæ˜“æ··æ·†çš„éš¾ä¾‹ï¼ˆä¸å½“å‰æ ·æœ¬ç›¸ä¼¼åº¦æœ€é«˜ä½†æ ‡ç­¾ç›¸åçš„ï¼‰ï¼Œä½¿ç”¨**åŠ¨æ€æ£€ç´¢**æ–¹å¼å•æ‹‰å‡ºæ¥ï¼Œä¸**ä¼ªé»„é‡‘æ­£æ ·æœ¬**ï¼ˆå’Œå½“å‰æ ·æœ¬ç›¸ä¼¼åº¦æœ€é«˜çš„æ ‡ç­¾ç›¸åŒçš„ï¼‰æˆå¯¹ï¼Œä½œä¸ºæ­£åä¾‹è¿›è¡Œå¯¹æ¯”å­¦ä¹ ã€‚ä»è€Œè§£å†³é—®é¢˜<br>**[method]** 1. ä½¿ç”¨å†»ç»“çš„CLIPç¼–ç å™¨æå–å›¾æ–‡ç‰¹å¾ï¼›<br>2. é€šè¿‡Faissæ£€ç´¢åŠ¨æ€è·å–åŒç±»ç›¸ä¼¼æ ·æœ¬ï¼ˆä¼ªé»„é‡‘æ­£æ ·æœ¬ï¼‰ä¸å¼‚ç±»ç›¸ä¼¼æ ·æœ¬ï¼ˆå›°éš¾è´Ÿæ ·æœ¬ï¼‰ä½œä¸ºæ­£åä¾‹ï¼›<br>3. ç»“åˆæ­£åä¾‹å¯¹æ¯”æŸå¤±ï¼ˆRGCLLï¼‰ä¸äº¤å‰ç†µæŸå¤±è®­ç»ƒMLPï¼›<br>4. å®ç°é€»è¾‘åˆ†ç±»ä¸KNNæ£€ç´¢åˆ†ç±»ä¸¤ç§åˆ†ç±»å™¨ï¼Œåè€…é€šè¿‡ç›¸ä¼¼åº¦åŠ æƒæŠ•ç¥¨è¿›è¡Œé¢„æµ‹ã€‚<br>**[conclusion/contribution]** åœ¨HatefulMemesæ•°æ®é›†ä¸Šè¾¾åˆ° AUROC 87.0%ï¼ˆSOTAï¼‰ï¼Œè¶…è¶ŠFlamingo-80Bç­‰å¤§å‹å¤šæ¨¡æ€æ¨¡å‹<br>**[limitation/future]** ä»‡æ¨è¨€è®ºçš„å®šä¹‰å…·æœ‰äº‰è®®æ€§ä¸æ–‡åŒ–ä¾èµ–æ€§ï¼›ç³»ç»Ÿå¯¹ ç»†å¾®é¢éƒ¨è¡¨æƒ… è¯†åˆ«èƒ½åŠ›æœ‰é™ï¼›ä¾èµ–æ•°æ®æ ‡æ³¨è´¨é‡ï¼Œå¯èƒ½å­˜åœ¨æ ‡æ³¨åå·®ã€‚</div></details></div>|

### Misinformation Analysis (5 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[News Source Credibility Assessment: A Reddit Case Study](https://ojs.aaai.org/index.php/ICWSM/article/view/35804) <br> Arash Amini, Yigit Ege Bayiz, Ashwin Ram, Radu Marculescu, and Ufuk Topcu <br> 2025-06-07|é€šè¿‡å¸–å­é—´çš„è¯„è®ºåŒºç›¸ä¼¼æ€§æ„å»ºåŠ æƒé“å­ç½‘ç»œï¼Œä»¥æ±‚æ‰¾åˆ°æ°´å†›è››ä¸é©¬è¿¹ï¼Œè¿›è€Œç¡®å®šæ–°é—»æ¥æºæ˜¯å¦å¯ä¿¡|<img width="1200" alt="pipeline" src="figures/CREDiBERT-NewsSou-1.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Driven by the proliferation of misinformation on social media, this work shifts focus from fact-checking individual news items to assessing the systemic credibility of news sources, addressing a critical gap in combating information pollution at its origin. \[ç¿»è¯‘\] æœ¬ç ”ç©¶å—ç¤¾äº¤åª’ä½“è™šå‡ä¿¡æ¯æ³›æ»¥çš„é©±åŠ¨ï¼Œå°†é‡ç‚¹ä»æ ¸æŸ¥å•ä¸€æ–°é—»çš„çœŸå®æ€§ï¼Œè½¬å‘è¯„ä¼°æ–°é—»æ¥æºçš„ç³»ç»Ÿæ€§å¯ä¿¡åº¦ï¼Œä»¥åº”å¯¹ä»æºå¤´æ²»ç†ä¿¡æ¯æ±¡æŸ“è¿™ä¸€å…³é”®é—®é¢˜ã€‚ **[innovation]** Its core innovation lies in constructing a weighted post-to-post network based on the semantic similarity of user comments. This network models latent socio-contextual linkages between submissions, which are then integrated via a Graph Convolutional Network \(GCN\) to enhance the binary classification of source credibility. \[ç¿»è¯‘\] å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºåŸºäºç”¨æˆ·è¯„è®ºçš„è¯­ä¹‰ç›¸ä¼¼æ€§æ„å»ºäº†ä¸€ä¸ªåŠ æƒå¸–å­é—´ç½‘ç»œã€‚è¯¥ç½‘ç»œå»ºæ¨¡äº†å¸–å­é—´æ½œåœ¨çš„ç¤¾ä¼šè¯­å¢ƒå…³è”ï¼Œå¹¶é€šè¿‡å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰æ•´åˆè¿™äº›å…³è”ï¼Œä»¥æå‡å¯¹æ–°é—»æ¥æºå¯ä¿¡åº¦çš„äºŒåˆ†ç±»æ€§èƒ½ã€‚ **[method]** The framework, CREDiBERT, first trains a bi-encoder on paired submissions about the same event to learn credibility-aware text embeddings. It then builds a novel graph where edge weights encode user reaction similarity via comments. Finally, a GCN fuses these textual and social signals for final classification. \[ç¿»è¯‘\] è¯¥æ¡†æ¶ï¼ˆCREDiBERTï¼‰é¦–å…ˆåœ¨æè¿°åŒä¸€äº‹ä»¶çš„æˆå¯¹å¸–å­ä¸Šè®­ç»ƒä¸€ä¸ªåŒç¼–ç å™¨ï¼Œä»¥å­¦ä¹ å…·æœ‰å¯ä¿¡åº¦æ„ŸçŸ¥çš„æ–‡æœ¬åµŒå…¥ã€‚éšåï¼Œå®ƒæ„å»ºäº†ä¸€ä¸ªæ–°é¢–çš„å›¾ç»“æ„ï¼Œå…¶ä¸­è¾¹çš„æƒé‡é€šè¿‡è¯„è®ºç¼–ç äº†ç”¨æˆ·ååº”çš„ç›¸ä¼¼æ€§ã€‚æœ€åï¼Œä¸€ä¸ªå›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰èåˆäº†è¿™äº›æ–‡æœ¬ä¸ç¤¾ä¼šä¿¡å·ä»¥å®Œæˆæœ€ç»ˆåˆ†ç±»ã€‚ **[conclusion/contribution]** The model outperforms BERT-based baselines by 3% in F1-score for credibility assessment. Incorporating the user-interaction graph yields a further 8% gain, demonstrating the significant value of socially-grounded signals in evaluating information ecosystems. \[ç¿»è¯‘\] è¯¥æ¨¡å‹åœ¨å¯ä¿¡åº¦è¯„ä¼°ä»»åŠ¡ä¸Šçš„F1åˆ†æ•°æ¯”åŸºäºBERTçš„åŸºçº¿æ¨¡å‹é«˜å‡º3%ã€‚èå…¥ç”¨æˆ·äº¤äº’å›¾åï¼Œæ€§èƒ½è¿›ä¸€æ­¥æå‡äº†8%ï¼Œè¿™è¯æ˜äº†åŸºäºç¤¾äº¤çš„æ„ŸçŸ¥ä¿¡å·åœ¨è¯„ä¼°ä¿¡æ¯ç”Ÿæ€ç³»ç»Ÿä¸­çš„é‡è¦ä»·å€¼ã€‚ **[limitation/future]** The method assesses source reputation rather than article veracity, leaving it blind to one-off falsehoods from otherwise credible outlets. Its performance is also tied to the bias present in the training data from specific online communities. \[ç¿»è¯‘\] è¯¥æ–¹æ³•è¯„ä¼°çš„æ˜¯æ¥æºå£°èª‰è€Œéæ–‡ç« çœŸå®æ€§ï¼Œå› æ­¤æ— æ³•è¯†åˆ«é‚£äº›æ¥è‡ªé€šå¸¸å¯ä¿¡åª’ä½“çš„å¶ç„¶æ€§è™šå‡ä¿¡æ¯ã€‚åŒæ—¶ï¼Œå…¶æ€§èƒ½å—é™äºæ¥è‡ªç‰¹å®šç½‘ç»œç¤¾åŒºçš„è®­ç»ƒæ•°æ®ä¸­å­˜åœ¨çš„å›ºæœ‰åå·®ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Driven by the proliferation of misinformation on social media, this work shifts focus from fact-checking individual news items to assessing the systemic credibility of news sources, addressing a critical gap in combating information pollution at its origin.<br>\[ç¿»è¯‘\]<br>æœ¬ç ”ç©¶å—ç¤¾äº¤åª’ä½“è™šå‡ä¿¡æ¯æ³›æ»¥çš„é©±åŠ¨ï¼Œå°†é‡ç‚¹ä»æ ¸æŸ¥å•ä¸€æ–°é—»çš„çœŸå®æ€§ï¼Œè½¬å‘è¯„ä¼°æ–°é—»æ¥æºçš„ç³»ç»Ÿæ€§å¯ä¿¡åº¦ï¼Œä»¥åº”å¯¹ä»æºå¤´æ²»ç†ä¿¡æ¯æ±¡æŸ“è¿™ä¸€å…³é”®é—®é¢˜ã€‚<br>**[innovation]** Its core innovation lies in constructing a weighted post-to-post network based on the semantic similarity of user comments. This network models latent socio-contextual linkages between submissions, which are then integrated via a Graph Convolutional Network \(GCN\) to enhance the binary classification of source credibility.<br>\[ç¿»è¯‘\]<br>å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºåŸºäºç”¨æˆ·è¯„è®ºçš„è¯­ä¹‰ç›¸ä¼¼æ€§æ„å»ºäº†ä¸€ä¸ªåŠ æƒå¸–å­é—´ç½‘ç»œã€‚è¯¥ç½‘ç»œå»ºæ¨¡äº†å¸–å­é—´æ½œåœ¨çš„ç¤¾ä¼šè¯­å¢ƒå…³è”ï¼Œå¹¶é€šè¿‡å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰æ•´åˆè¿™äº›å…³è”ï¼Œä»¥æå‡å¯¹æ–°é—»æ¥æºå¯ä¿¡åº¦çš„äºŒåˆ†ç±»æ€§èƒ½ã€‚<br>**[method]** The framework, CREDiBERT, first trains a bi-encoder on paired submissions about the same event to learn credibility-aware text embeddings. It then builds a novel graph where edge weights encode user reaction similarity via comments. Finally, a GCN fuses these textual and social signals for final classification.<br>\[ç¿»è¯‘\]<br>è¯¥æ¡†æ¶ï¼ˆCREDiBERTï¼‰é¦–å…ˆåœ¨æè¿°åŒä¸€äº‹ä»¶çš„æˆå¯¹å¸–å­ä¸Šè®­ç»ƒä¸€ä¸ªåŒç¼–ç å™¨ï¼Œä»¥å­¦ä¹ å…·æœ‰å¯ä¿¡åº¦æ„ŸçŸ¥çš„æ–‡æœ¬åµŒå…¥ã€‚éšåï¼Œå®ƒæ„å»ºäº†ä¸€ä¸ªæ–°é¢–çš„å›¾ç»“æ„ï¼Œå…¶ä¸­è¾¹çš„æƒé‡é€šè¿‡è¯„è®ºç¼–ç äº†ç”¨æˆ·ååº”çš„ç›¸ä¼¼æ€§ã€‚æœ€åï¼Œä¸€ä¸ªå›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰èåˆäº†è¿™äº›æ–‡æœ¬ä¸ç¤¾ä¼šä¿¡å·ä»¥å®Œæˆæœ€ç»ˆåˆ†ç±»ã€‚<br>**[conclusion/contribution]** The model outperforms BERT-based baselines by 3% in F1-score for credibility assessment. Incorporating the user-interaction graph yields a further 8% gain, demonstrating the significant value of socially-grounded signals in evaluating information ecosystems.<br>\[ç¿»è¯‘\]<br>è¯¥æ¨¡å‹åœ¨å¯ä¿¡åº¦è¯„ä¼°ä»»åŠ¡ä¸Šçš„F1åˆ†æ•°æ¯”åŸºäºBERTçš„åŸºçº¿æ¨¡å‹é«˜å‡º3%ã€‚èå…¥ç”¨æˆ·äº¤äº’å›¾åï¼Œæ€§èƒ½è¿›ä¸€æ­¥æå‡äº†8%ï¼Œè¿™è¯æ˜äº†åŸºäºç¤¾äº¤çš„æ„ŸçŸ¥ä¿¡å·åœ¨è¯„ä¼°ä¿¡æ¯ç”Ÿæ€ç³»ç»Ÿä¸­çš„é‡è¦ä»·å€¼ã€‚<br>**[limitation/future]** The method assesses source reputation rather than article veracity, leaving it blind to one-off falsehoods from otherwise credible outlets. Its performance is also tied to the bias present in the training data from specific online communities.<br>\[ç¿»è¯‘\]<br>è¯¥æ–¹æ³•è¯„ä¼°çš„æ˜¯æ¥æºå£°èª‰è€Œéæ–‡ç« çœŸå®æ€§ï¼Œå› æ­¤æ— æ³•è¯†åˆ«é‚£äº›æ¥è‡ªé€šå¸¸å¯ä¿¡åª’ä½“çš„å¶ç„¶æ€§è™šå‡ä¿¡æ¯ã€‚åŒæ—¶ï¼Œå…¶æ€§èƒ½å—é™äºæ¥è‡ªç‰¹å®šç½‘ç»œç¤¾åŒºçš„è®­ç»ƒæ•°æ®ä¸­å­˜åœ¨çš„å›ºæœ‰åå·®ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[notes\]å…³é”®è®¾è®¡åœ¨äºé€šè¿‡è¯„è®ºåŒºçš„è¯„è®ºç›¸ä¼¼æ€§å»ºæ¨¡ä¸åŒå¸–å­é—´çš„æ½œåœ¨è”ç³»ï¼ˆåŠ æƒå¸–å­ç½‘ç»œçš„è¾¹æƒé‡ï¼‰ï¼Œåœ¨GCNä¸­åˆ©ç”¨è¯¥è”ç³»æ¥è¿›è¡Œå¸–å­çš„æ¥æºæ–°é—»çš„å¯ä¿¡æ€§äºŒåˆ†ç±»<br>\[å¼•ç”¨æ–‡\]Amini et al. \(2025\) move beyond purely content-based pattern recognition, attempting instead to establish connections between posts and the credibility of news sources. Their CREDiBERT framework innovatively constructs a weighted post-to-post network from user comment similarities. This graph structure captures community-specific reaction patterns, which, when processed through a Graph Convolutional Network, significantly enhance the classification of news source credibility. This work underscores a paradigm shift: credibility assessment is beginning to focus on the patterns of information dissemination, rather than solely analyzing the specific content.<br>\[ç¿»è¯‘\]<br>Aminiç­‰äººï¼ˆ2025ï¼‰çš„ç ”ç©¶è¶…è¶Šäº†å•çº¯çš„åŸºäºå†…å®¹çš„æ¨¡å¼è¯†åˆ«ï¼Œè½¬è€Œå°è¯•å»ºç«‹å¸–å­ä¸æ–°é—»æ¥æºå¯ä¿¡åº¦çš„è”ç³»ã€‚ä»–ä»¬çš„CREDiBERTæ¡†æ¶åˆ›æ–°æ€§åœ°ä»ç”¨æˆ·è¯„è®ºç›¸ä¼¼æ€§ä¸­æ„å»ºäº†ä¸€ä¸ªåŠ æƒå¸–å­é—´ç½‘ç»œã€‚è¯¥å›¾ç»“æ„æ•è·äº†ç¤¾åŒºçš„ç‰¹å®šååº”æ¨¡å¼ï¼Œè¿™äº›æ¨¡å¼é€šè¿‡å›¾å·ç§¯ç½‘ç»œå¤„ç†åï¼Œæ˜¾è‘—å¢å¼ºäº†å¯¹æ–°é—»æ¥æºå¯ä¿¡åº¦çš„åˆ†ç±»èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†ä¸€ä¸ªèŒƒå¼è½¬å˜ï¼šå¯ä¿¡åº¦è¯„ä¼°å¼€å§‹å…³æ³¨æ¶ˆæ¯çš„ä¼ æ’­æ¨¡å¼ï¼Œè€Œä¸ä»…ä»…æ˜¯åˆ†æå…·ä½“å†…å®¹ã€‚</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-CIKM%20%2724-blue)]()<br>[Let silence speak: Enhancing fake news detection with generated comments from large language models](https://dl.acm.org/doi/10.1145/3627673.3679519) <br> Qiong Nan,Qiang Shengâˆ—,Juan Cao,Beizhe Hu,Danding Wang,Jintao Li <br> 2024-10-21|â€œè®©æ²‰é»˜çš„ç”¨æˆ·å‘å£°â€”â€”ç”¨LLMç”Ÿæˆå¤šæ ·è¯„è®ºï¼Œè¡¥å……è¯„è®ºç‰¹å¾ï¼Œæå‡è™šå‡æ–°é—»æ£€æµ‹çš„è¦†ç›–åŠ›å’Œæ—©æœŸæ€§èƒ½ã€‚â€|<img width="1200" alt="pipeline" src="figures/GenFEND-Letsile-1.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Comment-based fake news detection is hindered by the scarcity and skewed distribution of real user comments \(e.g., in early stages or from â€œsilentâ€ users\), leading to an incomplete and biased perception of public feedback.  \[ç¿»è¯‘\]åŸºäºè¯„è®ºçš„è™šå‡æ–°é—»æ£€æµ‹å—é™äºçœŸå®ç”¨æˆ·è¯„è®ºçš„ç¨€ç¼ºæ€§ä¸åˆ†å¸ƒåå·®ï¼ˆä¾‹å¦‚åœ¨æ—©æœŸä¼ æ’­é˜¶æ®µæˆ–æ¥è‡ªâ€œæ²‰é»˜â€ç”¨æˆ·ï¼‰ï¼Œå¯¼è‡´å¯¹å…¬ä¼—åé¦ˆçš„æ„ŸçŸ¥ä¸å®Œæ•´ä¸”å­˜åœ¨åå·®ã€‚ **[innovation]** ä½¿ç”¨LLMè¡¥å……è¯„è®ºç‰¹å¾ï¼Œè§£å†³è¯¥é¢†åŸŸè¯„è®ºæ•°æ®ä¸è¶³å’Œä¸å…¨é¢çš„é—®é¢˜ **[method]** The GenFEND framework: \(1\) generates comments by prompting an LLM with 30 predefined user profiles \(gender/age/education\); \(2\) analyzes them via group-wise semantic averaging and diversity measurement across demographic views; \(3\) aggregates intra-view and inter-view features adaptively for final classification.  \[ç¿»è¯‘\]GenFENDæ¡†æ¶ï¼š\(1\) é€šè¿‡ä¸ºLLMæä¾›30ä¸ªé¢„å®šä¹‰ç”¨æˆ·ç”»åƒï¼ˆæ€§åˆ«/å¹´é¾„/æ•™è‚²ï¼‰æ¥ç”Ÿæˆè¯„è®ºï¼›\(2\) é€šè¿‡åˆ†ç»„è¯­ä¹‰å¹³å‡å’Œè·¨äººå£ç»Ÿè®¡è§†å›¾çš„å¤šæ ·æ€§åº¦é‡å¯¹å…¶è¿›è¡Œåˆ†æï¼›\(3\) è‡ªé€‚åº”åœ°èšåˆè§†å›¾å†…å’Œè§†å›¾é—´çš„ç‰¹å¾ä»¥è¿›è¡Œæœ€ç»ˆåˆ†ç±»ã€‚ **[conclusion/contribution]** GenFEND consistently boosts both content-only and comment-based detectors across datasets. Notably, LLM-generated comments provide effective signals for early detection and can outperform actual comments, especially in identifying fake news.  \[ç¿»è¯‘\]GenFENDåœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠæŒç»­æå‡äº†ä»…ä½¿ç”¨å†…å®¹å’Œä½¿ç”¨è¯„è®ºçš„æ£€æµ‹å™¨æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒLLMç”Ÿæˆçš„è¯„è®ºä¸ºæ—©æœŸæ£€æµ‹æä¾›äº†æœ‰æ•ˆä¿¡å·ï¼Œå¹¶ä¸”å¯ä»¥è¶…è¶ŠçœŸå®è¯„è®ºçš„æ•ˆæœï¼Œå°¤å…¶åœ¨è¯†åˆ«è™šå‡æ–°é—»æ–¹é¢ã€‚ **[limitation/future]** Limitations include dependence on LLM generation quality, limited considered user attributes, and higher computational cost. Future work may explore more nuanced user modeling, dynamic profile generation, and integration with real social graphs.  \[ç¿»è¯‘\]å±€é™æ€§åŒ…æ‹¬å¯¹LLMç”Ÿæˆè´¨é‡çš„ä¾èµ–ã€æ‰€è€ƒè™‘ç”¨æˆ·å±æ€§çš„æœ‰é™æ€§ä»¥åŠè¾ƒé«˜çš„è®¡ç®—æˆæœ¬ã€‚æœªæ¥å·¥ä½œå¯æ¢ç´¢æ›´ç»†è‡´çš„ç”¨æˆ·å»ºæ¨¡ã€åŠ¨æ€ç”»åƒç”Ÿæˆä»¥åŠä¸çœŸå®ç¤¾äº¤å›¾è°±çš„ç»“åˆã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Comment-based fake news detection is hindered by the scarcity and skewed distribution of real user comments \(e.g., in early stages or from â€œsilentâ€ users\), leading to an incomplete and biased perception of public feedback.<br><br>\[ç¿»è¯‘\]åŸºäºè¯„è®ºçš„è™šå‡æ–°é—»æ£€æµ‹å—é™äºçœŸå®ç”¨æˆ·è¯„è®ºçš„ç¨€ç¼ºæ€§ä¸åˆ†å¸ƒåå·®ï¼ˆä¾‹å¦‚åœ¨æ—©æœŸä¼ æ’­é˜¶æ®µæˆ–æ¥è‡ªâ€œæ²‰é»˜â€ç”¨æˆ·ï¼‰ï¼Œå¯¼è‡´å¯¹å…¬ä¼—åé¦ˆçš„æ„ŸçŸ¥ä¸å®Œæ•´ä¸”å­˜åœ¨åå·®ã€‚<br>**[innovation]** ä½¿ç”¨LLMè¡¥å……è¯„è®ºç‰¹å¾ï¼Œè§£å†³è¯¥é¢†åŸŸè¯„è®ºæ•°æ®ä¸è¶³å’Œä¸å…¨é¢çš„é—®é¢˜<br>**[method]** The GenFEND framework: \(1\) generates comments by prompting an LLM with 30 predefined user profiles \(gender/age/education\); \(2\) analyzes them via group-wise semantic averaging and diversity measurement across demographic views; \(3\) aggregates intra-view and inter-view features adaptively for final classification.<br><br>\[ç¿»è¯‘\]GenFENDæ¡†æ¶ï¼š\(1\) é€šè¿‡ä¸ºLLMæä¾›30ä¸ªé¢„å®šä¹‰ç”¨æˆ·ç”»åƒï¼ˆæ€§åˆ«/å¹´é¾„/æ•™è‚²ï¼‰æ¥ç”Ÿæˆè¯„è®ºï¼›\(2\) é€šè¿‡åˆ†ç»„è¯­ä¹‰å¹³å‡å’Œè·¨äººå£ç»Ÿè®¡è§†å›¾çš„å¤šæ ·æ€§åº¦é‡å¯¹å…¶è¿›è¡Œåˆ†æï¼›\(3\) è‡ªé€‚åº”åœ°èšåˆè§†å›¾å†…å’Œè§†å›¾é—´çš„ç‰¹å¾ä»¥è¿›è¡Œæœ€ç»ˆåˆ†ç±»ã€‚<br>**[conclusion/contribution]** GenFEND consistently boosts both content-only and comment-based detectors across datasets. Notably, LLM-generated comments provide effective signals for early detection and can outperform actual comments, especially in identifying fake news.<br><br>\[ç¿»è¯‘\]GenFENDåœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠæŒç»­æå‡äº†ä»…ä½¿ç”¨å†…å®¹å’Œä½¿ç”¨è¯„è®ºçš„æ£€æµ‹å™¨æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒLLMç”Ÿæˆçš„è¯„è®ºä¸ºæ—©æœŸæ£€æµ‹æä¾›äº†æœ‰æ•ˆä¿¡å·ï¼Œå¹¶ä¸”å¯ä»¥è¶…è¶ŠçœŸå®è¯„è®ºçš„æ•ˆæœï¼Œå°¤å…¶åœ¨è¯†åˆ«è™šå‡æ–°é—»æ–¹é¢ã€‚<br>**[limitation/future]** Limitations include dependence on LLM generation quality, limited considered user attributes, and higher computational cost. Future work may explore more nuanced user modeling, dynamic profile generation, and integration with real social graphs.<br><br>\[ç¿»è¯‘\]å±€é™æ€§åŒ…æ‹¬å¯¹LLMç”Ÿæˆè´¨é‡çš„ä¾èµ–ã€æ‰€è€ƒè™‘ç”¨æˆ·å±æ€§çš„æœ‰é™æ€§ä»¥åŠè¾ƒé«˜çš„è®¡ç®—æˆæœ¬ã€‚æœªæ¥å·¥ä½œå¯æ¢ç´¢æ›´ç»†è‡´çš„ç”¨æˆ·å»ºæ¨¡ã€åŠ¨æ€ç”»åƒç”Ÿæˆä»¥åŠä¸çœŸå®ç¤¾äº¤å›¾è°±çš„ç»“åˆã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[å¼•ç”¨æ–‡\]Within the task of False Content Analysis, a key bottleneck is the scarcity of early-stage comments and the absence of opinions from silent users. The GenFEND framework \(Nan et al., 2024\) addresses this by using Large Language Models \(LLMs\) to supplement these missing comments. Instead of passively relying on sparse real comments, their approach actively generates a rich set of synthetic comments conditioned on diverse user profiles \(e.g., gender, age, education level\). This method effectively performs data augmentation in the social comment space, providing a stable and diverse informational supplement. This helps models establish a more complete perceptual foundation for veracity judgment and has proven to be highly effective for early fake news detection.<br>\[ç¿»è¯‘\]<br>åœ¨è™šå‡å†…å®¹åˆ†æä»»åŠ¡ä¸­ï¼Œä¸€ä¸ªå…³é”®ç“¶é¢ˆæ˜¯æ—©æœŸè¯„è®ºçš„ç¨€ç¼ºæ€§å’Œæ²‰é»˜ç”¨æˆ·æ„è§çš„ç¼ºå¤±ã€‚GenFENDæ¡†æ¶ \(Nan et al., 2024\) é€šè¿‡ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹æ¥è¡¥å……è¿™éƒ¨åˆ†ç¼ºå¤±çš„è¯„è®ºï¼Œä»è€Œè§£å†³äº†è¿™ä¸€é—®é¢˜ã€‚è¯¥æ–¹æ³•ä¸å†è¢«åŠ¨åœ°ä¾èµ–ç¨€ç–çš„çœŸå®è¯„è®ºï¼Œè€Œæ˜¯ä¸»åŠ¨ç”Ÿæˆä¸€ç»„ä»¥å¤šæ ·åŒ–ç”¨æˆ·ç”»åƒï¼ˆå¦‚æ€§åˆ«ã€å¹´é¾„ã€æ•™è‚²ç¨‹åº¦ï¼‰ä¸ºæ¡ä»¶çš„ä¸°å¯Œåˆæˆè¯„è®ºã€‚è¯¥æ–¹æ³•æœ‰æ•ˆåœ°åœ¨ç¤¾äº¤è¯„è®ºç©ºé—´è¿›è¡Œäº†æ•°æ®å¢å¼ºï¼Œæä¾›äº†ä¸€ä¸ªç¨³å®šä¸”å¤šæ ·åŒ–çš„ä¿¡æ¯è¡¥å……ã€‚è¿™æœ‰åŠ©äºæ¨¡å‹ä¸ºçœŸå®æ€§åˆ¤æ–­å»ºç«‹æ›´å®Œæ•´çš„æ„ŸçŸ¥åŸºç¡€ï¼Œå¹¶è¢«è¯æ˜å¯¹æ—©æœŸè™šå‡æ–°é—»æ£€æµ‹éå¸¸æœ‰æ•ˆã€‚</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence-blue)]()<br>[GAMC: An Unsupervised Method for Fake News Detection Using Graph Autoencoder with Masking](https://ojs.aaai.org/index.php/AAAI/article/view/27788) <br> Shu Yin,Peican Zhu,Lianwei Wu,Chao Gao,Zhen Wang <br> 2024-03-24|è‡ªç¼–ç å™¨æ–¹æ³•å¤„ç†ç±»ç¤¾äº¤ç½‘ç»œå›¾ç»“æ„|<img width="1200" alt="pipeline" src="figures/GAMC-GAMCAn-1.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** ç°æœ‰æ–¹æ³•å¤šä¾èµ–æ–°é—»å†…å®¹æˆ–éœ€å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨ä¼ æ’­ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ **[innovation]** é¦–ä¸ªç»“åˆå›¾è‡ªç¼–ç å™¨ã€æ©ç ä¸å¯¹æ¯”å­¦ä¹ çš„æ— ç›‘ç£å‡æ–°é—»æ£€æµ‹æ–¹æ³•ï¼ŒåŒæ—¶åˆ©ç”¨ä¼ æ’­ç»“æ„ä¸å†…å®¹ä¿¡æ¯ï¼Œæ— éœ€æ ‡æ³¨æ•°æ® **[method]** 1. å°†æ–°é—»ä¼ æ’­å»ºæ¨¡ä¸ºå›¾ï¼ˆæ–°é—»èŠ‚ç‚¹å’Œç”¨æˆ·èŠ‚ç‚¹ï¼Œè¾¹è¡¨ç¤ºè½¬å‘å…³ç³»ï¼ŒèŠ‚ç‚¹ç‰¹å¾æ¥è‡ªæ–°é—»å†…å®¹å’Œç”¨æˆ·å†å²è´´æ–‡ï¼‰ï¼› 2. æ•°æ®å¢å¼ºï¼ˆèŠ‚ç‚¹ç‰¹å¾æ©ç +è¾¹ä¸¢å¼ƒï¼‰ï¼ˆéšæœºé€‰å–èŠ‚ç‚¹å°†å…¶ç‰¹å¾æ›¿æ¢ä¸ºæ©ç æ ‡è®°ï¼Œéšæœºåˆ é™¤éƒ¨åˆ†è¾¹ï¼‰æ„é€ è‡ªç›‘ç£ç‰¹æ€§ï¼› 3. å›¾ç¼–ç å™¨ï¼ˆGINï¼‰ç”Ÿæˆæ½œåœ¨è¡¨ç¤ºï¼› 4. å›¾è§£ç å™¨é‡å»ºç‰¹å¾ï¼› 5. æŸå¤±å‡½æ•°ç»„æˆï¼ˆ**é‡å»ºæŸå¤±**ï¼ˆä½¿é‡å»ºç‰¹å¾æ¥è¿‘åŸå§‹ç‰¹å¾ï¼‰+**å¯¹æ¯”æŸå¤±**ï¼ˆæ¥è‡ªåŒä¸€ä¸ªåŸå§‹å›¾çš„ä¸¤ä¸ªå¢å¼ºå›¾é‡å»ºååº”å°½é‡ç›¸ä¼¼ï¼‰ï¼‰è®­ç»ƒã€‚ **[conclusion/contribution]** åœ¨ FakeNewsNet æ•°æ®é›†ä¸Šï¼ŒGAMC åœ¨æ— ç›‘ç£æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ï¼ˆå¦‚ GossipCop å‡†ç¡®ç‡ 0.946ï¼‰ï¼Œç”šè‡³æ¥è¿‘æˆ–è¶…è¶Šéƒ¨åˆ†ç›‘ç£æ–¹æ³• **[limitation/future]** éœ€è¦æ–°é—»å…·æœ‰ä¸€å®šçš„ä¼ æ’­é‡æ‰èƒ½å»ºæ¨¡ä¸ºå›¾ï¼›æ—©æœŸä¼ æ’­é˜¶æ®µæ£€æµ‹èƒ½åŠ›å—é™">**[summary]**</summary><div style="margin-top:6px">**[motivation]** ç°æœ‰æ–¹æ³•å¤šä¾èµ–æ–°é—»å†…å®¹æˆ–éœ€å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨ä¼ æ’­ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚<br>**[innovation]** é¦–ä¸ªç»“åˆå›¾è‡ªç¼–ç å™¨ã€æ©ç ä¸å¯¹æ¯”å­¦ä¹ çš„æ— ç›‘ç£å‡æ–°é—»æ£€æµ‹æ–¹æ³•ï¼ŒåŒæ—¶åˆ©ç”¨ä¼ æ’­ç»“æ„ä¸å†…å®¹ä¿¡æ¯ï¼Œæ— éœ€æ ‡æ³¨æ•°æ®<br>**[method]** 1. å°†æ–°é—»ä¼ æ’­å»ºæ¨¡ä¸ºå›¾ï¼ˆæ–°é—»èŠ‚ç‚¹å’Œç”¨æˆ·èŠ‚ç‚¹ï¼Œè¾¹è¡¨ç¤ºè½¬å‘å…³ç³»ï¼ŒèŠ‚ç‚¹ç‰¹å¾æ¥è‡ªæ–°é—»å†…å®¹å’Œç”¨æˆ·å†å²è´´æ–‡ï¼‰ï¼›<br>2. æ•°æ®å¢å¼ºï¼ˆèŠ‚ç‚¹ç‰¹å¾æ©ç +è¾¹ä¸¢å¼ƒï¼‰ï¼ˆéšæœºé€‰å–èŠ‚ç‚¹å°†å…¶ç‰¹å¾æ›¿æ¢ä¸ºæ©ç æ ‡è®°ï¼Œéšæœºåˆ é™¤éƒ¨åˆ†è¾¹ï¼‰æ„é€ è‡ªç›‘ç£ç‰¹æ€§ï¼›<br>3. å›¾ç¼–ç å™¨ï¼ˆGINï¼‰ç”Ÿæˆæ½œåœ¨è¡¨ç¤ºï¼›<br>4. å›¾è§£ç å™¨é‡å»ºç‰¹å¾ï¼›<br>5. æŸå¤±å‡½æ•°ç»„æˆï¼ˆ**é‡å»ºæŸå¤±**ï¼ˆä½¿é‡å»ºç‰¹å¾æ¥è¿‘åŸå§‹ç‰¹å¾ï¼‰+**å¯¹æ¯”æŸå¤±**ï¼ˆæ¥è‡ªåŒä¸€ä¸ªåŸå§‹å›¾çš„ä¸¤ä¸ªå¢å¼ºå›¾é‡å»ºååº”å°½é‡ç›¸ä¼¼ï¼‰ï¼‰è®­ç»ƒã€‚<br>**[conclusion/contribution]** åœ¨ FakeNewsNet æ•°æ®é›†ä¸Šï¼ŒGAMC åœ¨æ— ç›‘ç£æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ï¼ˆå¦‚ GossipCop å‡†ç¡®ç‡ 0.946ï¼‰ï¼Œç”šè‡³æ¥è¿‘æˆ–è¶…è¶Šéƒ¨åˆ†ç›‘ç£æ–¹æ³•<br>**[limitation/future]** éœ€è¦æ–°é—»å…·æœ‰ä¸€å®šçš„ä¼ æ’­é‡æ‰èƒ½å»ºæ¨¡ä¸ºå›¾ï¼›æ—©æœŸä¼ æ’­é˜¶æ®µæ£€æµ‹èƒ½åŠ›å—é™</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-Companion%20Proceedings%20of%20the%20Web%20Conference%202021-blue)]()<br>[How does truth evolve into fake news? An empirical study of fake news evolution](https://dl.acm.org/doi/10.1145/3442442.3452328) <br> Mingfei Guoï¼ŒXiuying Chenï¼ŒJuntao Liï¼ŒDongyan Zhaoï¼ŒRui Yan <br> 2021-06-03|ä¸€ä¸ªåŒ…å«\[åŸå§‹æ–°é—»ã€å‡æ–°é—»ã€æ¼”åŒ–åçš„å‡æ–°é—»\]ä¸‰å…ƒç»„çš„æ•°æ®é›†|<img width="1200" alt="pipeline" src="figures/FNE-Howdoes-1.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** è€Œç°æœ‰æ•°æ®é›†å¤šå…³æ³¨é™æ€æ ‡æ³¨ï¼Œç¼ºä¹å¯¹å…¶å‡æ–°é—»æ¼”åŒ–è¿‡ç¨‹çš„ç ”ç©¶ **[innovation]** ç»™å‡ºäº†å…³æ³¨å‡æ–°é—»æ¼”åŒ–çš„æ•°æ®é›†FNEï¼ŒåŒ…å«â€œçœŸç›¸-è™šå‡æ–°é—»-æ¼”åŒ–è™šå‡æ–°é—»â€ä¸‰å…ƒç»„ **[method]** 1. ä» Snopes.com\(ä¸€ä¸ªè¾Ÿè°£ç½‘ç«™\) æŠ“å–truthæ–‡ç« ï¼› 2. é€šè¿‡å…¶å¼•æ–‡æ”¶é›†è™šå‡æ–°é—»ï¼› 3. åˆ©ç”¨ç½‘é¡µå­˜æ¡£å¹³å°ï¼ˆå¦‚ Archive Todayï¼‰è·å–æ¼”åŒ–åç‰ˆæœ¬ï¼› 4. åˆ†æè™šå‡ä¿¡æ¯æŠ€æœ¯åˆ†ç±»ï¼ˆæé€ ã€å¦è®¤ã€æ··æ·†ã€æ­ªæ›²å››ç±»ã€æ–‡æœ¬ç›¸ä¼¼åº¦ã€å…³é”®è¯ã€è¯æ€§ã€æƒ…æ„Ÿç­‰å±æ€§ã€‚ **[conclusion/contribution]** æ¼”åŒ–åè™šå‡æ–°é—»ä¸åŸå§‹è™šå‡æ–°é—»ç›¸ä¼¼åº¦æ›´é«˜ï¼Œæƒ…æ„Ÿæ›´å®¢è§‚ç§¯æï¼Œæ›´éš¾ä»¥è¢«ç°æœ‰åˆ†ç±»æ¨¡å‹æ£€æµ‹ï¼›è™šå‡ä¿¡æ¯æŠ€æœ¯ä¸­ä»¥â€œæé€ â€ä¸ºä¸»ï¼›è¯æ€§å’Œå…³é”®è¯åœ¨æ¼”åŒ–ä¸­ä¿æŒç¨³å®šã€‚ **[limitation/future]** æ•°æ®æ¥æºä¾èµ–å•ä¸€äº‹å®æ ¸æŸ¥ç½‘ç«™ï¼ˆSnopesï¼‰ï¼Œå¯èƒ½å¼•å…¥åè§ï¼›ä»…å…³æ³¨æ–‡æœ¬æ–°é—»ï¼Œæœªæ¶µç›–å›¾åƒã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ¼”å˜ï¼›">**[summary]**</summary><div style="margin-top:6px">**[motivation]** è€Œç°æœ‰æ•°æ®é›†å¤šå…³æ³¨é™æ€æ ‡æ³¨ï¼Œç¼ºä¹å¯¹å…¶å‡æ–°é—»æ¼”åŒ–è¿‡ç¨‹çš„ç ”ç©¶<br>**[innovation]** ç»™å‡ºäº†å…³æ³¨å‡æ–°é—»æ¼”åŒ–çš„æ•°æ®é›†FNEï¼ŒåŒ…å«â€œçœŸç›¸-è™šå‡æ–°é—»-æ¼”åŒ–è™šå‡æ–°é—»â€ä¸‰å…ƒç»„<br>**[method]** 1. ä» Snopes.com\(ä¸€ä¸ªè¾Ÿè°£ç½‘ç«™\) æŠ“å–truthæ–‡ç« ï¼›<br>2. é€šè¿‡å…¶å¼•æ–‡æ”¶é›†è™šå‡æ–°é—»ï¼›<br>3. åˆ©ç”¨ç½‘é¡µå­˜æ¡£å¹³å°ï¼ˆå¦‚ Archive Todayï¼‰è·å–æ¼”åŒ–åç‰ˆæœ¬ï¼›<br>4. åˆ†æè™šå‡ä¿¡æ¯æŠ€æœ¯åˆ†ç±»ï¼ˆæé€ ã€å¦è®¤ã€æ··æ·†ã€æ­ªæ›²å››ç±»ã€æ–‡æœ¬ç›¸ä¼¼åº¦ã€å…³é”®è¯ã€è¯æ€§ã€æƒ…æ„Ÿç­‰å±æ€§ã€‚<br>**[conclusion/contribution]** æ¼”åŒ–åè™šå‡æ–°é—»ä¸åŸå§‹è™šå‡æ–°é—»ç›¸ä¼¼åº¦æ›´é«˜ï¼Œæƒ…æ„Ÿæ›´å®¢è§‚ç§¯æï¼Œæ›´éš¾ä»¥è¢«ç°æœ‰åˆ†ç±»æ¨¡å‹æ£€æµ‹ï¼›è™šå‡ä¿¡æ¯æŠ€æœ¯ä¸­ä»¥â€œæé€ â€ä¸ºä¸»ï¼›è¯æ€§å’Œå…³é”®è¯åœ¨æ¼”åŒ–ä¸­ä¿æŒç¨³å®šã€‚<br>**[limitation/future]** æ•°æ®æ¥æºä¾èµ–å•ä¸€äº‹å®æ ¸æŸ¥ç½‘ç«™ï¼ˆSnopesï¼‰ï¼Œå¯èƒ½å¼•å…¥åè§ï¼›ä»…å…³æ³¨æ–‡æœ¬æ–°é—»ï¼Œæœªæ¶µç›–å›¾åƒã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ¼”å˜ï¼›</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence-blue)]()<br>[Learning Complex Heterogeneous Multimodal Fake News via Social Latent Network Inference](https://ojs.aaai.org/index.php/AAAI/article/view/32022) <br> Mingxin Li,Yuchen Zhang,Haowei Xu,Xianghua Li\*,Chao Gao,Zhen Wang <br> 2025-04-11|é€šè¿‡ç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­ä¸è‡ªç›‘ç£å¤šæ¨¡æ€å­¦ä¹ æ£€æµ‹å¤æ‚å¼‚è´¨å¤šæ¨¡æ€å‡æ–°é—»çš„GNNæ–¹æ³•|<img width="1200" alt="pipeline" src="figures/HML-Learning-1.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** ç¤¾äº¤å¹³å°å¤šå…ƒåŒ–å¯¼è‡´æ–°é—»ä¼ æ’­å¤æ‚ã€å¤šæ¨¡æ€ï¼Œä¼ ç»Ÿå‡æ–°é—»æ£€æµ‹æ–¹æ³•ä¾èµ–æ˜¾å¼ä¼ æ’­å…³ç³»ï¼ˆå¦‚è½¬å‘ï¼‰ï¼Œåœ¨æŠ–éŸ³ç­‰å¹³å°éš¾ä»¥ç›´æ¥è·å–ï¼Œæ£€æµ‹éš¾åº¦å¤§ã€‚ **[innovation]** æå‡ºâ€œç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­Latent Network Inferenceâ€ç­–ç•¥ï¼Œæ— éœ€çœŸå®ä¼ æ’­å…³ç³»ï¼Œå³å¯æ„å»ºæ–°é—»é—´çš„æ½œåœ¨è”ç³» **[method]** 1. ç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­ï¼šåŸºäºHawkes Processå»ºæ¨¡æ–°é—»å½±å“åŠ›éšæ—¶é—´å˜åŒ–ï¼Œå¾—åˆ°äº‹ä»¶å†…éƒ¨ä¸äº‹ä»¶é—´çš„å½±å“å¼ºåº¦ï¼Œæ¨æ–­å‡ºæ½œåœ¨ä¼ æ’­ç½‘ç»œã€‚ 2. å¼‚è´¨å›¾æ„å»ºï¼šèŠ‚ç‚¹å‡ä¸ºæ–°é—»ï¼Œè¾¹ç±»å‹åŸºäºå„ç§ç›¸åŒæˆ–ç›¸ä¼¼å±æ€§ï¼ˆå¦‚ä½œè€…ã€æ ‡é¢˜ã€æ—¶é—´ç­‰ï¼‰æ„å»ºã€‚ä½¿ç”¨**æ³¨æ„åŠ›æœºåˆ¶**åŠ¨æ€èåˆä¸åŒè¾¹ç±»å‹ï¼Œç”Ÿæˆç»Ÿä¸€çš„å¼‚è´¨å›¾è¡¨ç¤ºï¼ˆæ¯ä¸ªç±»å‹çš„è¾¹çœ‹åšä¸€ä¸ªâ€œå¤´â€ï¼Œåˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›æ–¹æ³•ï¼‰ 3. è‡ªç›‘ç£å¤šæ¨¡æ€å†…å®¹å­¦ä¹ ï¼šæŸå¤±å‡½æ•°ï¼šå•æ¨¡æ€å¢å¼ºï¼ˆå¯¹åŒä¸€æ¨¡æ€è¿›è¡Œæ©ç ä¸é‡æ„ï¼‰ã€è·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ ï¼ˆå¯¹é½ä¸åŒæ¨¡æ€ï¼ˆå¦‚æ–‡æœ¬ä¸è§†é¢‘ï¼‰çš„ç‰¹å¾ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ æ‹‰è¿‘æ­£æ ·æœ¬ã€æ¨å¼€è´Ÿæ ·æœ¬ï¼‰ 4. ä¸ªæ€§åŒ–å›¾è¡¨ç¤ºä¸åˆ†ç±»ï¼šä½¿ç”¨å›¾Transformer Encoderèåˆå›¾ç»“æ„ä¸æ¨¡æ€ç‰¹å¾ï¼Œè¿›è¡Œåˆ†ç±»ã€‚ **[conclusion/contribution]** FakeSVå’ŒFVCæ•°æ®é›†ä¸Šå‡†ç¡®ç‡å‡è¶…89%ï¼Œè¾ƒSOTAæå‡0.12%~4.39%ï¼›åœ¨Twitter/å¾®åšä½œä¸ºæ’ä»¶ä¹Ÿæå‡æ˜æ˜¾ï¼ˆæœ€é«˜+10.71% F1ï¼‰ **[limitation/future]** ä¾èµ–äº‹ä»¶å®šä¹‰ä¸æ—¶é—´åºåˆ—å‡è®¾ï¼Œå¯¹å®æ—¶æ€§è¦æ±‚é«˜ï¼›è®¡ç®—å¤æ‚åº¦è¾ƒé«˜">**[summary]**</summary><div style="margin-top:6px">**[motivation]** ç¤¾äº¤å¹³å°å¤šå…ƒåŒ–å¯¼è‡´æ–°é—»ä¼ æ’­å¤æ‚ã€å¤šæ¨¡æ€ï¼Œä¼ ç»Ÿå‡æ–°é—»æ£€æµ‹æ–¹æ³•ä¾èµ–æ˜¾å¼ä¼ æ’­å…³ç³»ï¼ˆå¦‚è½¬å‘ï¼‰ï¼Œåœ¨æŠ–éŸ³ç­‰å¹³å°éš¾ä»¥ç›´æ¥è·å–ï¼Œæ£€æµ‹éš¾åº¦å¤§ã€‚<br>**[innovation]** æå‡ºâ€œç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­Latent Network Inferenceâ€ç­–ç•¥ï¼Œæ— éœ€çœŸå®ä¼ æ’­å…³ç³»ï¼Œå³å¯æ„å»ºæ–°é—»é—´çš„æ½œåœ¨è”ç³»<br>**[method]** 1. ç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­ï¼šåŸºäºHawkes Processå»ºæ¨¡æ–°é—»å½±å“åŠ›éšæ—¶é—´å˜åŒ–ï¼Œå¾—åˆ°äº‹ä»¶å†…éƒ¨ä¸äº‹ä»¶é—´çš„å½±å“å¼ºåº¦ï¼Œæ¨æ–­å‡ºæ½œåœ¨ä¼ æ’­ç½‘ç»œã€‚<br>2. å¼‚è´¨å›¾æ„å»ºï¼šèŠ‚ç‚¹å‡ä¸ºæ–°é—»ï¼Œè¾¹ç±»å‹åŸºäºå„ç§ç›¸åŒæˆ–ç›¸ä¼¼å±æ€§ï¼ˆå¦‚ä½œè€…ã€æ ‡é¢˜ã€æ—¶é—´ç­‰ï¼‰æ„å»ºã€‚ä½¿ç”¨**æ³¨æ„åŠ›æœºåˆ¶**åŠ¨æ€èåˆä¸åŒè¾¹ç±»å‹ï¼Œç”Ÿæˆç»Ÿä¸€çš„å¼‚è´¨å›¾è¡¨ç¤ºï¼ˆæ¯ä¸ªç±»å‹çš„è¾¹çœ‹åšä¸€ä¸ªâ€œå¤´â€ï¼Œåˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›æ–¹æ³•ï¼‰<br>3. è‡ªç›‘ç£å¤šæ¨¡æ€å†…å®¹å­¦ä¹ ï¼šæŸå¤±å‡½æ•°ï¼šå•æ¨¡æ€å¢å¼ºï¼ˆå¯¹åŒä¸€æ¨¡æ€è¿›è¡Œæ©ç ä¸é‡æ„ï¼‰ã€è·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ ï¼ˆå¯¹é½ä¸åŒæ¨¡æ€ï¼ˆå¦‚æ–‡æœ¬ä¸è§†é¢‘ï¼‰çš„ç‰¹å¾ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ æ‹‰è¿‘æ­£æ ·æœ¬ã€æ¨å¼€è´Ÿæ ·æœ¬ï¼‰<br>4. ä¸ªæ€§åŒ–å›¾è¡¨ç¤ºä¸åˆ†ç±»ï¼šä½¿ç”¨å›¾Transformer Encoderèåˆå›¾ç»“æ„ä¸æ¨¡æ€ç‰¹å¾ï¼Œè¿›è¡Œåˆ†ç±»ã€‚<br>**[conclusion/contribution]** FakeSVå’ŒFVCæ•°æ®é›†ä¸Šå‡†ç¡®ç‡å‡è¶…89%ï¼Œè¾ƒSOTAæå‡0.12%~4.39%ï¼›åœ¨Twitter/å¾®åšä½œä¸ºæ’ä»¶ä¹Ÿæå‡æ˜æ˜¾ï¼ˆæœ€é«˜+10.71% F1ï¼‰<br>**[limitation/future]** ä¾èµ–äº‹ä»¶å®šä¹‰ä¸æ—¶é—´åºåˆ—å‡è®¾ï¼Œå¯¹å®æ—¶æ€§è¦æ±‚é«˜ï¼›è®¡ç®—å¤æ‚åº¦è¾ƒé«˜</div></details></div>|

### Sentiment Analysis (3 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
|[![Star](https://img.shields.io/github/stars/neuralnaresh/multimodal-emotion-recognition.svg?style=social&label=Star)](https://github.com/neuralnaresh/multimodal-emotion-recognition) [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%2031st%20ACM%20International%20Conference%20on%20Multimedia-blue)]()<br>[Multi-label emotion analysis in conversation via multimodal knowledge distillation](https://dl.acm.org/doi/10.1145/3581783.3612517) <br> Sidharth Anandâˆ—,Naresh Kumar Devulapallyâˆ—,Sreyasee Das Bhattacharjee,Junsong Yuan <br> 2023-10-27|ä¸‰ä¸ªä¸“å®¶åˆ†åˆ«å¤„ç†ä¸€ä¸ªæ¨¡æ€ï¼Œè®­ç»ƒçš„åŒæ—¶å°†èƒ½åŠ›è’¸é¦ç»™èåˆåˆ†æ”¯ï¼Œæœ€ç»ˆå½¢æˆä¸€ä¸ªæ•´ä½“æ¨¡å‹ï¼Œæ•™å¸ˆï¼ˆåˆ†æ”¯ä¸“å®¶ï¼‰ä¸å­¦ç”Ÿï¼ˆèåˆä¸“å®¶ï¼‰ä¸€åŒå¤„ç†å¤šæ¨¡æ€å†…å®¹ï¼Œå¾—åˆ°æƒ…æ„Ÿåˆ†ç±»|| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Addresses the limitations of single-dominant emotion assumptions by tackling the challenge of multi-label emotion co-occurrence and generalization across diverse socio-demographic groups, particularly varying age populations. \[ç¿»è¯‘\] é’ˆå¯¹ç°æœ‰å¤šæ¨¡æ€æ–¹æ³•ä¸»è¦å…³æ³¨å•ä¸€ä¸»å¯¼æƒ…æ„Ÿçš„å±€é™æ€§ï¼Œè¯¥ç ”ç©¶è‡´åŠ›äºè§£å†³æƒ…æ„Ÿæ ‡ç­¾å…±ç°çš„è¯†åˆ«éš¾é¢˜ï¼Œå¹¶æå‡æ¨¡å‹åœ¨ä¸åŒç¤¾ä¼šäººå£ç»Ÿè®¡å­¦ç¾¤ä½“ï¼ˆç‰¹åˆ«æ˜¯ä¸åŒå¹´é¾„æ®µäººç¾¤ï¼‰ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚ **[innovation]** å°†å¤šæ¨¡æ€çŸ¥è¯†è’¸é¦ä¸æ ‡ç­¾ä¸€è‡´æ€§æ ¡å‡†æŸå¤±ï¼ˆLCCï¼‰ç›¸ç»“åˆï¼Œå‡è½»äº†æ¨¡å‹å¯¹ç®€å•æ ‡ç­¾çš„è¿‡æ‹Ÿåˆï¼ˆä¿è¯ç½®ä¿¡åº¦ç›¸è¿‘ï¼‰ï¼›æ„å»ºäº†ä¸€ä¸ªåˆ©ç”¨è’¸é¦æ–¹æ³•çš„æ•´ä½“æ¡†æ¶ï¼Œå…¶ç›®çš„æ˜¯ä¸ºäº†èåˆå„æ¨¡æ€èƒ½åŠ› **[method]** Employing a Multimodal Transformer Network where mode-specific peer branches \(visual, audio, textual\) collaboratively distill learned probabilistic uncertainty into a fusion branch via cross-network attention and noise contrastive estimation.â€¦â€¦ \[ç¿»è¯‘\] å°†ä¸‰ä¸ªç‰¹å®šæ¨¡æ€çš„å¯¹ç­‰åˆ†æ”¯é€šè¿‡è·¨ç½‘ç»œæ³¨æ„åŠ›å’Œå™ªå£°å¯¹æ¯”ä¼°è®¡ï¼ŒååŒåœ°å°†å…¶å­¦ä¹ åˆ°çš„æ¦‚ç‡è’¸é¦åˆ°èåˆåˆ†æ”¯ä¸­ï¼Œæ„å»ºäº†ä¸€ä¸ªæ‹¥æœ‰å››ä¸ªåˆ†æ”¯çš„æ•´ä½“é¢„æµ‹æ¨¡å‹ã€‚\[å€¼å¾—å…³æ³¨\]è§†é¢‘ä½¿ç”¨Tubelet embeddingæŠ€æœ¯ï¼Œå°†è§†é¢‘åˆ‡åˆ†ä¸ºæ—¶ç©ºå°å—ï¼ˆSpatial-Temporal Tubesï¼‰ï¼Œä¿ç•™æ—¶ç©ºä¿¡æ¯ **[conclusion/contribution]** Demonstrates state-of-the-art performance on MOSEI, EmoReact, and ElderReact datasets, achieving an approximate 17% improvement in weighted F1-score during cross-dataset evaluations, thereby validating robustness in age-diverse scenarios. \[ç¿»è¯‘\] åœ¨MOSEIã€EmoReactå’ŒElderReactæ•°æ®é›†ä¸Šæœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè·¨æ•°æ®é›†è¯„ä¼°æœ‰çº¦17%çš„åŠ æƒF1æå‡ï¼Œåœ¨è·¨å¹´é¾„åœºæ™¯ä¸‹å…·æœ‰é²æ£’æ€§ã€‚ **[limitation/future]** The approach necessitates the reduction of complex emotion categories to basic subsets for cross-dataset consistency and entails significant computational overhead due to the spatiotemporal tubelet embedding mechanism. \[ç¿»è¯‘\] ä¸ºäº†ä¿æŒè·¨æ•°æ®é›†ä¸€è‡´æ€§ï¼Œè¦å°†å¤æ‚æƒ…æ„Ÿç±»å½’çº¦ä¸ºåŸºç¡€å­é›†ï¼Œç”±äºé‡‡ç”¨æ—¶ç©ºTubeletåµŒå…¥æœºåˆ¶ï¼Œå¯¼è‡´äº†æ˜¾è‘—çš„è®¡ç®—å¼€é”€">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Addresses the limitations of single-dominant emotion assumptions by tackling the challenge of multi-label emotion co-occurrence and generalization across diverse socio-demographic groups, particularly varying age populations.<br>\[ç¿»è¯‘\] é’ˆå¯¹ç°æœ‰å¤šæ¨¡æ€æ–¹æ³•ä¸»è¦å…³æ³¨å•ä¸€ä¸»å¯¼æƒ…æ„Ÿçš„å±€é™æ€§ï¼Œè¯¥ç ”ç©¶è‡´åŠ›äºè§£å†³æƒ…æ„Ÿæ ‡ç­¾å…±ç°çš„è¯†åˆ«éš¾é¢˜ï¼Œå¹¶æå‡æ¨¡å‹åœ¨ä¸åŒç¤¾ä¼šäººå£ç»Ÿè®¡å­¦ç¾¤ä½“ï¼ˆç‰¹åˆ«æ˜¯ä¸åŒå¹´é¾„æ®µäººç¾¤ï¼‰ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚<br>**[innovation]** å°†å¤šæ¨¡æ€çŸ¥è¯†è’¸é¦ä¸æ ‡ç­¾ä¸€è‡´æ€§æ ¡å‡†æŸå¤±ï¼ˆLCCï¼‰ç›¸ç»“åˆï¼Œå‡è½»äº†æ¨¡å‹å¯¹ç®€å•æ ‡ç­¾çš„è¿‡æ‹Ÿåˆï¼ˆä¿è¯ç½®ä¿¡åº¦ç›¸è¿‘ï¼‰ï¼›æ„å»ºäº†ä¸€ä¸ªåˆ©ç”¨è’¸é¦æ–¹æ³•çš„æ•´ä½“æ¡†æ¶ï¼Œå…¶ç›®çš„æ˜¯ä¸ºäº†èåˆå„æ¨¡æ€èƒ½åŠ›<br>**[method]** Employing a Multimodal Transformer Network where mode-specific peer branches \(visual, audio, textual\) collaboratively distill learned probabilistic uncertainty into a fusion branch via cross-network attention and noise contrastive estimation.â€¦â€¦<br>\[ç¿»è¯‘\] å°†ä¸‰ä¸ªç‰¹å®šæ¨¡æ€çš„å¯¹ç­‰åˆ†æ”¯é€šè¿‡è·¨ç½‘ç»œæ³¨æ„åŠ›å’Œå™ªå£°å¯¹æ¯”ä¼°è®¡ï¼ŒååŒåœ°å°†å…¶å­¦ä¹ åˆ°çš„æ¦‚ç‡è’¸é¦åˆ°èåˆåˆ†æ”¯ä¸­ï¼Œæ„å»ºäº†ä¸€ä¸ªæ‹¥æœ‰å››ä¸ªåˆ†æ”¯çš„æ•´ä½“é¢„æµ‹æ¨¡å‹ã€‚\[å€¼å¾—å…³æ³¨\]è§†é¢‘ä½¿ç”¨Tubelet embeddingæŠ€æœ¯ï¼Œå°†è§†é¢‘åˆ‡åˆ†ä¸ºæ—¶ç©ºå°å—ï¼ˆSpatial-Temporal Tubesï¼‰ï¼Œä¿ç•™æ—¶ç©ºä¿¡æ¯<br>**[conclusion/contribution]** Demonstrates state-of-the-art performance on MOSEI, EmoReact, and ElderReact datasets, achieving an approximate 17% improvement in weighted F1-score during cross-dataset evaluations, thereby validating robustness in age-diverse scenarios.<br>\[ç¿»è¯‘\] åœ¨MOSEIã€EmoReactå’ŒElderReactæ•°æ®é›†ä¸Šæœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè·¨æ•°æ®é›†è¯„ä¼°æœ‰çº¦17%çš„åŠ æƒF1æå‡ï¼Œåœ¨è·¨å¹´é¾„åœºæ™¯ä¸‹å…·æœ‰é²æ£’æ€§ã€‚<br>**[limitation/future]** The approach necessitates the reduction of complex emotion categories to basic subsets for cross-dataset consistency and entails significant computational overhead due to the spatiotemporal tubelet embedding mechanism.<br>\[ç¿»è¯‘\] ä¸ºäº†ä¿æŒè·¨æ•°æ®é›†ä¸€è‡´æ€§ï¼Œè¦å°†å¤æ‚æƒ…æ„Ÿç±»å½’çº¦ä¸ºåŸºç¡€å­é›†ï¼Œç”±äºé‡‡ç”¨æ—¶ç©ºTubeletåµŒå…¥æœºåˆ¶ï¼Œå¯¼è‡´äº†æ˜¾è‘—çš„è®¡ç®—å¼€é”€</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">ã€é¢å‘ç»“æœæ¨¡å‹è®­ç»ƒã€‘\[å¼•ç”¨å¥\]"Transscending the traditional paradigm of identifying single dominant emotions, Anand et al. \[2023\] proposed SeMuL-PCD to enhance the granularity of affective perception in diverse social contexts; by leveraging a collaborative distillation mechanism that calibrates mode-specific feedback, their model robustly disentangles multi-label emotional co-occurrences across varying demographic backgrounds \(e.g., children and the elderly\), thereby providing a more nuanced foundation for socially adaptive agents."<br>\[ç¿»è¯‘\] â€œä¸ºäº†è¶…è¶Šè¯†åˆ«å•ä¸€ä¸»å¯¼æƒ…æ„Ÿçš„ä¼ ç»ŸèŒƒå¼ï¼ŒAnandç­‰äºº\[2023\]æå‡ºäº†SeMuL-PCDï¼Œæ—¨åœ¨å¢å¼ºä¸åŒç¤¾ä¼šè¯­å¢ƒä¸‹æƒ…æ„Ÿæ„ŸçŸ¥çš„ç²’åº¦ï¼›é€šè¿‡åˆ©ç”¨ä¸€ç§æ ¡å‡†æ¨¡æ€ç‰¹å®šåé¦ˆçš„åä½œè’¸é¦æœºåˆ¶ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒçš„äººå£ç»Ÿè®¡èƒŒæ™¯ï¼ˆå¦‚å„¿ç«¥å’Œè€äººï¼‰ä¸‹é²æ£’åœ°è§£è€¦å¤šæ ‡ç­¾æƒ…æ„Ÿçš„å…±ç°å…³ç³»ï¼Œä»è€Œä¸ºå…·å¤‡ç¤¾ä¼šé€‚åº”èƒ½åŠ›çš„æ™ºèƒ½ä½“æä¾›äº†æ›´ç²¾ç»†çš„æƒ…æ„Ÿç†è§£åŸºç¡€ã€‚â€</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/dess-mannheim/temporal-adapters.svg?style=social&label=Star)](https://github.com/dess-mannheim/temporal-adapters) [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Extracting affect aggregates from longitudinal social media data with temporal adapters for large...](https://ojs.aaai.org/index.php/ICWSM/article/view/35801) <br> Georg Ahnert, Max Pellert, David Garcia, Markus Strohmaier <br> 2025-06-07|å¯¹äºæ¯å‘¨ï¼Œè®­ç»ƒä¸€ä¸ªLoRAä½œä¸ºæ—¶é—´é€‚é…å™¨ï¼Œä½¿æ¨¡å‹è·å¾—äº†æ ¹æ®æ—¶é—´æ®µé¢„æµ‹æƒ…æ„Ÿçš„èƒ½åŠ›|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Temporal Adapters-Extracti-1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Temporal Adapters2-Extracti-1.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Addresses the temporal misalignment inherent in prompt-based in silico surveys and the scalability bottlenecks of traditional affective computing, which heavily relies on resource-intensive labeled datasets or static dictionaries. \[ç¿»è¯‘\] è§£å†³äº†åŸºäºæç¤ºè¯çš„in silicoï¼ˆè®¡ç®—æœºæ¨¡æ‹Ÿï¼‰è°ƒæŸ¥ä¸­å›ºæœ‰çš„æ—¶é—´é”™ä½é—®é¢˜ï¼Œä»¥åŠä¼ ç»Ÿæƒ…æ„Ÿè®¡ç®—ä¸¥é‡ä¾èµ–èµ„æºå¯†é›†å‹æ ‡æ³¨æ•°æ®é›†æˆ–é™æ€è¯å…¸çš„å¯æ‰©å±•æ€§ç“¶é¢ˆ **[innovation]** åˆ©ç”¨LoRAä½œä¸ºæ¨¡å—åŒ–å­¦ä¹ å…ƒä»¶çš„â€œæ—¶é—´é€‚é…å™¨â€ï¼Œä»¥æ•æ‰ç‰¹å®šæ—¶æœŸç‹¬æœ‰çš„æ—¶é—´ä¸è¯­è¨€ç‰¹å¾ã€‚é€šè¿‡å°†è¿™äº›è½»é‡çº§é€‚é…å™¨ä¸å†»ç»“åŸºåº§æ¨¡å‹çš„å›ºæœ‰æ¨ç†èƒ½åŠ›äº§ç”ŸååŒä½œç”¨ï¼Œè¯¥æ¡†æ¶å®ç°äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„çºµå‘æƒ…æ„Ÿé¢„æµ‹ã€‚ **[method]** Employs a two-stage framework: first, fine-tuning weekly LoRA adapters on longitudinal Twitter timelines via a self-supervised causal language modeling objective; second, probing the adapted models with standard psychometric questionnaires to extract aggregate affect via token probability distributions. \[ç¿»è¯‘\] é‡‡ç”¨åŒé˜¶æ®µæ¡†æ¶ï¼šé¦–å…ˆï¼Œé€šè¿‡è‡ªç›‘ç£çš„å› æœè¯­è¨€å»ºæ¨¡ç›®æ ‡åœ¨çºµå‘Twitteræ—¶é—´çº¿ä¸Šå¾®è°ƒæ¯å‘¨çš„LoRAé€‚é…å™¨ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨æ ‡å‡†å¿ƒç†æµ‹é‡é—®å·æ¢æµ‹é€‚é…åçš„æ¨¡å‹ï¼Œé€šè¿‡Tokenæ¦‚ç‡åˆ†å¸ƒæå–èšåˆæƒ…æ„Ÿ \[é€šä¿—æ ¸å¿ƒ\]åœ¨æ¯å‘¨åˆ†åˆ«è¿›è¡ŒLoRAè‡ªç›‘ç£å¾®è°ƒï¼Œè®©æ¨¡å‹çš„é¢„æµ‹å°½å¯èƒ½å’ŒåŸæ•°æ®ä¸€æ ·ã€‚ä½¿ç”¨ä¸“ä¸šé—®å·ä½œä¸ºpromptï¼Œæ¨¡æ‹Ÿæ¨¡å‹å›ç­”é—®å·ï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªæƒ…æ„Ÿæ¦‚ç‡éšæ—¶é—´çš„åˆ†å¸ƒï¼Œä¸å…¬ä¼—çœŸå®åˆ†å¸ƒå¯¹æ¯” **[conclusion/contribution]** Demonstrates strong, significant correlations with representative polling data \(YouGov\) during the COVID-19 pandemic, achieving performance comparable to supervised baselines \(e.g., TweetNLP\) while offering superior flexibility in querying diverse and complex collective attitudes. \[ç¿»è¯‘\] å±•ç¤ºäº†åœ¨COVID-19å¤§æµè¡ŒæœŸé—´ä¸ä»£è¡¨æ€§æ°‘è°ƒæ•°æ®ï¼ˆYouGovï¼‰çš„å¼ºæ˜¾è‘—ç›¸å…³æ€§ï¼Œå®ç°äº†ä¸ç›‘ç£åŸºçº¿æ¨¡å‹ï¼ˆå¦‚TweetNLPï¼‰ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶åœ¨æŸ¥è¯¢å¤šæ ·åŒ–ä¸”å¤æ‚çš„é›†ä½“æ€åº¦æ–¹é¢æä¾›äº†æ›´ä¼˜è¶Šçš„çµæ´»æ€§ã€‚ **[limitation/future]** Primarily effective for longitudinal trend analysis rather than absolute cross-sectional calibration, and the representativeness of the emergent sentiment is constrained by the demographic biases inherent in the social media training corpora. \[ç¿»è¯‘\] ä¸»è¦åœ¨çºµå‘è¶‹åŠ¿åˆ†æè€Œéç»å¯¹æ¨ªæˆªé¢æ ¡å‡†æ–¹é¢æœ‰æ•ˆï¼Œä¸”æ¶Œç°å‡ºçš„æƒ…æ„Ÿä»£è¡¨æ€§å—é™äºç¤¾äº¤åª’ä½“è®­ç»ƒè¯­æ–™åº“ä¸­å›ºæœ‰çš„äººå£ç»Ÿè®¡å­¦åå·®">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Addresses the temporal misalignment inherent in prompt-based in silico surveys and the scalability bottlenecks of traditional affective computing, which heavily relies on resource-intensive labeled datasets or static dictionaries.<br>\[ç¿»è¯‘\] è§£å†³äº†åŸºäºæç¤ºè¯çš„in silicoï¼ˆè®¡ç®—æœºæ¨¡æ‹Ÿï¼‰è°ƒæŸ¥ä¸­å›ºæœ‰çš„æ—¶é—´é”™ä½é—®é¢˜ï¼Œä»¥åŠä¼ ç»Ÿæƒ…æ„Ÿè®¡ç®—ä¸¥é‡ä¾èµ–èµ„æºå¯†é›†å‹æ ‡æ³¨æ•°æ®é›†æˆ–é™æ€è¯å…¸çš„å¯æ‰©å±•æ€§ç“¶é¢ˆ<br>**[innovation]** åˆ©ç”¨LoRAä½œä¸ºæ¨¡å—åŒ–å­¦ä¹ å…ƒä»¶çš„â€œæ—¶é—´é€‚é…å™¨â€ï¼Œä»¥æ•æ‰ç‰¹å®šæ—¶æœŸç‹¬æœ‰çš„æ—¶é—´ä¸è¯­è¨€ç‰¹å¾ã€‚é€šè¿‡å°†è¿™äº›è½»é‡çº§é€‚é…å™¨ä¸å†»ç»“åŸºåº§æ¨¡å‹çš„å›ºæœ‰æ¨ç†èƒ½åŠ›äº§ç”ŸååŒä½œç”¨ï¼Œè¯¥æ¡†æ¶å®ç°äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„çºµå‘æƒ…æ„Ÿé¢„æµ‹ã€‚<br>**[method]** Employs a two-stage framework: first, fine-tuning weekly LoRA adapters on longitudinal Twitter timelines via a self-supervised causal language modeling objective; second, probing the adapted models with standard psychometric questionnaires to extract aggregate affect via token probability distributions.<br>\[ç¿»è¯‘\] é‡‡ç”¨åŒé˜¶æ®µæ¡†æ¶ï¼šé¦–å…ˆï¼Œé€šè¿‡è‡ªç›‘ç£çš„å› æœè¯­è¨€å»ºæ¨¡ç›®æ ‡åœ¨çºµå‘Twitteræ—¶é—´çº¿ä¸Šå¾®è°ƒæ¯å‘¨çš„LoRAé€‚é…å™¨ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨æ ‡å‡†å¿ƒç†æµ‹é‡é—®å·æ¢æµ‹é€‚é…åçš„æ¨¡å‹ï¼Œé€šè¿‡Tokenæ¦‚ç‡åˆ†å¸ƒæå–èšåˆæƒ…æ„Ÿ<br>\[é€šä¿—æ ¸å¿ƒ\]åœ¨æ¯å‘¨åˆ†åˆ«è¿›è¡ŒLoRAè‡ªç›‘ç£å¾®è°ƒï¼Œè®©æ¨¡å‹çš„é¢„æµ‹å°½å¯èƒ½å’ŒåŸæ•°æ®ä¸€æ ·ã€‚ä½¿ç”¨ä¸“ä¸šé—®å·ä½œä¸ºpromptï¼Œæ¨¡æ‹Ÿæ¨¡å‹å›ç­”é—®å·ï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªæƒ…æ„Ÿæ¦‚ç‡éšæ—¶é—´çš„åˆ†å¸ƒï¼Œä¸å…¬ä¼—çœŸå®åˆ†å¸ƒå¯¹æ¯”<br>**[conclusion/contribution]** Demonstrates strong, significant correlations with representative polling data \(YouGov\) during the COVID-19 pandemic, achieving performance comparable to supervised baselines \(e.g., TweetNLP\) while offering superior flexibility in querying diverse and complex collective attitudes.<br>\[ç¿»è¯‘\] å±•ç¤ºäº†åœ¨COVID-19å¤§æµè¡ŒæœŸé—´ä¸ä»£è¡¨æ€§æ°‘è°ƒæ•°æ®ï¼ˆYouGovï¼‰çš„å¼ºæ˜¾è‘—ç›¸å…³æ€§ï¼Œå®ç°äº†ä¸ç›‘ç£åŸºçº¿æ¨¡å‹ï¼ˆå¦‚TweetNLPï¼‰ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶åœ¨æŸ¥è¯¢å¤šæ ·åŒ–ä¸”å¤æ‚çš„é›†ä½“æ€åº¦æ–¹é¢æä¾›äº†æ›´ä¼˜è¶Šçš„çµæ´»æ€§ã€‚<br>**[limitation/future]** Primarily effective for longitudinal trend analysis rather than absolute cross-sectional calibration, and the representativeness of the emergent sentiment is constrained by the demographic biases inherent in the social media training corpora.<br>\[ç¿»è¯‘\] ä¸»è¦åœ¨çºµå‘è¶‹åŠ¿åˆ†æè€Œéç»å¯¹æ¨ªæˆªé¢æ ¡å‡†æ–¹é¢æœ‰æ•ˆï¼Œä¸”æ¶Œç°å‡ºçš„æƒ…æ„Ÿä»£è¡¨æ€§å—é™äºç¤¾äº¤åª’ä½“è®­ç»ƒè¯­æ–™åº“ä¸­å›ºæœ‰çš„äººå£ç»Ÿè®¡å­¦åå·®</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">ã€é›†ä½“æƒ…æ„Ÿåˆ†æã€‘é€šè¿‡LoRAè‡ªç›‘ç£å­¦åˆ°çš„æ˜¯è¯¥ç‰¹å®šæ—¶é—´æ®µå†…å…¬ä¼—çš„è¯­è¨€é£æ ¼å’Œå…³æ³¨ç‚¹ï¼Œç»“åˆåŸºç¡€æ¨¡å‹çš„å›ºæœ‰èƒ½åŠ›è·å¾—äº†é¢„æµ‹ç‰¹å®šæ—¶é—´å†…å…¬ä¼—æƒ…æ„Ÿçš„èƒ½åŠ›ï¼Œå¾ˆç¥å¥‡ï¼Œè¿™æ˜¯ä¸€ä¸ªé€šç”¨æ–¹æ³•<br>\[å¼•ç”¨æ–‡\]Moving beyond traditional supervised classifiers, Ahnert et al. \(2025\) demonstrate a shift toward the social simulation paradigm by proposing Temporal Adapters. Instead of training models to explicitly recognize emotion patterns, they utilize self-supervised learning to train lightweight LoRA modules as learning components, aligning the frozen LLM with specific temporal and linguistic contexts derived from longitudinal social media data. This equips the model with the capability to predict public sentiment within specific timeframes. Their approach validates that scalable and accurate tracking of public opinion dynamic<br>\[ç¿»è¯‘\]<br>è¶…è¶Šäº†ä¼ ç»Ÿçš„ç›‘ç£åˆ†ç±»å™¨ï¼ŒAhnertç­‰äºº \(2025\) é€šè¿‡æå‡º â€œæ—¶é—´é€‚é…å™¨â€ å±•ç¤ºäº†å‘ç¤¾ä¼šä»¿çœŸèŒƒå¼çš„è½¬å˜ã€‚ä»–ä»¬ä¸å†è®­ç»ƒæ¨¡å‹å»æ˜¾å¼åœ°è¯†åˆ«æƒ…æ„Ÿæ¨¡å¼ï¼Œè€Œæ˜¯é€šè¿‡è‡ªç›‘ç£å­¦ä¹ è®­ç»ƒè½»é‡çº§çš„LoRAæ¨¡å—ä½œä¸ºå­¦ä¹ å…ƒä»¶ï¼Œå°†å†»ç»“çš„å¤§è¯­è¨€æ¨¡å‹ä¸æºè‡ªçºµå‘ç¤¾äº¤åª’ä½“æ•°æ®çš„ç‰¹å®šæ—¶é—´åŠè¯­è¨€è¯­å¢ƒç›¸å¯¹é½ã€‚ä½¿æ¨¡å‹è·å¾—äº†é¢„æµ‹ç‰¹å®šæ—¶é—´å†…å…¬ä¼—æƒ…æ„Ÿçš„èƒ½åŠ›ã€‚ä»–ä»¬çš„æ–¹æ³•è¯å®ï¼Œé€šè¿‡æ—¶é—´å¯¹é½è€Œéæ ‡ç­¾ç›‘ç£ï¼Œå³å¯å®ç°å¯¹æ°‘æ„åŠ¨æ€çš„å¯æ‰©å±•ä¸”å‡†ç¡®çš„è¿½è¸ªã€‚</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence-blue)]()<br>[CAMEL: Capturing metaphorical alignment with context disentangling for multimodal emotion recogni...](https://ojs.aaai.org/index.php/AAAI/article/view/28787) <br> Linhao Zhang,Li Jin\*,Guangluan Xu,Xiaoyu Li,Cai Xu,Kaiwen Wei,Nayu Liu,Haonan Liu <br> 2024-03-24|\[AI generated\] CAMEL disentangles metaphorical alignment like a prism separating light, then adaptively fuses context for emotion recognition. \[ç¿»è¯‘\]CAMELåƒæ£±é•œåˆ†ç¦»å…‰çº¿èˆ¬è§£è€¦éšå–»å¯¹é½ï¼Œå†è‡ªé€‚åº”èåˆä¸Šä¸‹æ–‡è¿›è¡Œæƒ…æ„Ÿè¯†åˆ«ã€‚|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/CAMEL1-CAMELC-1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/CAMEL-CAMELC-1.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** ä¸ºäº†è§£å†³å¤šæ¨¡æ€å†…å®¹ä¸­å› éšå–»å¯¹é½å¯¼è‡´**æƒ…æ„Ÿè¯¯åˆ¤**çš„é—®é¢˜ï¼šä¹‹å‰çš„æ–¹æ³•æœ¬è´¨ä¸Šæ— æ³•ç†è§£éšå–»,ä¸“æ³¨äºç›´æ¥çš„è¯­ä¹‰å¯¹é½ï¼Œæ— æ³•æ•æ‰å¦‚æ–‡å­—â€œçœ¼æ³ªâ€ä¸å›¾ç‰‡â€œæ²³æµâ€çš„è¿™ç§éšå¼è”ç³» **[innovation]** å°†å¤šæ¨¡æ€é—´éšå«è”ç³»çš„å¯¹é½æ€æƒ³åº”ç”¨äºå¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«é¢†åŸŸ **[method]** ä½¿ç”¨äº†åŸºäºæ¡ä»¶ç”Ÿæˆä¸è§£è€¦ä¸Šä¸‹æ–‡é€‚åº”çš„CAMELæ¡†æ¶:éšå–»å¯¹é½å»ºæ¨¡ï¼ˆæ¡ä»¶ç”Ÿæˆï¼‰\(å¼ºåˆ¶æ¨¡å‹æŒ‰ç…§æ¨¡ç‰ˆè¾“å‡ºï¼ˆCMTå’ŒSPVä¸¤ç§æŠ€æœ¯ï¼‰ï¼›ä½¿ç”¨å›¾ç‰‡ã€æ ‡é¢˜ã€æ–‡æœ¬çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œä½¿ç”¨ä¸€ä¸ª\[CLS\] tokenèšåˆå…¨å±€ä¿¡æ¯ï¼‰-&gt;ä¸Šä¸‹æ–‡è¯­ä¹‰é€‚åº”ï¼ˆç‰¹å¾èåˆï¼‰ï¼ˆä½¿ç”¨ä¸¤ä¸ªå¼‚æ„æ¨¡å‹ï¼Œåˆ†åˆ«è¾“å…¥å­—é¢ç‰¹å¾ï¼ˆCAMEL-Cï¼ŒCMTï¼‰å’Œéšå–»ç‰¹å¾ï¼ˆCAMEL-Sï¼ŒSPVï¼‰ç”Ÿæˆä¸¤ä¸ªå‘é‡çŸ©é˜µï¼Œé€šè¿‡éšå–»æŸ¥å­—é¢å®ç°å¤šå¤´æ³¨æ„åŠ›ï¼‰-&gt;è§£è€¦å¯¹æ¯”åŒ¹é…ï¼ˆä¸Šä¸‹æ–‡æ­£åˆ™åŒ–ï¼‰ï¼ˆç¡®ä¿ä¸åç¦»è¯­å¢ƒã€‚é‡‡ç”¨è§£è€¦å­¦ä¹ æ€æƒ³ï¼Œéšå–»ç‰¹å¾ä¸­åˆ†ç¦»å‡ºä»£è¡¨â€œä¸»å¯¼ä¸Šä¸‹æ–‡ç±»åˆ«â€çš„ç¦»æ•£åˆ†å¸ƒï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œä½¿å­—é¢ç‰¹å¾æ¨å‡ºçš„åˆ†å¸ƒä¸ä¹‹å¯¹é½ï¼‰ **[conclusion/contribution]** è¾¾æˆäº†å¯¹éšå«æƒ…æ„Ÿæ›´ç²¾å‡†ã€é²æ£’çš„è¯†åˆ«æ•ˆæœ **[limitation/future]** æ•´ä¸ªæ–¹æ³•æ¡†æ¶å¤æ‚ï¼Œæ¨¡å‹æ‰€éœ€çš„æ‰€æœ‰èƒ½åŠ›ï¼šæ‰¾å­—é¢ç‰¹å¾ã€æ‰¾éšå–»ç‰¹å¾ã€ä¸¤è€…å¯¹é½ã€æ ¹æ®èåˆç‰¹å¾ç”Ÿæˆæƒ…æ„Ÿåˆ†æï¼Œéƒ½æ˜¯ä¸€æ¬¡è®­ç»ƒå®Œæˆçš„ï¼Œæ˜¯å¦éš¾ä»¥æ”¶æ•›ï¼ˆè™½ç„¶è®ºæ–‡ä½¿ç”¨äº†è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼‰ï¼Œæ˜¯å¦èƒ½å¤Ÿåœ¨è®­ç»ƒå±‚é¢è¿›è¡Œä¸€å®šçš„è§£è€¦ï¼Ÿåˆ†åˆ«è®­ç»ƒå„èƒ½åŠ›">**[summary]**</summary><div style="margin-top:6px">**[motivation]** ä¸ºäº†è§£å†³å¤šæ¨¡æ€å†…å®¹ä¸­å› éšå–»å¯¹é½å¯¼è‡´**æƒ…æ„Ÿè¯¯åˆ¤**çš„é—®é¢˜ï¼šä¹‹å‰çš„æ–¹æ³•æœ¬è´¨ä¸Šæ— æ³•ç†è§£éšå–»,ä¸“æ³¨äºç›´æ¥çš„è¯­ä¹‰å¯¹é½ï¼Œæ— æ³•æ•æ‰å¦‚æ–‡å­—â€œçœ¼æ³ªâ€ä¸å›¾ç‰‡â€œæ²³æµâ€çš„è¿™ç§éšå¼è”ç³»<br>**[innovation]** å°†å¤šæ¨¡æ€é—´éšå«è”ç³»çš„å¯¹é½æ€æƒ³åº”ç”¨äºå¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«é¢†åŸŸ<br>**[method]** ä½¿ç”¨äº†åŸºäºæ¡ä»¶ç”Ÿæˆä¸è§£è€¦ä¸Šä¸‹æ–‡é€‚åº”çš„CAMELæ¡†æ¶:éšå–»å¯¹é½å»ºæ¨¡ï¼ˆæ¡ä»¶ç”Ÿæˆï¼‰\(å¼ºåˆ¶æ¨¡å‹æŒ‰ç…§æ¨¡ç‰ˆè¾“å‡ºï¼ˆCMTå’ŒSPVä¸¤ç§æŠ€æœ¯ï¼‰ï¼›ä½¿ç”¨å›¾ç‰‡ã€æ ‡é¢˜ã€æ–‡æœ¬çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œä½¿ç”¨ä¸€ä¸ª\[CLS\] tokenèšåˆå…¨å±€ä¿¡æ¯ï¼‰->ä¸Šä¸‹æ–‡è¯­ä¹‰é€‚åº”ï¼ˆç‰¹å¾èåˆï¼‰ï¼ˆä½¿ç”¨ä¸¤ä¸ªå¼‚æ„æ¨¡å‹ï¼Œåˆ†åˆ«è¾“å…¥å­—é¢ç‰¹å¾ï¼ˆCAMEL-Cï¼ŒCMTï¼‰å’Œéšå–»ç‰¹å¾ï¼ˆCAMEL-Sï¼ŒSPVï¼‰ç”Ÿæˆä¸¤ä¸ªå‘é‡çŸ©é˜µï¼Œé€šè¿‡éšå–»æŸ¥å­—é¢å®ç°å¤šå¤´æ³¨æ„åŠ›ï¼‰->è§£è€¦å¯¹æ¯”åŒ¹é…ï¼ˆä¸Šä¸‹æ–‡æ­£åˆ™åŒ–ï¼‰ï¼ˆç¡®ä¿ä¸åç¦»è¯­å¢ƒã€‚é‡‡ç”¨è§£è€¦å­¦ä¹ æ€æƒ³ï¼Œéšå–»ç‰¹å¾ä¸­åˆ†ç¦»å‡ºä»£è¡¨â€œä¸»å¯¼ä¸Šä¸‹æ–‡ç±»åˆ«â€çš„ç¦»æ•£åˆ†å¸ƒï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œä½¿å­—é¢ç‰¹å¾æ¨å‡ºçš„åˆ†å¸ƒä¸ä¹‹å¯¹é½ï¼‰<br>**[conclusion/contribution]** è¾¾æˆäº†å¯¹éšå«æƒ…æ„Ÿæ›´ç²¾å‡†ã€é²æ£’çš„è¯†åˆ«æ•ˆæœ<br>**[limitation/future]** æ•´ä¸ªæ–¹æ³•æ¡†æ¶å¤æ‚ï¼Œæ¨¡å‹æ‰€éœ€çš„æ‰€æœ‰èƒ½åŠ›ï¼šæ‰¾å­—é¢ç‰¹å¾ã€æ‰¾éšå–»ç‰¹å¾ã€ä¸¤è€…å¯¹é½ã€æ ¹æ®èåˆç‰¹å¾ç”Ÿæˆæƒ…æ„Ÿåˆ†æï¼Œéƒ½æ˜¯ä¸€æ¬¡è®­ç»ƒå®Œæˆçš„ï¼Œæ˜¯å¦éš¾ä»¥æ”¶æ•›ï¼ˆè™½ç„¶è®ºæ–‡ä½¿ç”¨äº†è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼‰ï¼Œæ˜¯å¦èƒ½å¤Ÿåœ¨è®­ç»ƒå±‚é¢è¿›è¡Œä¸€å®šçš„è§£è€¦ï¼Ÿåˆ†åˆ«è®­ç»ƒå„èƒ½åŠ›</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">é¦–å…ˆé€šè¿‡å¤šå¤´è·¨åŸŸæ³¨æ„åŠ›æœºåˆ¶å®ç°åˆæ­¥çš„å¯¹é½ï¼Œç„¶åè®©å­—é¢ç‰¹å¾çš„åˆ†å¸ƒä¸éšå–»ç‰¹å¾çš„åˆ†å¸ƒå¯¹é½ï¼Œè¿›ä¸€æ­¥å¼ºåŒ–å¯¹é½ï¼›</div></details></div></div>|

### | Understanding (3 papers)


### Event Extraction (3 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[Towards Effective, Efficient and Unsupervised Social Event Detection in the Hyperbolic Space](https://ojs.aaai.org/index.php/AAAI/article/view/33430) <br> Xiaoyan Yu,Yifan Wei,Shuaishuai Zhou,Zhiwei Yang,Li Sun,Hao Peng,Liehuang Zhu\*,Philip S. Yu <br> 2025-04-11|é€šè¿‡ä¸¤å±‚å‹ç¼©å‡å°‘å¼€é”€ï¼ˆç®€åŒ–è¾¹ã€èŠ‚ç‚¹èšåˆä¸ºé”šç‚¹ï¼‰ï¼Œé€šè¿‡åˆ’åˆ†æ ‘è¡¨ç¤ºäº‹ä»¶èšç±»|<img width="1200" alt="pipeline" src="figures/HyperSED-Towards-1.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Social event detection on social media platforms faces significant challenges due to the large scale, dynamic nature, and complex relational structures inherent in user-generated content. Existing methods often suffer from inefficiency in processing massive message streams and limited expressive power in capturing hierarchical event structures. \[ç¿»è¯‘\]ï¼šç”±äºç”¨æˆ·ç”Ÿæˆå†…å®¹è§„æ¨¡åºå¤§ã€åŠ¨æ€æ€§å¼ºä¸”å…³ç³»ç»“æ„å¤æ‚ï¼Œç¤¾äº¤åª’ä½“å¹³å°ä¸Šçš„ç¤¾äº¤äº‹ä»¶æ£€æµ‹é¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æµ·é‡æ¶ˆæ¯æµæ—¶å¸¸æ•ˆç‡ä½ä¸‹ï¼Œä¸”åœ¨æ•æ‰å±‚æ¬¡åŒ–äº‹ä»¶ç»“æ„æ–¹é¢è¡¨è¾¾èƒ½åŠ›æœ‰é™ã€‚ **[innovation]** The paper introduces HyperSED, a novel unsupervised framework that reduces computational overhead through a two-stage compression mechanismâ€”semantic-based anchor construction and graph sparsificationâ€”and represents event clusters via a differentiable partitioning tree learned in hyperbolic space. This approach effectively captures hierarchical and nested event structures without requiring predefined cluster counts. \[ç¿»è¯‘\]ï¼šæœ¬æ–‡æå‡ºHyperSEDï¼Œä¸€ç§æ–°é¢–çš„æ— ç›‘ç£æ¡†æ¶ï¼Œé€šè¿‡åŸºäºè¯­ä¹‰çš„é”šç‚¹æ„å»ºä¸å›¾ç¨€ç–åŒ–ä¸¤é˜¶æ®µå‹ç¼©æœºåˆ¶é™ä½è®¡ç®—å¼€é”€ï¼Œå¹¶åˆ©ç”¨åœ¨åŒæ›²ç©ºé—´ä¸­å­¦ä¹ çš„å¯å¾®åˆ’åˆ†æ ‘è¡¨ç¤ºäº‹ä»¶èšç±»ã€‚è¯¥æ–¹æ³•æ— éœ€é¢„è®¾èšç±»æ•°é‡ï¼Œå³å¯æœ‰æ•ˆæ•æ‰å±‚æ¬¡åŒ–ä¸åµŒå¥—çš„äº‹ä»¶ç»“æ„ã€‚ **[method]** The framework first constructs a semantic anchor graph to compress message nodes and simplify relational edges. It then maps the anchor graph into hyperbolic space and employs a hyperbolic graph autoencoder to learn structure-aware representations. Finally, a partitioning tree is built and optimized via differentiable structural information minimization, yielding hierarchical event clusters. \[ç¿»è¯‘\]ï¼šè¯¥æ¡†æ¶é¦–å…ˆæ„å»ºè¯­ä¹‰é”šç‚¹å›¾ä»¥å‹ç¼©æ¶ˆæ¯èŠ‚ç‚¹å¹¶ç®€åŒ–å…³ç³»è¾¹ï¼Œéšåå°†é”šç‚¹å›¾æ˜ å°„è‡³åŒæ›²ç©ºé—´ï¼Œé‡‡ç”¨åŒæ›²å›¾è‡ªç¼–ç å™¨å­¦ä¹ ç»“æ„æ„ŸçŸ¥è¡¨ç¤ºï¼Œæœ€ç»ˆé€šè¿‡å¯å¾®ç»“æ„ä¿¡æ¯æœ€å°åŒ–æ„å»ºå¹¶ä¼˜åŒ–åˆ’åˆ†æ ‘ï¼Œå¾—åˆ°å±‚æ¬¡åŒ–äº‹ä»¶ç°‡ **[conclusion/contribution]** Experiments on real-world Twitter datasets demonstrate that HyperSED achieves competitive performance in normalized mutual information, adjusted mutual information, and adjusted Rand index, while improving computational efficiency by up to 37 times compared to state-of-the-art unsupervised baselines. \[ç¿»è¯‘\]ï¼šåœ¨çœŸå®Twitteræ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHyperSEDåœ¨å½’ä¸€åŒ–äº’ä¿¡æ¯ã€è°ƒæ•´äº’ä¿¡æ¯ä¸è°ƒæ•´å…°å¾·æŒ‡æ•°ä¸Šå‡å–å¾—å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶ç›¸æ¯”å‰æ²¿æ— ç›‘ç£åŸºçº¿ï¼Œè®¡ç®—æ•ˆç‡æå‡æœ€é«˜è¾¾37å€ã€‚ **[limitation/future]** The performance may marginally decline in some message blocks due to potential errors in anchor construction, where semantically distinct messages are incorrectly grouped. Additionally, the efficiency gains come with a slight trade-off in clustering granularity control. \[ç¿»è¯‘\]ï¼šç”±äºé”šç‚¹æ„å»ºä¸­å¯èƒ½å‡ºç°è¯­ä¹‰ä¸åŒæ¶ˆæ¯è¢«é”™è¯¯åˆ†ç»„çš„æƒ…å†µï¼Œè¯¥æ¨¡å‹åœ¨éƒ¨åˆ†æ¶ˆæ¯å—ä¸Šçš„æ€§èƒ½å¯èƒ½ç•¥æœ‰ä¸‹é™ã€‚æ­¤å¤–ï¼Œæ•ˆç‡æå‡åœ¨ä¸€å®šç¨‹åº¦ä¸Šä»¥èšç±»ç²’åº¦æ§åˆ¶çš„ç²¾ç»†åº¦ä¸ºä»£ä»·ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Social event detection on social media platforms faces significant challenges due to the large scale, dynamic nature, and complex relational structures inherent in user-generated content. Existing methods often suffer from inefficiency in processing massive message streams and limited expressive power in capturing hierarchical event structures.<br>\[ç¿»è¯‘\]ï¼šç”±äºç”¨æˆ·ç”Ÿæˆå†…å®¹è§„æ¨¡åºå¤§ã€åŠ¨æ€æ€§å¼ºä¸”å…³ç³»ç»“æ„å¤æ‚ï¼Œç¤¾äº¤åª’ä½“å¹³å°ä¸Šçš„ç¤¾äº¤äº‹ä»¶æ£€æµ‹é¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æµ·é‡æ¶ˆæ¯æµæ—¶å¸¸æ•ˆç‡ä½ä¸‹ï¼Œä¸”åœ¨æ•æ‰å±‚æ¬¡åŒ–äº‹ä»¶ç»“æ„æ–¹é¢è¡¨è¾¾èƒ½åŠ›æœ‰é™ã€‚<br>**[innovation]** The paper introduces HyperSED, a novel unsupervised framework that reduces computational overhead through a two-stage compression mechanismâ€”semantic-based anchor construction and graph sparsificationâ€”and represents event clusters via a differentiable partitioning tree learned in hyperbolic space. This approach effectively captures hierarchical and nested event structures without requiring predefined cluster counts.<br>\[ç¿»è¯‘\]ï¼šæœ¬æ–‡æå‡ºHyperSEDï¼Œä¸€ç§æ–°é¢–çš„æ— ç›‘ç£æ¡†æ¶ï¼Œé€šè¿‡åŸºäºè¯­ä¹‰çš„é”šç‚¹æ„å»ºä¸å›¾ç¨€ç–åŒ–ä¸¤é˜¶æ®µå‹ç¼©æœºåˆ¶é™ä½è®¡ç®—å¼€é”€ï¼Œå¹¶åˆ©ç”¨åœ¨åŒæ›²ç©ºé—´ä¸­å­¦ä¹ çš„å¯å¾®åˆ’åˆ†æ ‘è¡¨ç¤ºäº‹ä»¶èšç±»ã€‚è¯¥æ–¹æ³•æ— éœ€é¢„è®¾èšç±»æ•°é‡ï¼Œå³å¯æœ‰æ•ˆæ•æ‰å±‚æ¬¡åŒ–ä¸åµŒå¥—çš„äº‹ä»¶ç»“æ„ã€‚<br>**[method]** The framework first constructs a semantic anchor graph to compress message nodes and simplify relational edges. It then maps the anchor graph into hyperbolic space and employs a hyperbolic graph autoencoder to learn structure-aware representations. Finally, a partitioning tree is built and optimized via differentiable structural information minimization, yielding hierarchical event clusters.<br>\[ç¿»è¯‘\]ï¼šè¯¥æ¡†æ¶é¦–å…ˆæ„å»ºè¯­ä¹‰é”šç‚¹å›¾ä»¥å‹ç¼©æ¶ˆæ¯èŠ‚ç‚¹å¹¶ç®€åŒ–å…³ç³»è¾¹ï¼Œéšåå°†é”šç‚¹å›¾æ˜ å°„è‡³åŒæ›²ç©ºé—´ï¼Œé‡‡ç”¨åŒæ›²å›¾è‡ªç¼–ç å™¨å­¦ä¹ ç»“æ„æ„ŸçŸ¥è¡¨ç¤ºï¼Œæœ€ç»ˆé€šè¿‡å¯å¾®ç»“æ„ä¿¡æ¯æœ€å°åŒ–æ„å»ºå¹¶ä¼˜åŒ–åˆ’åˆ†æ ‘ï¼Œå¾—åˆ°å±‚æ¬¡åŒ–äº‹ä»¶ç°‡<br>**[conclusion/contribution]** Experiments on real-world Twitter datasets demonstrate that HyperSED achieves competitive performance in normalized mutual information, adjusted mutual information, and adjusted Rand index, while improving computational efficiency by up to 37 times compared to state-of-the-art unsupervised baselines.<br>\[ç¿»è¯‘\]ï¼šåœ¨çœŸå®Twitteræ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHyperSEDåœ¨å½’ä¸€åŒ–äº’ä¿¡æ¯ã€è°ƒæ•´äº’ä¿¡æ¯ä¸è°ƒæ•´å…°å¾·æŒ‡æ•°ä¸Šå‡å–å¾—å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶ç›¸æ¯”å‰æ²¿æ— ç›‘ç£åŸºçº¿ï¼Œè®¡ç®—æ•ˆç‡æå‡æœ€é«˜è¾¾37å€ã€‚<br>**[limitation/future]** The performance may marginally decline in some message blocks due to potential errors in anchor construction, where semantically distinct messages are incorrectly grouped. Additionally, the efficiency gains come with a slight trade-off in clustering granularity control.<br>\[ç¿»è¯‘\]ï¼šç”±äºé”šç‚¹æ„å»ºä¸­å¯èƒ½å‡ºç°è¯­ä¹‰ä¸åŒæ¶ˆæ¯è¢«é”™è¯¯åˆ†ç»„çš„æƒ…å†µï¼Œè¯¥æ¨¡å‹åœ¨éƒ¨åˆ†æ¶ˆæ¯å—ä¸Šçš„æ€§èƒ½å¯èƒ½ç•¥æœ‰ä¸‹é™ã€‚æ­¤å¤–ï¼Œæ•ˆç‡æå‡åœ¨ä¸€å®šç¨‹åº¦ä¸Šä»¥èšç±»ç²’åº¦æ§åˆ¶çš„ç²¾ç»†åº¦ä¸ºä»£ä»·ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[notes\]ä¸ºä»€ä¹ˆç”¨åŒæ›²ç©ºé—´ï¼Ÿ ç°å®ä¸–ç•Œçš„äº‹ä»¶å’Œè¯é¢˜å¾€å¾€å…·æœ‰å±‚æ¬¡ç»“æ„ï¼ˆå¦‚â€œä½“è‚² -> è¶³çƒ -> ä¸–ç•Œæ¯â€ï¼‰ã€‚åŒæ›²ç©ºé—´çš„å‡ ä½•ç‰¹æ€§ï¼ˆæŒ‡æ•°çº§å¢é•¿çš„ç©ºé—´ï¼‰èƒ½æ›´è‡ªç„¶ã€æ›´ç´§å‡‘åœ°åµŒå…¥è¿™ç§æ ‘çŠ¶æˆ–å±‚æ¬¡åŒ–æ•°æ®ã€‚<br>\[é€šä¿—æ ¸å¿ƒ\]é€šè¿‡æ¶ˆæ¯å„å±æ€§çš„ç›¸åŒæ€§ï¼ˆç”¨æˆ·ã€æ ‡ç­¾ï¼‰æ„å»ºç½‘ç»œï¼›é€šè¿‡æ–¹æ³•ç²¾ç®€ç½‘ç»œè¾¹ã€å‹ç¼©1ã€‘ï¼›æ ¹æ®ç›¸å…³æ€§å°†ç›¸ä¼¼ä¿¡æ¯èšç±»ä¸ºé”šç‚¹ï¼Œé”šç‚¹ä¹‹é—´æœ‰èŠ‚ç‚¹ç›¸è¿çš„æ„å»ºè¾¹ï¼Œå¾—åˆ°é”šç‚¹å›¾ã€å‹ç¼©2ã€‘ï¼›æ˜ å°„åˆ°åŒæ›²ç©ºé—´è¿›è¡Œè‡ªç›‘ç£é‡å»ºè®­ç»ƒï¼ˆå›¾è‡ªç¼–ç å™¨GAEï¼‰è·å¾—èšåˆæ¨¡å‹ï¼›æ¨¡å‹è¾“å‡ºæ ¹æ®ç‰¹å¾å‘é‡è·ç¦»è‡ªåº•å‘ä¸Šèšåˆå½¢æˆåˆ’åˆ†æ ‘ï¼Œè¯¥æ ‘å³è¡¨ç¤ºæ¶ˆæ¯å„å±‚çº§èšç±»å…³ç³»ã€‚æ¯ä¸ªèšç±»èŠ‚ç‚¹éƒ½ä»£è¡¨äº†ä¸€ä¸ªæŸå±‚çº§äº‹ä»¶ï¼ˆå¦‚ä½“è‚²ã€ä¸–ç•Œæ¯ã€æ–°å† ï¼‰\[å¼•ç”¨æ–‡\]HyperSED demonstrates how structural and geometric inductive biases can be integrated into scalable unsupervised learning \(Yu et al., 2025\). By compressing the message graph into semantic anchors and learning a partitioning tree in hyperbolic spaceâ€”where internal nodes formed through bottomâ€‘up aggregation represent concrete event categoriesâ€”the framework not only enhances detection efficiency but also captures the multiâ€‘scale organization of social events.<br><br>\[ç¿»è¯‘\]HyperSEDå±•ç¤ºäº†å¦‚ä½•å°†ç»“æ„ä¸å‡ ä½•å½’çº³åç½®èå…¥å¯æ‰©å±•çš„æ— ç›‘ç£å­¦ä¹ ï¼ˆYu et al., 2025ï¼‰ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†æ¶ˆæ¯å›¾å‹ç¼©ä¸ºè¯­ä¹‰é”šç‚¹ï¼Œå¹¶åœ¨åŒæ›²ç©ºé—´ä¸­å­¦ä¹ åˆ’åˆ†æ ‘â€”â€”å…¶ä¸­é€šè¿‡è‡ªåº•å‘ä¸Šèšåˆå½¢æˆçš„å†…éƒ¨èŠ‚ç‚¹ä»£è¡¨å…·ä½“çš„äº‹ä»¶ç±»åˆ«â€”â€”ä¸ä»…æå‡äº†æ£€æµ‹æ•ˆç‡ï¼Œè¿˜æ•æ‰äº†ç¤¾äº¤äº‹ä»¶çš„å¤šå°ºåº¦ç»„ç»‡ç‰¹å¾ã€‚</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-Neural%20Information%20Processing-blue)]()<br>[A Three-Stage Framework for Event-Event Relation Extraction with Large Language Model](https://link.springer.com/10.1007/978-981-99-8181-6_33) <br> Feng Huang,Qiang Huang,YueTong Zhao,ZhiXiao Qi,BingKun Wang,YongFeng Huang,SongBin Li <br> 2024|é€šè¿‡ç»“æ„åŒ–promptæ„å»ºçš„ï¼Œæ— è®­ç»ƒé›¶æ ·æœ¬çš„ï¼Œä¾èµ–äºæœ¬åœ°çŸ¥è¯†åº“çš„ï¼Œäº‹ä»¶æŠ½å–æ–¹æ³•|<img width="1200" alt="pipeline" src="figures/ThreeEERE-AThree-1.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Traditional event relation extraction methods rely heavily on annotated data, which is costly and difficult to scale. The zero-shot capability of large language models remains underexplored for temporal and causal relation tasks. \[ç¿»è¯‘\] ä¼ ç»Ÿäº‹ä»¶å…³ç³»æå–æ–¹æ³•ä¸¥é‡ä¾èµ–æ ‡æ³¨æ•°æ®ï¼Œæˆæœ¬é«˜ä¸”éš¾ä»¥æ‰©å±•ã€‚å¤§è¯­è¨€æ¨¡å‹åœ¨æ—¶åºä¸å› æœå…³ç³»ä»»åŠ¡ä¸­çš„é›¶æ ·æœ¬èƒ½åŠ›å°šæœªå……åˆ†æŒ–æ˜ã€‚ **[innovation]** A three-stage framework \(ThreeEERE\) is proposed, integrating an improved Auto-CoT prompting strategy with local knowledge retrieval to enable zero-shot event-event relation extraction without task-specific training. \[ç¿»è¯‘\] æå‡ºä¸‰é˜¶æ®µæ¡†æ¶ThreeEEREï¼Œèåˆæ”¹è¿›çš„Auto-CoTæç¤ºç­–ç•¥ä¸æœ¬åœ°çŸ¥è¯†æ£€ç´¢ï¼Œå®ç°æ— éœ€ä»»åŠ¡ç‰¹å®šè®­ç»ƒçš„é›¶æ ·æœ¬äº‹ä»¶-å…³ç³»æå–ã€‚ **[method]** æ„å»ºç¤ºèŒƒæ ·ä¾‹ï¼ˆåŒ…å«cotéƒ¨åˆ†ï¼‰-&gt;æ£€ç´¢æœ¬åœ°çŸ¥è¯†-&gt;å–é«˜äºé˜ˆå€¼çš„ç­”æ¡ˆ **[conclusion/contribution]** ThreeEERE outperforms standard prompting methods and matches or surpasses several supervised baselines in event, temporal, and causal relation extraction across multiple datasets. \[ç¿»è¯‘\] åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„äº‹ä»¶ã€æ—¶åºä¸å› æœå…³ç³»æå–ä»»åŠ¡ä¸­ï¼ŒThreeEEREä¼˜äºæ ‡å‡†æç¤ºæ–¹æ³•ï¼Œå¹¶è¾¾åˆ°æˆ–è¶…è¶Šè‹¥å¹²ç›‘ç£åŸºçº¿ã€‚ **[limitation/future]** Potential inconsistency between generated reasoning chains and gold answers in demonstrations may introduce noise and affect model stability.And it relies on the construction of a local knowledge base. \[ç¿»è¯‘\] ç¤ºèŒƒä¸­ç”Ÿæˆçš„æ¨ç†é“¾ä¸æ ‡å‡†ç­”æ¡ˆä¹‹é—´å¯èƒ½å­˜åœ¨ä¸ä¸€è‡´ï¼Œå¯èƒ½å¼•å…¥å™ªå£°å¹¶å½±å“æ¨¡å‹ç¨³å®šæ€§ã€‚ä¸”ä¾èµ–äºæœ¬åœ°çŸ¥è¯†åº“æ„å»º">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Traditional event relation extraction methods rely heavily on annotated data, which is costly and difficult to scale. The zero-shot capability of large language models remains underexplored for temporal and causal relation tasks.<br>\[ç¿»è¯‘\]<br>ä¼ ç»Ÿäº‹ä»¶å…³ç³»æå–æ–¹æ³•ä¸¥é‡ä¾èµ–æ ‡æ³¨æ•°æ®ï¼Œæˆæœ¬é«˜ä¸”éš¾ä»¥æ‰©å±•ã€‚å¤§è¯­è¨€æ¨¡å‹åœ¨æ—¶åºä¸å› æœå…³ç³»ä»»åŠ¡ä¸­çš„é›¶æ ·æœ¬èƒ½åŠ›å°šæœªå……åˆ†æŒ–æ˜ã€‚<br>**[innovation]** A three-stage framework \(ThreeEERE\) is proposed, integrating an improved Auto-CoT prompting strategy with local knowledge retrieval to enable zero-shot event-event relation extraction without task-specific training.<br>\[ç¿»è¯‘\]<br>æå‡ºä¸‰é˜¶æ®µæ¡†æ¶ThreeEEREï¼Œèåˆæ”¹è¿›çš„Auto-CoTæç¤ºç­–ç•¥ä¸æœ¬åœ°çŸ¥è¯†æ£€ç´¢ï¼Œå®ç°æ— éœ€ä»»åŠ¡ç‰¹å®šè®­ç»ƒçš„é›¶æ ·æœ¬äº‹ä»¶-å…³ç³»æå–ã€‚<br>**[method]** æ„å»ºç¤ºèŒƒæ ·ä¾‹ï¼ˆåŒ…å«cotéƒ¨åˆ†ï¼‰->æ£€ç´¢æœ¬åœ°çŸ¥è¯†->å–é«˜äºé˜ˆå€¼çš„ç­”æ¡ˆ<br>**[conclusion/contribution]** ThreeEERE outperforms standard prompting methods and matches or surpasses several supervised baselines in event, temporal, and causal relation extraction across multiple datasets.<br>\[ç¿»è¯‘\]<br>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„äº‹ä»¶ã€æ—¶åºä¸å› æœå…³ç³»æå–ä»»åŠ¡ä¸­ï¼ŒThreeEEREä¼˜äºæ ‡å‡†æç¤ºæ–¹æ³•ï¼Œå¹¶è¾¾åˆ°æˆ–è¶…è¶Šè‹¥å¹²ç›‘ç£åŸºçº¿ã€‚<br>**[limitation/future]** Potential inconsistency between generated reasoning chains and gold answers in demonstrations may introduce noise and affect model stability.And it relies on the construction of a local knowledge base.<br>\[ç¿»è¯‘\]<br>ç¤ºèŒƒä¸­ç”Ÿæˆçš„æ¨ç†é“¾ä¸æ ‡å‡†ç­”æ¡ˆä¹‹é—´å¯èƒ½å­˜åœ¨ä¸ä¸€è‡´ï¼Œå¯èƒ½å¼•å…¥å™ªå£°å¹¶å½±å“æ¨¡å‹ç¨³å®šæ€§ã€‚ä¸”ä¾èµ–äºæœ¬åœ°çŸ¥è¯†åº“æ„å»º</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[notes\]èšç±»åªæ˜¯ä¸ºäº†é€‰æ‹©æœ€æ¥è¿‘èšç±»ä¸­å¿ƒçš„æµ‹è¯•æ ·æœ¬ï¼Œä½œä¸ºç¤ºèŒƒæ ·ä¾‹ï¼ˆå› ä¸ºæ¥è¿‘ä¸­å¿ƒæ„å‘³ç€æ›´èƒ½ä»£è¡¨è¯¥èšç±»è¯­ä¹‰ç‰¹å¾ï¼‰ï¼Œä¹‹åçš„æ“ä½œå°±æ˜¯è¾“å…¥æµ‹è¯•æ ·ä¾‹å’Œè¿™äº›ç¤ºèŒƒæ ·ä¾‹ï¼ˆç­”æ¡ˆéƒ¨åˆ†æ›¿æ¢ä¸ºæ ‡å‡†ç­”æ¡ˆï¼‰ä»¥åŠæ£€ç´¢å¾—åˆ°çš„æœ¬åœ°çŸ¥è¯†ï¼Œæœ€ç»ˆå–è¶…è¿‡é˜ˆå€¼çš„ç»“æœ<br>\[å¼•ç”¨æ–‡\]The three-stage framework proposed by Huang et al. \(2024\) integrates chain-of-thought reasoning with localized knowledge, demonstrating the feasibility of eliciting zero-shot inference of complex event relations from large language models through meticulously designed prompts, without the need for supervised fine-tuning.<br>\[ç¿»è¯‘\]<br>Huangç­‰äººï¼ˆ2024ï¼‰æå‡ºçš„ä¸‰é˜¶æ®µæ¡†æ¶ï¼Œå°†æ€ç»´é“¾æ¨ç†ä¸æœ¬åœ°åŒ–çŸ¥è¯†ç›¸ç»“åˆï¼Œè¯æ˜äº†é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯ï¼Œæ— éœ€ç›‘ç£å¾®è°ƒå³å¯ä»å¤§è¯­è¨€æ¨¡å‹ä¸­æ¿€å‘å‡ºå¯¹å¤æ‚äº‹ä»¶å…³ç³»çš„é›¶æ ·æœ¬æ¨æ–­èƒ½åŠ›ã€‚</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%202023%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing-blue)]()<br>[Event causality extraction via implicit cause-effect interactions](https://aclanthology.org/2023.emnlp-main.420) <br> Jintao Liu,Zequn Zhang,Kaiwen Wei,Zhi Guo,Xian Sun,Li Jin,Xiaoyu Li <br> 2023|é€šè¿‡OTå¼ºåˆ¶å­¦ç”Ÿæ¨¡å‹ä¸æ•™å¸ˆæ¨¡å‹å¯¹é½|<img width="1200" alt="pipeline" src="figures/ICE-Eventca-1.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** ç°æœ‰ECEï¼ˆäº‹ä»¶å› æœå…³ç³»æŠ½å–ï¼‰æ–¹å¼æ²¡æœ‰å……åˆ†åˆ©ç”¨åŸå› äº‹ä»¶å’Œç»“æœäº‹ä»¶ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚è¿™æœ¬å¯ä»¥ä¸ºå› æœå…³ç³»æ¨ç†æä¾›å…³é”®çº¿ç´¢ **[innovation]** è®ºæ–‡è§£è€¦ECEçš„ä¸¤ä¸ªä»»åŠ¡ï¼ˆè®ºå…ƒæŠ½å–ã€ç»“æœäº‹ä»¶é¢„æµ‹ï¼‰ï¼Œå¹¶ä½¿ç”¨OTè¿›è¡Œæ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹çš„ç»†ç²’åº¦å¯¹é½ï¼Œå¢å¼ºäº†å› æœäº‹ä»¶ä¹‹é—´çš„éšå¼è”ç³» **[method]** åŸºäºæ¨¡æ¿çš„æ¡ä»¶ç”Ÿæˆï¼ˆè¾“å…¥åŸºäºæ¨¡æ¿é™„æœ‰ç‰¹å®šç‰¹æƒä¿¡æ¯çš„promptï¼Œä½¿é¢„è®­ç»ƒæ¨¡å‹BARTï¼ˆåŸºäºtransformerï¼‰è¾“å‡ºåŸºäºæ¨¡æ¿çš„ç»“æ„åŒ–çš„æ–‡æœ¬ï¼Œç”¨äºåç»­å¾®è°ƒï¼‰-&gt;æ•™å¸ˆ-å­¦ç”ŸçŸ¥è¯†è’¸é¦ï¼ˆå¾®è°ƒäº†ä¸¤ä¸ªæ•™å¸ˆæ¨¡å‹è´Ÿè´£ä¸åŒä»»åŠ¡ï¼šäº‹ä»¶è®ºå…ƒæŠ½å–ã€ç»“æœäº‹ä»¶é¢„æµ‹ï¼‰-&gt;å› æœæœ€ä¼˜ä¼ è¾“CEOTï¼ˆç›¸å…³æŸå¤±å¹¶å…¥è’¸é¦æŸå¤±ï¼Œå‚ä¸è’¸é¦è®­ç»ƒï¼Œå­¦ç”Ÿæ¨¡å‹ä¸æ•™å¸ˆæ¨¡å‹ç»†ç²’åº¦å¯¹é½ï¼‰ **[conclusion/contribution]** ECEä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼ŒECE-CCKSæ•°æ®é›†ä¸Šæ¯”æ­¤å‰æœ€ä¼˜æ–¹æ³•F1å€¼æé«˜äº†8.39% **[limitation/future]** å¤šæ•™å¸ˆè’¸é¦æœºåˆ¶å’Œå¤æ‚çš„OTè®¡ç®—æ˜¾è‘—å¢åŠ äº†æ¨¡å‹è®­ç»ƒé˜¶æ®µçš„æˆæœ¬">**[summary]**</summary><div style="margin-top:6px">**[motivation]** ç°æœ‰ECEï¼ˆäº‹ä»¶å› æœå…³ç³»æŠ½å–ï¼‰æ–¹å¼æ²¡æœ‰å……åˆ†åˆ©ç”¨åŸå› äº‹ä»¶å’Œç»“æœäº‹ä»¶ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚è¿™æœ¬å¯ä»¥ä¸ºå› æœå…³ç³»æ¨ç†æä¾›å…³é”®çº¿ç´¢<br>**[innovation]** è®ºæ–‡è§£è€¦ECEçš„ä¸¤ä¸ªä»»åŠ¡ï¼ˆè®ºå…ƒæŠ½å–ã€ç»“æœäº‹ä»¶é¢„æµ‹ï¼‰ï¼Œå¹¶ä½¿ç”¨OTè¿›è¡Œæ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹çš„ç»†ç²’åº¦å¯¹é½ï¼Œå¢å¼ºäº†å› æœäº‹ä»¶ä¹‹é—´çš„éšå¼è”ç³»<br>**[method]** åŸºäºæ¨¡æ¿çš„æ¡ä»¶ç”Ÿæˆï¼ˆè¾“å…¥åŸºäºæ¨¡æ¿é™„æœ‰ç‰¹å®šç‰¹æƒä¿¡æ¯çš„promptï¼Œä½¿é¢„è®­ç»ƒæ¨¡å‹BARTï¼ˆåŸºäºtransformerï¼‰è¾“å‡ºåŸºäºæ¨¡æ¿çš„ç»“æ„åŒ–çš„æ–‡æœ¬ï¼Œç”¨äºåç»­å¾®è°ƒï¼‰->æ•™å¸ˆ-å­¦ç”ŸçŸ¥è¯†è’¸é¦ï¼ˆå¾®è°ƒäº†ä¸¤ä¸ªæ•™å¸ˆæ¨¡å‹è´Ÿè´£ä¸åŒä»»åŠ¡ï¼šäº‹ä»¶è®ºå…ƒæŠ½å–ã€ç»“æœäº‹ä»¶é¢„æµ‹ï¼‰->å› æœæœ€ä¼˜ä¼ è¾“CEOTï¼ˆç›¸å…³æŸå¤±å¹¶å…¥è’¸é¦æŸå¤±ï¼Œå‚ä¸è’¸é¦è®­ç»ƒï¼Œå­¦ç”Ÿæ¨¡å‹ä¸æ•™å¸ˆæ¨¡å‹ç»†ç²’åº¦å¯¹é½ï¼‰<br>**[conclusion/contribution]** ECEä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼ŒECE-CCKSæ•°æ®é›†ä¸Šæ¯”æ­¤å‰æœ€ä¼˜æ–¹æ³•F1å€¼æé«˜äº†8.39%<br>**[limitation/future]** å¤šæ•™å¸ˆè’¸é¦æœºåˆ¶å’Œå¤æ‚çš„OTè®¡ç®—æ˜¾è‘—å¢åŠ äº†æ¨¡å‹è®­ç»ƒé˜¶æ®µçš„æˆæœ¬</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">â”è¿™ä¸ªæ–¹æ³•ä¸ºä»€ä¹ˆå¯ä»¥è§£å†³é—®é¢˜ï¼Ÿ<br>    æ ¸å¿ƒæ–¹æ³•æ˜¯ä½¿ç”¨ä¼˜ç§€çš„ä¸“å®¶æ¨¡å‹å¯¹å°æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œç»“åˆäº†5ä¸ªå°æŸå¤±å‡½æ•°ï¼ˆä¸¤ä¸ªæ¥æºäºOTï¼‰ï¼Œä»¥å°½å¯èƒ½ä¿è¯çŸ¥è¯†è¿ç§»æ•ˆæœ<br><br>â”æœ‰ä»€ä¹ˆå€¼å¾—æ³¨æ„çš„ç»†èŠ‚å—ï¼Ÿ<br>    ğŸ“è®ºæ–‡ä¸ºä»€ä¹ˆé€‰æ‹©è®­ç»ƒä¸¤ä¸ªæ‰¿æ‹…ä¸åŒä»»åŠ¡çš„æ•™å¸ˆæ¨¡å‹ï¼Œä¸€èµ·è’¸é¦å‡ºç›®æ ‡æ¨¡å‹çš„æ–¹æ³•<br>        è¿™å‡ ä¹æ˜¯è¿›è¡Œå¾®è°ƒç‰¹åŒ–ç”¨äºè¯¥ä¸‹æ¸¸ä»»åŠ¡çš„å¿…ç„¶é€‰æ‹©<br>        å› ä¸ºéœ€è¦è®­ç»ƒä¸¤ä¸ªèƒ½åŠ›ï¼ˆå­ä»»åŠ¡ï¼‰ï¼šæ–‡æœ¬è®ºå…ƒæŠ½å–èƒ½åŠ›ï¼ˆäº‹ä»¶å†…äº¤äº’ï¼‰å’Œäº‹ä»¶ç»“æœè”ç³»èƒ½åŠ›ï¼ˆäº‹ä»¶é—´ï¼‰<br>        ä¸¤ä¸ªå­ä»»åŠ¡éœ€è¦åˆ†åˆ«è°ƒæ•´æ•°æ®é›†çš„è¾“å…¥ï¼Œä¸ºä»–ä»¬åˆ†é…ä¸åŒçš„ç‰¹æƒä¿¡æ¯ï¼Œä»è€Œé¿å…æ··æ·†å’Œå‡ºç°â€œä½œå¼Šâ€ï¼ˆçœ‹åˆ°è¿™ä¸ªå­ä»»åŠ¡ä¸åº”çœ‹åˆ°çš„ç‰¹æƒä¿¡æ¯ï¼‰</div></details></div></div>|

### | Generation (1 papers)


### Comment Generation (1 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
|[![Project](https://img.shields.io/badge/Project-View-blue)](https://netsys.surrey.ac.uk/datasets/slashdot/) [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Conversation Kernels: A Flexible Mechanism to Learn Relevant Context for Online Conversation Unde...](https://ojs.aaai.org/index.php/ICWSM/article/view/35800) <br> to be filled in <br> 2025-06-07 <br> <span style="color:cyan">[multi-categoryï¼š[Base Techniques](#-Base-Techniques-2-papers), [Comment Generation](#Comment-Generation-1-papers)]</span>|A flexible, structural context discovery framework that enhances conversation understanding by learning to attend to relevant topological neighborhoods within conversation trees.\[ç¿»è¯‘\] ä¸€ä¸ªçµæ´»çš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡å‘ç°æ¡†æ¶ï¼Œé€šè¿‡å­¦ä¹ å…³æ³¨å¯¹è¯æ ‘å†…ç›¸å…³çš„æ‹“æ‰‘é‚»åŸŸæ¥å¢å¼ºå¯¹è¯ç†è§£èƒ½åŠ›ã€‚|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Conversation Kernels-Conversa-1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Conversation Kernels2-Conversa-1.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Addressing the sparsity and context-dependency of individual online utterances, where traditional models often fail to capture implicit dependencies within conversation trees or introduce noise through indiscriminate context inclusion. \[ç¿»è¯‘\] é’ˆå¯¹åœ¨çº¿è¨€è®ºå›ºæœ‰çš„ç¨€ç–æ€§å’Œè¯­å¢ƒä¾èµ–æ€§é—®é¢˜ï¼Œå³ä¼ ç»Ÿæ¨¡å‹å¾€å¾€éš¾ä»¥æ•æ‰å¯¹è¯æ ‘å†…çš„éšå¼ä¾èµ–å…³ç³»ï¼Œæˆ–å› æ— å·®åˆ«åœ°å¼•å…¥ä¸Šä¸‹æ–‡è€Œäº§ç”Ÿå™ªå£° **[innovation]** The proposal of &quot;Conversation Kernels,&quot; a general-purpose mechanism that employs flexible topological shapes to retrieve fine-grained, structured conversational context, distinguishing itself by identifying the &quot;right&quot; structural neighborhood rather than merely increasing context length. \[ç¿»è¯‘\] æå‡ºäº†â€œå¯¹è¯æ ¸â€è¿™ä¸€é€šç”¨æœºåˆ¶ï¼Œåˆ©ç”¨çµæ´»çš„æ‹“æ‰‘å½¢çŠ¶æ¥æ£€ç´¢ç»†ç²’åº¦çš„ç»“æ„åŒ–å¯¹è¯ä¸Šä¸‹æ–‡ï¼›å…¶ç‹¬åˆ°ä¹‹å¤„åœ¨äºé€šè¿‡è¯†åˆ«â€œæ­£ç¡®â€çš„ç»“æ„é‚»åŸŸè€Œéå•çº¯å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦æ¥ç†è§£å¯¹è¯ã€‚ **[method]** An end-to-end trained probabilistic framework that first retrieves relevant structural windows \(e.g., ancestors, neighbors\) via similarity scoring, and subsequently fuses these contexts through a weighted marginalization of the predictive distributions generated by a RoBERTa-based encoder. \[ç¿»è¯‘\] ä¸€ä¸ªç«¯åˆ°ç«¯è®­ç»ƒçš„æ¦‚ç‡æ¡†æ¶ï¼Œé¦–å…ˆé€šè¿‡ç›¸ä¼¼åº¦è¯„åˆ†æ£€ç´¢ç›¸å…³çš„ç»“æ„åŒ–çª—å£ï¼ˆå¦‚ç¥–å…ˆã€é‚»å±…ï¼‰ï¼Œéšåé€šè¿‡å¯¹RoBERTaç¼–ç å™¨ç”Ÿæˆçš„é¢„æµ‹åˆ†å¸ƒè¿›è¡ŒåŠ æƒæ±‚å’Œï¼ˆè¾¹ç¼˜åŒ–ï¼‰ï¼Œä»è€Œèåˆè¿™äº›ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\[é€šä¿—æ ¸å¿ƒ\]é’ˆå¯¹ç›®æ ‡è¯„è®ºæ„å»ºå›å¤æ ‘ï¼Œå–å‡ ä¸ªçª—å£ï¼ˆå¦‚çˆ¶è¯„è®ºçª—å£ã€1è·³çª—å£ï¼‰ï¼Œæ¯ä¸ªçª—å£ä¸­æ‰€æœ‰è¯„è®ºä¸åŸè¯„è®ºæ‹¼æ¥ï¼Œå¹¶è¿›è¡Œé¢„æµ‹ï¼Œæœ€åä¸åŒçª—å£ä¸åŸè¯„è®ºçš„ç›¸å…³æ€§ç»è¿‡softmaxä½œä¸ºæƒé‡ï¼Œå¯¹æ‰€æœ‰é¢„æµ‹ç½®ä¿¡åº¦åŠ æƒå’Œï¼Œå¾—åˆ°æœ€ç»ˆç»“æœ **[conclusion/contribution]** Extensive experiments on Slashdot data demonstrate that context-augmented kernels outperform baseline transformers by up to 20% in accuracy and surpass general-purpose LLMs \(GPT-3.5/4\) in specific categorization tasks, revealing that different tasks require distinct structural context patterns. \[ç¿»è¯‘\] åœ¨Slashdotæ•°æ®ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œä¸Šä¸‹æ–‡å¢å¼ºçš„æ ¸æœºåˆ¶åœ¨å‡†ç¡®ç‡ä¸Šæ¯”åŸºçº¿Transformeræ¨¡å‹é«˜å‡º20%ï¼Œå¹¶åœ¨ç‰¹å®šåˆ†ç±»ä»»åŠ¡ä¸­è¶…è¶Šäº†é€šç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆGPT-3.5/4ï¼‰ï¼Œæ­ç¤ºäº†ä¸åŒä»»åŠ¡éœ€è¦æˆªç„¶ä¸åŒçš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ¨¡å¼ã€‚ **[limitation/future]** The approach relies heavily on explicit tree-structured reply threads, limiting applicability in flat discussion formats, and may face cold-start challenges in early-stage conversations with sparse context. \[ç¿»è¯‘\] è¯¥æ–¹æ³•ä¸¥é‡ä¾èµ–æ˜¾å¼çš„æ ‘çŠ¶å›å¤çº¿ç´¢ï¼Œé™åˆ¶äº†å…¶åœ¨æ‰å¹³åŒ–è®¨è®ºå½¢å¼ä¸­çš„é€‚ç”¨æ€§ï¼Œå¹¶ä¸”åœ¨ä¸Šä¸‹æ–‡ç¨€ç–çš„å¯¹è¯æ—©æœŸé˜¶æ®µå¯èƒ½é¢ä¸´å†·å¯åŠ¨æŒ‘æˆ˜ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Addressing the sparsity and context-dependency of individual online utterances, where traditional models often fail to capture implicit dependencies within conversation trees or introduce noise through indiscriminate context inclusion.<br>\[ç¿»è¯‘\] é’ˆå¯¹åœ¨çº¿è¨€è®ºå›ºæœ‰çš„ç¨€ç–æ€§å’Œè¯­å¢ƒä¾èµ–æ€§é—®é¢˜ï¼Œå³ä¼ ç»Ÿæ¨¡å‹å¾€å¾€éš¾ä»¥æ•æ‰å¯¹è¯æ ‘å†…çš„éšå¼ä¾èµ–å…³ç³»ï¼Œæˆ–å› æ— å·®åˆ«åœ°å¼•å…¥ä¸Šä¸‹æ–‡è€Œäº§ç”Ÿå™ªå£°<br>**[innovation]** The proposal of "Conversation Kernels," a general-purpose mechanism that employs flexible topological shapes to retrieve fine-grained, structured conversational context, distinguishing itself by identifying the "right" structural neighborhood rather than merely increasing context length.<br>\[ç¿»è¯‘\] æå‡ºäº†â€œå¯¹è¯æ ¸â€è¿™ä¸€é€šç”¨æœºåˆ¶ï¼Œåˆ©ç”¨çµæ´»çš„æ‹“æ‰‘å½¢çŠ¶æ¥æ£€ç´¢ç»†ç²’åº¦çš„ç»“æ„åŒ–å¯¹è¯ä¸Šä¸‹æ–‡ï¼›å…¶ç‹¬åˆ°ä¹‹å¤„åœ¨äºé€šè¿‡è¯†åˆ«â€œæ­£ç¡®â€çš„ç»“æ„é‚»åŸŸè€Œéå•çº¯å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦æ¥ç†è§£å¯¹è¯ã€‚<br>**[method]** An end-to-end trained probabilistic framework that first retrieves relevant structural windows \(e.g., ancestors, neighbors\) via similarity scoring, and subsequently fuses these contexts through a weighted marginalization of the predictive distributions generated by a RoBERTa-based encoder.<br>\[ç¿»è¯‘\] ä¸€ä¸ªç«¯åˆ°ç«¯è®­ç»ƒçš„æ¦‚ç‡æ¡†æ¶ï¼Œé¦–å…ˆé€šè¿‡ç›¸ä¼¼åº¦è¯„åˆ†æ£€ç´¢ç›¸å…³çš„ç»“æ„åŒ–çª—å£ï¼ˆå¦‚ç¥–å…ˆã€é‚»å±…ï¼‰ï¼Œéšåé€šè¿‡å¯¹RoBERTaç¼–ç å™¨ç”Ÿæˆçš„é¢„æµ‹åˆ†å¸ƒè¿›è¡ŒåŠ æƒæ±‚å’Œï¼ˆè¾¹ç¼˜åŒ–ï¼‰ï¼Œä»è€Œèåˆè¿™äº›ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\[é€šä¿—æ ¸å¿ƒ\]é’ˆå¯¹ç›®æ ‡è¯„è®ºæ„å»ºå›å¤æ ‘ï¼Œå–å‡ ä¸ªçª—å£ï¼ˆå¦‚çˆ¶è¯„è®ºçª—å£ã€1è·³çª—å£ï¼‰ï¼Œæ¯ä¸ªçª—å£ä¸­æ‰€æœ‰è¯„è®ºä¸åŸè¯„è®ºæ‹¼æ¥ï¼Œå¹¶è¿›è¡Œé¢„æµ‹ï¼Œæœ€åä¸åŒçª—å£ä¸åŸè¯„è®ºçš„ç›¸å…³æ€§ç»è¿‡softmaxä½œä¸ºæƒé‡ï¼Œå¯¹æ‰€æœ‰é¢„æµ‹ç½®ä¿¡åº¦åŠ æƒå’Œï¼Œå¾—åˆ°æœ€ç»ˆç»“æœ<br>**[conclusion/contribution]** Extensive experiments on Slashdot data demonstrate that context-augmented kernels outperform baseline transformers by up to 20% in accuracy and surpass general-purpose LLMs \(GPT-3.5/4\) in specific categorization tasks, revealing that different tasks require distinct structural context patterns.<br>\[ç¿»è¯‘\] åœ¨Slashdotæ•°æ®ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œä¸Šä¸‹æ–‡å¢å¼ºçš„æ ¸æœºåˆ¶åœ¨å‡†ç¡®ç‡ä¸Šæ¯”åŸºçº¿Transformeræ¨¡å‹é«˜å‡º20%ï¼Œå¹¶åœ¨ç‰¹å®šåˆ†ç±»ä»»åŠ¡ä¸­è¶…è¶Šäº†é€šç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆGPT-3.5/4ï¼‰ï¼Œæ­ç¤ºäº†ä¸åŒä»»åŠ¡éœ€è¦æˆªç„¶ä¸åŒçš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ¨¡å¼ã€‚<br>**[limitation/future]** The approach relies heavily on explicit tree-structured reply threads, limiting applicability in flat discussion formats, and may face cold-start challenges in early-stage conversations with sparse context.<br>\[ç¿»è¯‘\] è¯¥æ–¹æ³•ä¸¥é‡ä¾èµ–æ˜¾å¼çš„æ ‘çŠ¶å›å¤çº¿ç´¢ï¼Œé™åˆ¶äº†å…¶åœ¨æ‰å¹³åŒ–è®¨è®ºå½¢å¼ä¸­çš„é€‚ç”¨æ€§ï¼Œå¹¶ä¸”åœ¨ä¸Šä¸‹æ–‡ç¨€ç–çš„å¯¹è¯æ—©æœŸé˜¶æ®µå¯èƒ½é¢ä¸´å†·å¯åŠ¨æŒ‘æˆ˜ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">ã€åŸºç¡€æŠ€æœ¯â€”ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ–¹æ³•ã€‘å¯ç”¨äºæ‰€æœ‰å†…å®¹ç†è§£ä»»åŠ¡ï¼Œè®ºæ–‡ä¸­çš„å®éªŒç”¨çš„æ˜¯æ˜¯å¦å—æ¬¢è¿äºŒåˆ†ç±»<br>\[å¼•ç”¨æ–‡\]To better bridge pattern recognition with social interaction structures, Agarwal et al. \(2025\) proposed Conversation Kernels, an end-to-end framework designed to extract fine-grained context from conversation trees. By dynamically retrieving and weighting specific topological neighborhoods \(e.g., ancestors or siblings\) rather than ingesting linear history, their method effectively filters noise inherent in social discussions. This structural selectivity demonstrates that incorporating explicit interaction topologies is crucial for accurately decoding the nature of online conversations, yielding performance that surpasses even general-purpose Large Language Models like GPT-4.<br>\[ç¿»è¯‘\]<br>ä¸ºäº†æ›´å¥½åœ°å°†æ¨¡å¼è¯†åˆ«ä¸ç¤¾ä¼šäº’åŠ¨ç»“æ„è”ç³»èµ·æ¥ï¼ŒAgarwalç­‰äºº \(2025\) æå‡ºäº†â€œå¯¹è¯æ ¸ï¼ˆConversation Kernelsï¼‰â€ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨ä»å¯¹è¯æ ‘ä¸­æå–ç»†ç²’åº¦ä¸Šä¸‹æ–‡çš„ç«¯åˆ°ç«¯æ¡†æ¶ã€‚é€šè¿‡åŠ¨æ€æ£€ç´¢å¹¶åŠ æƒç‰¹å®šçš„æ‹“æ‰‘é‚»åŸŸï¼ˆå¦‚ç¥–å…ˆæˆ–å…„å¼ŸèŠ‚ç‚¹ï¼‰è€Œéæ‘„å…¥çº¿æ€§å†å²ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°è¿‡æ»¤äº†ç¤¾ä¼šè®¨è®ºä¸­å›ºæœ‰çš„å™ªå£°ã€‚è¿™ç§ç»“æ„é€‰æ‹©æ€§è¯æ˜ï¼Œç»“åˆæ˜¾å¼çš„äº’åŠ¨æ‹“æ‰‘å¯¹äºå‡†ç¡®è§£è¯»åœ¨çº¿å¯¹è¯çš„æ€§è´¨è‡³å…³é‡è¦ï¼Œå…¶è¡¨ç°ç”šè‡³è¶…è¶Šäº†åƒ GPT-4 è¿™æ ·çš„é€šç”¨å¤§è¯­è¨€æ¨¡å‹ã€‚</div></details></div></div>|

### | Simulation and Deduction (2 papers)


### Social Simulation (2 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-Political%20Analysis-blue)]()<br>[Out of one, many: Using language models to simulate human samples](https://www.cambridge.org/core/journals/political-analysis/article/out-of-one-many-using-language-models-to-simulate-human-samples/035D7C8A55B237942FB6DBAD7CAA4E49) <br> Lisa P. Argyle,Ethan C. Busby,Nancy Fulda2, Joshua R. Gubler,Christopher Rytting and David Wingate <br> 2023-07|è®©LLMæ¨¡ä»¿äººç±»è¿›è¡Œç¤¾ä¼šå­¦å®éªŒï¼Œé€šè¿‡ä¸çœŸå®æƒ…å†µå¯¹é½æ¥åˆ¤æ–­LLMç›¸å…³é¢„æµ‹èƒ½åŠ›|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Out of One, Many-Outofo-1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Out of One, Many2-Outofo-1.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** LLM&#x27;s well-documented propensity to replicate societal biases is often viewed as a liability, but this paper reconsiders it as a potential asset, suggesting these biases reflect the complex, fine-grained attitudinal distributions embedded within human subpopulations.  \[ç¿»è¯‘\]æ¨¡å‹å¤åˆ¶ç¤¾ä¼šåè§çš„å€¾å‘é€šå¸¸è¢«è§†ä¸ºç¼ºé™·ï¼Œä½†æœ¬æ–‡å°†å…¶é‡æ–°è§†ä¸ºä¸€ç§æ½œåœ¨ä¼˜åŠ¿ï¼Œè®¤ä¸ºè¿™äº›åè§åæ˜ äº†å†…åµŒäºäººç±»äºšç¾¤ä½“ä¸­å¤æ‚ã€ç»†ç²’åº¦çš„æ€åº¦åˆ†å¸ƒã€‚ **[innovation]** \(i\) proposing the novel concept of â€œalgorithmic fidelityâ€ and its four criteria, establishing a framework to quantify how well LLMs simulate human populations; \(ii\) introducing â€œsilicon sampling,â€ a method that conditions models on real demographic backstories to generate representative virtual samples \[ç¿»è¯‘\] \(i\) æå‡ºâ€œç®—æ³•ä¿çœŸåº¦â€æ–°æ¦‚å¿µåŠå…¶å››ä¸ªæ ‡å‡†ï¼Œå»ºç«‹äº†é‡åŒ–LLMæ¨¡æ‹Ÿäººç±»ç¾¤ä½“æ•ˆæœçš„æ¡†æ¶ï¼›\(ii\) å¼•å…¥â€œç¡…é‡‡æ ·â€æ–¹æ³•ï¼ŒåŸºäºçœŸå®äººå£èƒŒæ™¯æ•…äº‹å¯¹æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–ï¼Œä»¥ç”Ÿæˆæœ‰ä»£è¡¨æ€§çš„è™šæ‹Ÿæ ·æœ¬ **[method]** \(i\) extracting sociodemographic profiles from large-scale human surveys; \(ii\) constructing first-person narrative backstories as conditioning prompts; \(iii\) feeding these prompts into GPT-3 to generate responses \(â€œsilicon samplesâ€\) to specific questions; \(iv\) statistically comparing the generated data with original human data to validate algorithmic fidelity across various metrics.  \[ç¿»è¯‘\] \(i\) ä»å¤§è§„æ¨¡äººç±»è°ƒæŸ¥ä¸­æå–ç¤¾ä¼šäººå£å­¦ç‰¹å¾ï¼›\(ii\) æ„å»ºç¬¬ä¸€äººç§°å™äº‹èƒŒæ™¯æ•…äº‹ä½œä¸ºæ¡ä»¶åŒ–æç¤ºï¼›\(iii\) å°†è¿™äº›æç¤ºè¾“å…¥GPT-3ï¼Œä»¥ç”Ÿæˆé’ˆå¯¹ç‰¹å®šé—®é¢˜çš„å›ç­”ï¼ˆâ€œç¡…æ ·æœ¬â€ï¼‰ï¼›\(iv\) ä»å¤šç»´åº¦ç»Ÿè®¡ä¸Šæ¯”è¾ƒç”Ÿæˆæ•°æ®ä¸åŸå§‹äººç±»æ•°æ®ï¼Œä»¥éªŒè¯ç®—æ³•ä¿çœŸåº¦ã€‚\[é€šä¿—æ ¸å¿ƒ\]æ–¹æ³•å¾ˆç®€å•ï¼Œä½¿ç”¨æç¤ºè¯æ¨¡ç‰ˆå¡«å…¥ç¬¦åˆäººå£ç»Ÿè®¡ç‰¹å¾çš„å—è®¿è€…ç‰¹å¾ï¼Œè®©LLMè¾“å‡ºæŒ‡å®šå›ç­”ï¼Œä¸äººç±»æ ·æœ¬åšå¯¹é½ **[conclusion/contribution]** The study demonstrates that GPT-3 exhibits high algorithmic fidelity: human evaluators struggle to distinguish its outputs from human text, and its generated data closely replicates not only aggregate opinion distributions \(e.g., vote shares\) but also the complex correlational structures between demographics, attitudes, and behaviors found in real human data.  \[ç¿»è¯‘\] ç ”ç©¶è¡¨æ˜GPT-3è¡¨ç°å‡ºé«˜ç®—æ³•ä¿çœŸåº¦ï¼šäººç±»è¯„ä¼°è€…éš¾ä»¥åŒºåˆ†å…¶è¾“å‡ºä¸äººç±»æ–‡æœ¬ï¼Œå…¶ç”Ÿæˆçš„æ•°æ®ä¸ä»…ç´§å¯†å¤ç°äº†èšåˆæ„è§åˆ†å¸ƒï¼ˆå¦‚æŠ•ç¥¨ä»½é¢ï¼‰ï¼Œè¿˜å¤ç°äº†çœŸå®äººç±»æ•°æ®ä¸­äººå£ç‰¹å¾ã€æ€åº¦å’Œè¡Œä¸ºä¹‹é—´å¤æ‚çš„ç›¸å…³æ€§ç»“æ„ã€‚ **[limitation/future]** æç¤ºè¯ä¸­æ˜¾ç¤ºæ ‡æ˜è§’è‰²èº«ä»½ï¼Œä¼šè®©LLMè¿‡åº¦é‡è§†ï¼Œæœ‰èµ°æ·å¾„ä¹‹å«Œ">**[summary]**</summary><div style="margin-top:6px">**[motivation]** LLM's well-documented propensity to replicate societal biases is often viewed as a liability, but this paper reconsiders it as a potential asset, suggesting these biases reflect the complex, fine-grained attitudinal distributions embedded within human subpopulations.<br><br>\[ç¿»è¯‘\]æ¨¡å‹å¤åˆ¶ç¤¾ä¼šåè§çš„å€¾å‘é€šå¸¸è¢«è§†ä¸ºç¼ºé™·ï¼Œä½†æœ¬æ–‡å°†å…¶é‡æ–°è§†ä¸ºä¸€ç§æ½œåœ¨ä¼˜åŠ¿ï¼Œè®¤ä¸ºè¿™äº›åè§åæ˜ äº†å†…åµŒäºäººç±»äºšç¾¤ä½“ä¸­å¤æ‚ã€ç»†ç²’åº¦çš„æ€åº¦åˆ†å¸ƒã€‚<br>**[innovation]** \(i\) proposing the novel concept of â€œalgorithmic fidelityâ€ and its four criteria, establishing a framework to quantify how well LLMs simulate human populations; \(ii\) introducing â€œsilicon sampling,â€ a method that conditions models on real demographic backstories to generate representative virtual samples<br>\[ç¿»è¯‘\] \(i\) æå‡ºâ€œç®—æ³•ä¿çœŸåº¦â€æ–°æ¦‚å¿µåŠå…¶å››ä¸ªæ ‡å‡†ï¼Œå»ºç«‹äº†é‡åŒ–LLMæ¨¡æ‹Ÿäººç±»ç¾¤ä½“æ•ˆæœçš„æ¡†æ¶ï¼›\(ii\) å¼•å…¥â€œç¡…é‡‡æ ·â€æ–¹æ³•ï¼ŒåŸºäºçœŸå®äººå£èƒŒæ™¯æ•…äº‹å¯¹æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–ï¼Œä»¥ç”Ÿæˆæœ‰ä»£è¡¨æ€§çš„è™šæ‹Ÿæ ·æœ¬<br>**[method]** \(i\) extracting sociodemographic profiles from large-scale human surveys; \(ii\) constructing first-person narrative backstories as conditioning prompts; \(iii\) feeding these prompts into GPT-3 to generate responses \(â€œsilicon samplesâ€\) to specific questions; \(iv\) statistically comparing the generated data with original human data to validate algorithmic fidelity across various metrics.<br><br>\[ç¿»è¯‘\] \(i\) ä»å¤§è§„æ¨¡äººç±»è°ƒæŸ¥ä¸­æå–ç¤¾ä¼šäººå£å­¦ç‰¹å¾ï¼›\(ii\) æ„å»ºç¬¬ä¸€äººç§°å™äº‹èƒŒæ™¯æ•…äº‹ä½œä¸ºæ¡ä»¶åŒ–æç¤ºï¼›\(iii\) å°†è¿™äº›æç¤ºè¾“å…¥GPT-3ï¼Œä»¥ç”Ÿæˆé’ˆå¯¹ç‰¹å®šé—®é¢˜çš„å›ç­”ï¼ˆâ€œç¡…æ ·æœ¬â€ï¼‰ï¼›\(iv\) ä»å¤šç»´åº¦ç»Ÿè®¡ä¸Šæ¯”è¾ƒç”Ÿæˆæ•°æ®ä¸åŸå§‹äººç±»æ•°æ®ï¼Œä»¥éªŒè¯ç®—æ³•ä¿çœŸåº¦ã€‚\[é€šä¿—æ ¸å¿ƒ\]æ–¹æ³•å¾ˆç®€å•ï¼Œä½¿ç”¨æç¤ºè¯æ¨¡ç‰ˆå¡«å…¥ç¬¦åˆäººå£ç»Ÿè®¡ç‰¹å¾çš„å—è®¿è€…ç‰¹å¾ï¼Œè®©LLMè¾“å‡ºæŒ‡å®šå›ç­”ï¼Œä¸äººç±»æ ·æœ¬åšå¯¹é½<br>**[conclusion/contribution]** The study demonstrates that GPT-3 exhibits high algorithmic fidelity: human evaluators struggle to distinguish its outputs from human text, and its generated data closely replicates not only aggregate opinion distributions \(e.g., vote shares\) but also the complex correlational structures between demographics, attitudes, and behaviors found in real human data.<br><br>\[ç¿»è¯‘\] ç ”ç©¶è¡¨æ˜GPT-3è¡¨ç°å‡ºé«˜ç®—æ³•ä¿çœŸåº¦ï¼šäººç±»è¯„ä¼°è€…éš¾ä»¥åŒºåˆ†å…¶è¾“å‡ºä¸äººç±»æ–‡æœ¬ï¼Œå…¶ç”Ÿæˆçš„æ•°æ®ä¸ä»…ç´§å¯†å¤ç°äº†èšåˆæ„è§åˆ†å¸ƒï¼ˆå¦‚æŠ•ç¥¨ä»½é¢ï¼‰ï¼Œè¿˜å¤ç°äº†çœŸå®äººç±»æ•°æ®ä¸­äººå£ç‰¹å¾ã€æ€åº¦å’Œè¡Œä¸ºä¹‹é—´å¤æ‚çš„ç›¸å…³æ€§ç»“æ„ã€‚<br>**[limitation/future]** æç¤ºè¯ä¸­æ˜¾ç¤ºæ ‡æ˜è§’è‰²èº«ä»½ï¼Œä¼šè®©LLMè¿‡åº¦é‡è§†ï¼Œæœ‰èµ°æ·å¾„ä¹‹å«Œ</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[å¼•ç”¨æ–‡\]Argyle et al. \(2023\) represent a pivotal shift from viewing LLMs as mere pattern recognition tools to employing them as tools for social simulation. Their work provides a paradigmatic methodologyâ€”centered on the concept of â€œalgorithmic fidelityâ€â€”for experimentally testing whether and how the statistical predictions of an LLM align with nuanced human societal patterns. By conditioning GPT-3 on detailed demographic backstories within prompts \(â€œsilicon samplingâ€\), they demonstrated that the model itself could generate attitudes and internal correlations that closely mirror those of real human subgroups. This marks a transition from goal-oriented text generation to the study of simulated social emergence.<br><br>\[ç¿»è¯‘\]<br>Argyleç­‰äºº\(2023\)çš„ç ”ç©¶æ ‡å¿—ç€ä¸€ä¸ªå…³é”®è½¬å˜ï¼šä»å°†LLMè§†ä¸ºå•çº¯çš„æ¨¡å¼è¯†åˆ«å·¥å…·ï¼Œè½¬å‘å°†å…¶ç”¨ä½œç¤¾ä¼šä»¿çœŸçš„å·¥å…·ã€‚ä»–ä»¬çš„å·¥ä½œæä¾›äº†ä¸€ç§èŒƒå¼æ–¹æ³•â€”â€”å›´ç»•â€œç®—æ³•ä¿çœŸåº¦â€æ¦‚å¿µâ€”â€”æ¥å®éªŒæ€§åœ°æµ‹è¯•LLMçš„ç»Ÿè®¡é¢„æµ‹æ˜¯å¦åŠå¦‚ä½•ä¸äººç±»ç¤¾ä¼šæ¨¡å¼å¯¹é½ã€‚é€šè¿‡åœ¨æç¤ºè¯ä¸­ä¸ºGPT-3æ–½åŠ è¯¦ç»†çš„äººå£èƒŒæ™¯æ•…äº‹æ¡ä»¶ï¼ˆâ€œç¡…é‡‡æ ·â€ï¼‰ï¼Œä»–ä»¬è¯æ˜äº†è¯¥æ¨¡å‹èƒ½å¤Ÿæ¶Œç°å‡ºä¸çœŸå®äººç±»äºšç¾¤ä½“é«˜åº¦å»åˆçš„æ€åº¦åŠå†…éƒ¨å…³è”ã€‚æ ‡å¿—ç€ä»ç›®æ ‡å¯¼å‘çš„æ–‡æœ¬ç”Ÿæˆå‘æ¨¡æ‹Ÿç¤¾ä¼šæ¶Œç°ç ”ç©¶çš„è¿‡æ¸¡</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-EMNLP%20Findings-blue)]()<br>[Are Large Language Models \\(LLMs\\) Good Social Predictors?](https://aclanthology.org/2024.findings-emnlp.153) <br> Kaiqi Yang\*,Hang Li\*,Hongzhi Wen,Tai-Quan Peng,Jiliang Tang,Hui Liu <br> 2024|æ¶ˆèäº†æœ€èƒ½å½±å“é¢„æµ‹ç»“æœçš„â€œæ„è¯†å½¢æ€è‡ªæˆ‘å®šä½â€å’Œâ€œå…šæ´¾è®¤åŒâ€ï¼Œå‘ç°é¢„æµ‹èƒ½åŠ›æ¥è¿‘äºéšæœº|<img width="1200" alt="pipeline" src="figures/anti-Out of One, Many-AreLarg-1.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** è®ºæ–‡Out of one, many: Using language models to simulate human sampleså¯èƒ½åˆ©ç”¨äº†æ·å¾„ç‰¹æ€§ï¼Œä¸”èƒ½åŠ›éš¾ä»¥ä»å®è§‚ç»†åŒ–åˆ°ä¸ªä½“ **[innovation]** \[AI generated\] Proposes a novel social prediction benchmark \(Soc-PRF\) categorizing features by mutability to rigorously evaluate LLMs and reveals their reliance on input shortcuts. \[ç¿»è¯‘\]ï¼šæå‡ºäº†ä¸€ä¸ªæŒ‰ç‰¹å¾å¯å˜æ€§åˆ†ç±»çš„æ–°é¢–ç¤¾ä¼šé¢„æµ‹åŸºå‡†ï¼ˆSoc-PRFï¼‰ï¼Œä»¥ä¸¥æ ¼è¯„ä¼°LLMsï¼Œå¹¶æ­ç¤ºäº†å…¶å¯¹è¾“å…¥æ·å¾„çš„ä¾èµ–ã€‚ **[method]** First, a replication and ablation study on the ANES voting dataset quantifies the performance drop when removing highly correlated â€œshortcutâ€ inputs \(e.g., party ID\). Second, a new benchmark is constructed using Gallup World Poll data. Features are categorized by mutability \(low: demographics; high: attitudes/behaviors\). Three prediction settings are definedâ€”low-to-high, high-to-low, and high-to-highâ€”simulating realistic data collection scenarios. Multiple LLMs are evaluated under zero-shot prompting, with AUC as the primary metric. \[ç¿»è¯‘\]ï¼šé¦–å…ˆï¼Œåœ¨ANESæŠ•ç¥¨æ•°æ®é›†ä¸Šè¿›è¡Œå¤åˆ¶å’Œæ¶ˆèç ”ç©¶ï¼Œé‡åŒ–äº†ç§»é™¤é«˜åº¦ç›¸å…³çš„â€œæ·å¾„â€è¾“å…¥ï¼ˆå¦‚å…šæ´¾èº«ä»½ï¼‰åçš„æ€§èƒ½ä¸‹é™ã€‚å…¶æ¬¡ï¼Œä½¿ç”¨ç›–æ´›æ™®ä¸–ç•Œæ°‘æ„è°ƒæŸ¥æ•°æ®æ„å»ºäº†ä¸€ä¸ªæ–°åŸºå‡†ã€‚ç‰¹å¾æŒ‰å¯å˜æ€§åˆ†ç±»ï¼ˆä½ï¼šäººå£ç»Ÿè®¡å­¦ç‰¹å¾ï¼›é«˜ï¼šæ€åº¦/è¡Œä¸ºï¼‰ã€‚å®šä¹‰äº†ä¸‰ç§é¢„æµ‹è®¾å®šâ€”â€”ä½æ¨é«˜ã€é«˜æ¨ä½å’Œé«˜æ¨é«˜â€”â€”ä»¥æ¨¡æ‹Ÿç°å®çš„æ•°æ®æ”¶é›†åœºæ™¯ã€‚åœ¨é›¶æ ·æœ¬æç¤ºä¸‹è¯„ä¼°äº†å¤šç§LLMsï¼Œä»¥AUCä¸ºä¸»è¦æŒ‡æ ‡ã€‚ **[conclusion/contribution]** The high performance in prior voting prediction vanishes when shortcuts are removed, with accuracy dropping to near-random levels \(e.g., ~61% for GPT-3.5\). In the stringent Soc-PRF settings devoid of shortcuts, all tested LLMs \(including GPT-4\) perform no better than random guessing \(AUC ~50\). \[ç¿»è¯‘\]ï¼š å…ˆå‰æŠ•ç¥¨é¢„æµ‹ä¸­çš„é«˜æ€§èƒ½æ¶ˆå¤±ï¼Œå‡†ç¡®ç‡ä¸‹é™è‡³æ¥è¿‘éšæœºæ°´å¹³ï¼ˆä¾‹å¦‚ï¼ŒGPT-3.5çº¦ä¸º61%ï¼‰ã€‚åœ¨æ’é™¤æ·å¾„çš„ä¸¥æ ¼Soc-PRFè®¾å®šä¸­ï¼Œæ‰€æœ‰æµ‹è¯•çš„LLMsï¼ˆåŒ…æ‹¬GPT-4ï¼‰çš„è¡¨ç°å‡ä¸ä¼˜äºéšæœºçŒœæµ‹ï¼ˆAUC ~50ï¼‰ã€‚ **[limitation/future]** \[AI generated\] The promising performance of LLMs in social prediction heavily relies on unrealistic shortcut features, and their ability to generalize to real-world scenarios with ordinary inputs remains questionable. \[ç¿»è¯‘\]ï¼šLLMsåœ¨ç¤¾ä¼šé¢„æµ‹ä¸­çš„ä¼˜å¼‚è¡¨ç°ä¸¥é‡ä¾èµ–ä¸ç°å®çš„æ·å¾„ç‰¹å¾ï¼Œå…¶ä½¿ç”¨æ™®é€šè¾“å…¥æ³›åŒ–åˆ°çœŸå®åœºæ™¯çš„èƒ½åŠ›å­˜ç–‘ã€‚">**[summary]**</summary><div style="margin-top:6px">**[motivation]** è®ºæ–‡Out of one, many: Using language models to simulate human sampleså¯èƒ½åˆ©ç”¨äº†æ·å¾„ç‰¹æ€§ï¼Œä¸”èƒ½åŠ›éš¾ä»¥ä»å®è§‚ç»†åŒ–åˆ°ä¸ªä½“<br>**[innovation]** \[AI generated\] Proposes a novel social prediction benchmark \(Soc-PRF\) categorizing features by mutability to rigorously evaluate LLMs and reveals their reliance on input shortcuts.<br>\[ç¿»è¯‘\]ï¼šæå‡ºäº†ä¸€ä¸ªæŒ‰ç‰¹å¾å¯å˜æ€§åˆ†ç±»çš„æ–°é¢–ç¤¾ä¼šé¢„æµ‹åŸºå‡†ï¼ˆSoc-PRFï¼‰ï¼Œä»¥ä¸¥æ ¼è¯„ä¼°LLMsï¼Œå¹¶æ­ç¤ºäº†å…¶å¯¹è¾“å…¥æ·å¾„çš„ä¾èµ–ã€‚<br>**[method]** First, a replication and ablation study on the ANES voting dataset quantifies the performance drop when removing highly correlated â€œshortcutâ€ inputs \(e.g., party ID\). Second, a new benchmark is constructed using Gallup World Poll data. Features are categorized by mutability \(low: demographics; high: attitudes/behaviors\). Three prediction settings are definedâ€”low-to-high, high-to-low, and high-to-highâ€”simulating realistic data collection scenarios. Multiple LLMs are evaluated under zero-shot prompting, with AUC as the primary metric.<br>\[ç¿»è¯‘\]ï¼šé¦–å…ˆï¼Œåœ¨ANESæŠ•ç¥¨æ•°æ®é›†ä¸Šè¿›è¡Œå¤åˆ¶å’Œæ¶ˆèç ”ç©¶ï¼Œé‡åŒ–äº†ç§»é™¤é«˜åº¦ç›¸å…³çš„â€œæ·å¾„â€è¾“å…¥ï¼ˆå¦‚å…šæ´¾èº«ä»½ï¼‰åçš„æ€§èƒ½ä¸‹é™ã€‚å…¶æ¬¡ï¼Œä½¿ç”¨ç›–æ´›æ™®ä¸–ç•Œæ°‘æ„è°ƒæŸ¥æ•°æ®æ„å»ºäº†ä¸€ä¸ªæ–°åŸºå‡†ã€‚ç‰¹å¾æŒ‰å¯å˜æ€§åˆ†ç±»ï¼ˆä½ï¼šäººå£ç»Ÿè®¡å­¦ç‰¹å¾ï¼›é«˜ï¼šæ€åº¦/è¡Œä¸ºï¼‰ã€‚å®šä¹‰äº†ä¸‰ç§é¢„æµ‹è®¾å®šâ€”â€”ä½æ¨é«˜ã€é«˜æ¨ä½å’Œé«˜æ¨é«˜â€”â€”ä»¥æ¨¡æ‹Ÿç°å®çš„æ•°æ®æ”¶é›†åœºæ™¯ã€‚åœ¨é›¶æ ·æœ¬æç¤ºä¸‹è¯„ä¼°äº†å¤šç§LLMsï¼Œä»¥AUCä¸ºä¸»è¦æŒ‡æ ‡ã€‚<br>**[conclusion/contribution]** The high performance in prior voting prediction vanishes when shortcuts are removed, with accuracy dropping to near-random levels \(e.g., ~61% for GPT-3.5\). In the stringent Soc-PRF settings devoid of shortcuts, all tested LLMs \(including GPT-4\) perform no better than random guessing \(AUC ~50\). \[ç¿»è¯‘\]ï¼š å…ˆå‰æŠ•ç¥¨é¢„æµ‹ä¸­çš„é«˜æ€§èƒ½æ¶ˆå¤±ï¼Œå‡†ç¡®ç‡ä¸‹é™è‡³æ¥è¿‘éšæœºæ°´å¹³ï¼ˆä¾‹å¦‚ï¼ŒGPT-3.5çº¦ä¸º61%ï¼‰ã€‚åœ¨æ’é™¤æ·å¾„çš„ä¸¥æ ¼Soc-PRFè®¾å®šä¸­ï¼Œæ‰€æœ‰æµ‹è¯•çš„LLMsï¼ˆåŒ…æ‹¬GPT-4ï¼‰çš„è¡¨ç°å‡ä¸ä¼˜äºéšæœºçŒœæµ‹ï¼ˆAUC ~50ï¼‰ã€‚<br>**[limitation/future]** \[AI generated\] The promising performance of LLMs in social prediction heavily relies on unrealistic shortcut features, and their ability to generalize to real-world scenarios with ordinary inputs remains questionable. \[ç¿»è¯‘\]ï¼šLLMsåœ¨ç¤¾ä¼šé¢„æµ‹ä¸­çš„ä¼˜å¼‚è¡¨ç°ä¸¥é‡ä¾èµ–ä¸ç°å®çš„æ·å¾„ç‰¹å¾ï¼Œå…¶ä½¿ç”¨æ™®é€šè¾“å…¥æ³›åŒ–åˆ°çœŸå®åœºæ™¯çš„èƒ½åŠ›å­˜ç–‘ã€‚</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[å¼•ç”¨æ–‡\]As the field evolves from pattern recognition towards social simulation and emergent understanding, a critical reassessment of our tools is imperative. Yang et al. \(2024\) provide a pivotal corrective in this transition. Their work challenges the optimistic narrative that LLMs can serve as accurate social predictors. They demonstrate that previously reported successes in tasks like vote prediction critically depended on "shortcut features" \(e.g., using party identification to predict vote choice\) and, by introducing a novel shortcut-free benchmark \(Soc-PRF\), reveal a significant gap. In settings devoid of such shortcuts, even state-of-the-art LLMs perform at random levels. This finding underscores a fundamental limitation: while current LLMs are excellent pattern recognizers of surface correlations, they lack the deeper causal or contextual reasoning necessary for genuine social simulation and the emergence of robust socio-behavioral understanding. Their research suggests that achieving true social fidelity requires moving beyond exploiting statistical artifacts in data.<br><br>\[ç¿»è¯‘\]<br><br>éšç€è¯¥é¢†åŸŸä»æ¨¡å¼è¯†åˆ«å‘ç¤¾ä¼šä»¿çœŸä¸æ¶Œç°æ€§ç†è§£æ¼”è¿›ï¼Œå¯¹æˆ‘ä»¬çš„å·¥å…·è¿›è¡Œæ‰¹åˆ¤æ€§é‡ä¼°åŠ¿åœ¨å¿…è¡Œã€‚Yangç­‰äººï¼ˆ2024ï¼‰åœ¨è¿™ä¸€è½¬å˜ä¸­æä¾›äº†ä¸€ä¸ªå…³é”®ä¿®æ­£ã€‚ä»–ä»¬çš„å·¥ä½œæŒ‘æˆ˜äº†â€œLLMsèƒ½ä½œä¸ºå‡†ç¡®ç¤¾ä¼šé¢„æµ‹å™¨â€çš„ä¹è§‚è®ºè¿°ã€‚ä»–ä»¬è¯æ˜ï¼Œå…ˆå‰åœ¨æŠ•ç¥¨é¢„æµ‹ç­‰ä»»åŠ¡ä¸­æŠ¥å‘Šçš„æˆåŠŸï¼Œå…³é”®ä¾èµ–äºâ€œæ·å¾„ç‰¹å¾â€ï¼ˆä¾‹å¦‚ï¼Œç”¨å…šæ´¾èº«ä»½é¢„æµ‹æŠ•ç¥¨é€‰æ‹©ï¼‰ï¼Œå¹¶é€šè¿‡å¼•å…¥ä¸€ä¸ªæ–°é¢–çš„ã€æ— æ·å¾„çš„åŸºå‡†ï¼ˆSoc-PRFï¼‰ï¼Œæ­ç¤ºäº†ä¸€ä¸ªæ˜¾è‘—çš„å·®è·ã€‚åœ¨ç¼ºå°‘æ­¤ç±»æ·å¾„çš„è®¾å®šä¸­ï¼Œå³ä½¿æ˜¯æœ€å…ˆè¿›çš„LLMsè¡¨ç°ä¹Ÿå¤„äºéšæœºæ°´å¹³ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†ä¸€ä¸ªæ ¹æœ¬æ€§å±€é™ï¼šå½“å‰çš„LLMsè™½ç„¶æ˜¯ä¼˜ç§€çš„è¡¨é¢ç›¸å…³æ€§æ¨¡å¼è¯†åˆ«å™¨ï¼Œä½†ç¼ºä¹çœŸæ­£çš„ç¤¾ä¼šä»¿çœŸä»¥åŠæ¶Œç°å‡ºç¨³å¥ç¤¾ä¼šè¡Œä¸ºç†è§£æ‰€å¿…éœ€çš„ã€æ›´æ·±å±‚çš„å› æœæˆ–è¯­å¢ƒæ¨ç†èƒ½åŠ›ã€‚ä»–ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œè¦å®ç°çœŸæ­£çš„ç¤¾ä¼šæ‹ŸçœŸåº¦ï¼Œéœ€è¦è¶…è¶Šå¯¹æ•°æ®ä¸­ç»Ÿè®¡å‡è±¡çš„åˆ©ç”¨ã€‚</div></details></div></div>|

=====List End=====
## Acknowledgement