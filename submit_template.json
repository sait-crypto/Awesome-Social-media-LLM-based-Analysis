{
  "papers": [
    {
      "doi": "10.1007/s11280-022-01116-0",
      "title": "A text and GNN based controversy detection method on social media",
      "authors": "Samy Benslimane, Jérôme Azé, Sandra Bringay, Maximilien Servajean, Caroline Mollevi",
      "date": "2023-03-01",
      "category": "Controversy Analysis",
      "summary_motivation": "Existing controversy detection approaches often treat structural patterns and semantic content in isolation or rely solely on post-reply trees, neglecting the critical role of user entities and their interaction dynamics in driving social polarization.\n[翻译] 现有的争议检测方法通常将结构模式和语义内容割裂处理，或单纯依赖帖子回复树结构，忽视了用户实体及其交互动态在驱动社会极化中的关键作用。",
      "summary_innovation": "The study shifts focus from message-level dependencies to user-centric interaction graphs. A key innovation lies in aggregating individual comments into unified user features, which allows the model to encode network-level information and actor stances simultaneously within the graph structure.\n[翻译] 该研究将焦点从消息级依赖关系转移到了以用户为中心的交互图上。其主要创新在于将分散的评论聚合为统一的用户特征，这使得模型能够在图结构中同时编码网络层面的信息和行动者的立场。",
      "summary_method": "The framework constructs a user graph where node features are initialized with BERT-encoded textual features aggregated from user historical comments. Subsequently, two GNN methods—Hierarchical Representation Learning via differentiable pooling (HRL-GCN) or Attention-based Representation Learning (ARL-GAT)—are employed to capture structural patterns, ultimately performing graph-level binary classification.\n[翻译] 该框架构建了一个用户图，其中节点特征初始化为从用户历史评论中聚合的BERT编码文本特征。随后，利用通过可微池化实现的分层表示学习（HRL-GCN）或基于注意力的表示学习（ARL-GAT）两种GNN方法来捕捉结构模式，最终完成图级二分类。",
      "summary_conclusion": "Empirical evaluations on Reddit and Twitter datasets demonstrate that the hierarchical pooling strategy (HRL-GCN) achieves superior performance by effectively capturing community-level structures, validating that combining aggregated user semantics with interaction topology significantly outperforms structure-only baselines.\n[翻译] 在Reddit和Twitter数据集上的实证评估表明，分层池化策略（HRL-GCN）通过有效捕捉社区级结构实现了更优的性能，证实了结合聚合的用户语义与交互拓扑结构显著优于仅依赖基线的结构。",
      "summary_limitation": "Standard pre-trained language models perform suboptimally on noisy Twitter data without domain-specific fine-tuning. Additionally, the approach is currently limited to homogeneous graphs, suggesting that future work could explore heterogeneous graph modeling to integrate multiple interaction types.\n[翻译] 标准预训练语言模型在未经领域微调的情况下在噪声较大的Twitter数据上表现欠佳，以及仅限于同构图，未来可以探索异构图建模以整合多种交互类型。",
      "paper_url": "https://doi.org/10.1007/s11280-022-01116-0",
      "project_url": "https://github.com/gvrkiran/controversy-detection",
      "conference": "World Wide Web",
      "title_translation": "",
      "analogy_summary": "To identify controversial topics from discussion inputs, the method aggregates historical comments into user node features to encode intrinsic user and network attributes, and subsequently applies GNN methods on the user-centric social network to achieve binary classification.\n[翻译] 在争议话题识别中，输入是一段讨论，为了编码用户本身特征和用户网络特征，将用户历史评论聚合为用户节点特征，在以用户为节点的社交网络上，进行GNN方法，实现二分类。",
      "pipeline_image": "figures/HRL-GCN.png",
      "abstract": "Expressed opinions on social media frequently cause a controversy. Controversial content refers to content that attracts different opinions and interrogations, implying interaction between communities. Its automatic identification remains a challenging task. Most of the existing approaches rely on the graph structure of discussion and/or the content of messages but did not deeply explore the recent advances on Graph Neural Network (gnn) to predict if a discussion is controversial or not. This paper aims to combine both user interactions present in the graph structure of a discussion and the discussion text features to detect controversy. We rely on sampling techniques to reduce the size of large graphs and augment the graph training set if needed. Our proposed approach relies then on gnn techniques to encode the initial (or sampled) graph in an embedding vector before performing a graph classification task. We propose two controversy detection strategies. The first one is based on a hierarchical graph representation learning to take advantage of hierarchical relationships that could exist between users. The second one is based on the attention mechanism, which allows each user node to give more or less importance to its neighbors when computing node embeddings. We present different experiments conducted with data sources collected from both Reddit and Twitter to show the applicability of our approach to different social networks. Conducted experiments show the positive impact of combining textual features and structural information in terms of performance and accuracy.",
      "contributor": "",
      "notes": "[引用文]To better capture the dynamics of social polarization in the field of controversial content identification, Benslimane et al. (2023) shift from content-based analysis to a user-centric perspective. They argue that the structural relationships between users and the users' inherent attributes are pivotal for understanding controversy. Unlike traditional methods that treat posts as isolated nodes, their approach constructs a user interaction graph where node representations are derived by aggregating the semantic content of each user’s historical comments. This design encodes complex network information and individual stances into a unified feature space. By employing GNN methods such as Hierarchical Graph Representation Learning (HRL-GCN), the model performs multi-layer aggregation on the graph to capture high-level community structures, demonstrating that the fusion of user features with social interaction patterns provides an effective mechanism for controversy identification in social media.\n[翻译] 为了更好地在争议内容识别领域捕捉社会极化的动态，Benslimane等人 (2023) 的方法从基于内容的分析转变为以用户为中心视角。他们认为，用户之间的结构关系以及用户本身的属性对于理解争议至关重要。与将帖子视为孤立节点的传统方法不同，他们的方法构建了一个用户交互图，其中节点表示通过聚合每个用户历史评论的语义内容得到。这种设计将复杂的网络信息和个人立场编码到了统一的特征空间中。通过采用分层图表示学习（HRL-GCN）等GNN的方法，该模型对图进行多层聚合以捕捉高层级的社区结构，证明了用户特征与社交交互模式的融合为识别社交媒体中的争议识别提供了一种有效的机制。",
      "show_in_readme": true,
      "status": "unread",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1609/icwsm.v19i1.35815",
      "title": "Clustering Internet Memes Through Template Matching and Multi-Dimensional Similarity",
      "authors": "Tygo Bloem, Filip Ilievski",
      "date": "2025-06-07",
      "category": "Multimodal Analysis",
      "summary_motivation": "Existing approaches often rely on static, incomplete databases or single-modality features, failing to capture the dynamic evolution and multi-layered semantics of internet memes.\n[翻译] 现有方法通常依赖静态、不完整的数据库或单一模态特征，难以捕捉互联网模因的动态演化及多层语义。",
      "summary_innovation": "The study introduces a fine-grained multi-dimensional similarity framework and a two-stage strategy that filters weak connections to bootstrap high-purity template clusters, significantly enhancing the efficiency of community detection algorithms like Louvain.\n[翻译] 该研究提出了一种细粒度的多维相似度框架，以及一种两阶段策略，通过过滤弱连接来自举生成高纯度的模版簇，显著提升了Louvain等社区发现算法的效率。",
      "summary_method": "The method constructs adjacency matrices based on form, content, text, and identity features, applying a filtering threshold to simplify the graph structure for robust, low-noise template identification, followed by classifying the remaining samples via similarity matching.\n[翻译] 该方法基于形式、内容、文本和身份特征构建邻接矩阵，应用过滤阈值简化图结构以实现稳健、低噪声的模版识别，随后通过相似度匹配对剩余样本进行分类。",
      "summary_conclusion": "Experimental results demonstrate that this template-based approach achieves superior cluster consistency (0.94) compared to standard baselines, effectively handling diverse meme variants while aligning with human semantic intuition.\n[翻译] 实验结果表明，这种基于模版的方法实现了优于标准基线的聚类一致性（0.94），在有效处理多样化模因变体的同时，与人类的语义直觉保持一致。",
      "summary_limitation": "The framework's performance is contingent on the quality of upstream feature extractors and currently lacks integration with external knowledge graphs to interpret complex cultural metaphors or irony.\n[翻译] 该框架的性能取决于上游特征提取器的质量，且目前缺乏与外部知识图谱的整合以解释复杂的文化隐喻或反讽。",
      "paper_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/35815",
      "project_url": "https://github.com/tygobl/meme-clustering",
      "conference": "ICWSM",
      "title_translation": "",
      "analogy_summary": "Utilizing the Louvain community detection algorithm for meme clustering, the study decomposes similarity into four dimensions (form, visual content, text, and identity) to construct adjacency matrices, and employs a strategy of filtering prior to clustering, followed by matching filtered samples, to enhance efficiency and purity by reducing noise.\n[翻译] 为实现meme的聚类，使用社区发现算法louvain。首先将meme相似度分为4个维度（形式、图义、文本、身份），据其构建邻接矩阵。为提高聚类效率和纯度（降低噪声），采用先过滤，再聚类，最后匹配被过滤样本的方法。",
      "pipeline_image": "figures/meme-clustering.png",
      "abstract": "Meme clustering is critical for toxicity detection, virality modeling, and typing, but it has received little attention in previous research. Clustering similar Internet memes is challenging due to their multimodality, cultural context, and adaptability. Existing approaches rely on databases, overlook semantics, and struggle to handle diverse dimensions of similarity. This paper introduces a novel method that uses template-based matching with multi-dimensional similarity features, thus eliminating the need for predefined databases and supporting adaptive matching. Memes are clustered using local and global features across similarity categories such as form, visual content, text, and identity. Our combined approach outperforms existing clustering methods, producing more consistent and coherent clusters, while similarity-based feature sets enable adaptability and align with human intuition. We make all supporting code publicly available to support subsequent research.",
      "contributor": "",
      "notes": "【meme聚类】[引用文]To address the limitations of static database matching in capturing evolving digital content, Bloem and Ilievski (2025) proposed a template-based clustering framework that deconstructs meme similarity into four fine-grained dimensions: form, visual content, text, and identity. A key innovation is the introduction of a graph filtering mechanism prior to clustering with community detection algorithms. By pruning weak connections in the adjacency matrix, the method simplifies the graph structure to efficiently identify high-purity core templates using the Louvain algorithm. The remaining instances are subsequently re-associated through similarity matching, thereby effectively balancing computational complexity with semantic coherence in tracking meme propagation.\n[翻译] 为了解决静态数据库匹配在捕捉演化数字内容方面的局限性，Bloem和Ilievski (2025) 提出了一种基于模版的聚类框架，将模因相似度解构为形式、视觉内容、文本和身份四个细粒度维度。关键创新是在使用社区发现算法进行聚类之前引入了图过滤机制。通过剪除邻接矩阵中的弱连接，该方法简化了图结构，从而利用Louvain算法高效地识别出高纯度的核心模版。剩余的实例随后通过相似度匹配被重新关联，从而在追踪模因传播时有效平衡了计算复杂度与语义连贯性。",
      "show_in_readme": true,
      "status": "skimmed",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1145/3589334.3648151",
      "title": "MemeCraft: Contextual and stance-driven multimodal meme generation",
      "authors": "Han Wang, Roy Ka-Wei Lee",
      "date": "2024-05-13",
      "category": "Multimodal Analysis;Humor Generation",
      "summary_motivation": "While internet memes have evolved into potent vehicles for social and political discourse, existing generation tools often lack the capability to align content with specific ideological stances or ensure safety against hate speech.\n[翻译] 虽然网络迷因已演变为社会和政治话语的有力载体，但现有的生成工具往往缺乏将内容与特定意识形态立场对齐的能力，也难以确保内容安全以防止仇恨言论。",
      "summary_innovation": "This work proposes a novel framework utilizing off-the-shelf Large Language Models (LLMs) and Visual Language Models (VLMs) to generate advocacy-driven memes without fine-tuning, incorporating a dedicated safety mechanism to mitigate the production of hateful content.\n[翻译] 该工作提出了一个利用现成的多模态大模型（LLMs和VLMs）生成宣传性迷因的新颖框架，无需进行微调，并内置了专门的安全机制以减少仇恨内容的产生。",
      "summary_method": "The authors devise an inference-only pipeline that decouples visual processing from text generation: a VLM first converts meme templates into textual descriptions, which serve as context for an LLM conditioned on structured prompts (e.g., stance, persuasion technique) to synthesize humorous captions.\n[翻译] 作者设计了一个仅推理（inference-only）的流水线，将视觉处理与文本生成解耦：首先由VLM将迷因模板转换为文本描述，随后将其作为上下文，结合结构化提示（如立场、说服技巧）引导LLM合成幽默配文。",
      "summary_conclusion": "Experimental evaluations focusing on UN Sustainable Development Goals demonstrate that the approach, particularly when leveraging ChatGPT, significantly outperforms state-of-the-art baselines in terms of hilarity and persuasiveness, achieving authenticity scores comparable to human-created content.\n[翻译] 针对联合国可持续发展目标的实验评估表明，该方法（尤其是基于ChatGPT的版本）在幽默感和说服力方面显著优于最先进的基线模型，并达到了与人类创作内容相当的真实性评分。",
      "summary_limitation": "A notable limitation lies in the information bottleneck introduced by converting visual data into text descriptions, which may fail to capture fine-grained visual nuances or pixel-level text-image interplay compared to end-to-end multimodal training.\n[翻译] 一个显著的局限性在于将视觉数据转换为文本描述所引入的信息瓶颈，与端到端的多模态训练相比，这种方法可能难以捕捉细粒度的视觉细微差别或像素级的图文互动。",
      "paper_url": "https://dl.acm.org/doi/10.1145/3589334.3648151",
      "project_url": "https://github.com/Social-AI-Studio/MemeCraft",
      "conference": "Proceedings of the ACM Web Conference 2024（WWW '24)",
      "title_translation": "",
      "analogy_summary": "This work presents an end-to-end, training-free meme generator that operates through a sequence of template retrieval, visual description generation, text synthesis via structured prompting, meme composition, and final hate speech detection.\n[翻译] 端到端无训练meme生成器：获得模板->生成模板描述->结构化prompt生成meme文本->组合为meme->仇恨检测。",
      "pipeline_image": "figures/MemeCraft.png",
      "abstract": "Online memes have emerged as powerful digital cultural artifacts in the age of social media, offering not only humor but also platforms for political discourse, social critique, and information dissemination. Their extensive reach and influence in shaping online communities' sentiments make them invaluable tools for campaigning and promoting ideologies. Despite the development of several meme generation tools, there remains a gap in their systematic evaluation and their ability to effectively communicate ideologies. Addressing this, we introduce MemeCraft, an innovative meme generator that leverages large language models (LLMs) and visual language models (VLMs) to produce memes advocating specific social movements. MemeCraft presents an end-to-end pipeline, transforming user prompts into compelling multimodal memes without manual intervention. Conscious of the misuse potential in creating divisive content, an intrinsic safety mechanism is embedded to curb hateful meme production. Our assessment, focusing on two UN Sustainable Development Goals-Climate Action and Gender Equality-shows MemeCraft's prowess in creating memes that are both funny and supportive of advocacy goals. This paper highlights how generative AI can promote social good and pioneers the use of LLMs and VLMs in meme generation.",
      "contributor": "",
      "notes": "[引用文]In the pursuit of deploying generative AI for specific social goals, Wang and Lee [1] introduce MemeCraft, a framework designed to fabricate memes advocating for UN Sustainable Development Goals (e.g., climate action). It functions as an end-to-end, inference-only generation framework where visual semantics are compressed into textual descriptions by a VLM to guide an LLM in generating stance-aligned captions. While this structured prompting approach ensures high controllability and safety in propagating social messages, the reliance on intermediate textual representations instead of joint multimodal embedding implies a potential granularity loss in capturing complex visual-semantic interplay.\n[翻译] 在探索将生成式AI应用于特定社会目标的背景下，Wang和Lee [1] 推出了MemeCraft，这是一个旨在制作倡导联合国可持续发展目标（如气候行动）迷因的框架。这是一个端到端的、仅推理（inference-only）的生成框架，通过VLM将视觉语义压缩为文本描述，进而引导LLM生成与立场一致的配文。虽然这种结构化提示方法在传播社会信息时确保了高度的可控性和安全性，但依赖中间文本表示而非联合多模态嵌入的做法，也意味着在捕捉复杂的视觉-语义交互时可能存在细粒度信息的缺失。",
      "show_in_readme": true,
      "status": "unread",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.18653/v1/2023.emnlp-main.972",
      "title": "Stance Detection on Social Media with Background Knowledge",
      "authors": "Ang Li, Bin Liang, Jingqian Zhao, Bowen Zhang, Min Yang, Ruifeng Xu",
      "date": "2023",
      "category": "User Stance Detection",
      "summary_motivation": "Stance detection often struggles with the brevity and implicit nature of social media texts, where conventional keyword-based retrieval methods frequently introduce noise or fail to capture the underlying sociopoli\n[翻译] 立场检测常受限于社交媒体文本的短小和隐含性，而传统的基于关键词的检索方法往往引入噪声或未能捕捉潜在的社会政治语境。",
      "summary_innovation": "Li et al. (2023) introduce the KASD framework, which categorizes background information into episodic (factual) and discourse (linguistic) knowledge, distinctively utilizing Large Language Models (LLMs) as active semantic filters and paraphrasers rather than mere predictive engines.\n[翻译] Li等人（2023）引入了KASD框架，将背景信息分类为情景知识（事实）和语篇知识（语言），其独特之处在于利用大语言模型（LLM）作为主动的语义过滤器和改写器，而不仅仅是预测引擎。",
      "summary_method": "The methodology operates at the discourse level by utilizing LLMs to expand slang and hashtags into explicit text, and at the episodic level by employing topic modeling with heuristic metrics to retrieve Wikipedia documents for LLM summarization, ultimately fusing both into a structured input for classifica\n[翻译] 语篇层面利用LLM将俚语和标签扩展为明确文本，情景层面利用主题建模和启发式度量检索维基百科文档并由LLM进行总结，最后将两者融合为结构化输入以进行分类。",
      "summary_conclusion": "Experimental results across four benchmarks demonstrate that KASD achieves state-of-the-art performance, with knowledge-augmented fine-tuned models significantly outperforming standard LLMs in both in-target and zero-shot scenarios.\n[翻译] 在四个基准测试上的实验结果表明，KASD取得了最先进的性能，经过知识增强的微调模型在目标内和零样本场景中均显著优于标准LLM。",
      "summary_limitation": "A primary limitation lies in the reliance on pre-crawled Wikipedia dumps, which may inhibit the detection of stances regarding real-time events or breaking news not yet documented in static knowledge bases.\n[翻译] 主要局限性在于依赖预先爬取的维基百科数据，这可能阻碍对静态知识库中尚未记录的实时事件或突发新闻的立场检测。",
      "paper_url": "https://aclanthology.org/2023.emnlp-main.972",
      "project_url": "https://github.com/HITSZ-HLT/KA-Stance-Detection",
      "conference": "EMNLP 2023",
      "title_translation": "",
      "analogy_summary": "A retrieval-augmented stance detection framework that synthesizes LLM-refined Wikipedia facts and linguistic expansions to address the issue of stance implicitness in social media posts.\n[翻译] 检索增强的立场检测框架，通过综合经LLM提炼的维基百科事实和语言扩展信息，来解决社交媒体帖子的立场隐含性问题。",
      "pipeline_image": "figures/KASD.png",
      "abstract": "Identifying users' stances regarding specific targets/topics is a significant route to learning public opinion from social media platforms. Most existing studies of stance detection strive to learn stance information about specific targets from the context, in order to determine the user's stance on the target. However, in real-world scenarios, we usually have a certain understanding of a target when we express our stance on it. In this paper, we investigate stance detection from a novel perspective, where the background knowledge of the targets is taken into account for better stance detection. To be specific, we categorize background knowledge into two categories: episodic knowledge and discourse knowledge, and propose a novel Knowledge-Augmented Stance Detection (KASD) framework. For episodic knowledge, we devise a heuristic retrieval algorithm based on the topic to retrieve the Wikipedia documents relevant to the sample. Further, we construct a prompt for ChatGPT to filter the Wikipedia documents to derive episodic knowledge. For discourse knowledge, we construct a prompt for ChatGPT to paraphrase the hashtags, references, etc., in the sample, thereby injecting discourse knowledge into the sample. Experimental results on four benchmark datasets demonstrate that our KASD achieves state-of-the-art performance in in-target and zero-shot stance detection.",
      "contributor": "",
      "notes": "[方法总结]输入：评论和他的target->输入通过LLM将俚语简写标签扩展为完整内容->对输入进行主题建模，从维基百科中通过主题相似度和内容相似度（与评论）检索出相关知识->相关知识交由LLM进行过滤总结->生成结构化输出模板->使用输出模板进行微调或作为少样本进行立场分类[引用文]To bridge the gap between static text recognition and dynamic context understanding, Li et al. (2023) proposed the Knowledge-Augmented Stance Detection (KASD) framework to address the semantic scarcity of short texts. Their approach simulates a human-like reasoning process on two levels: at the discourse level, it utilizes LLMs to interpret and expand sociolinguistic cues, such as hashtags and slang, into explicit natural language; at the episodic level, it combines topic modeling with heuristic similarity metrics to retrieve relevant Wikipedia documents, which are filtered and summarized by an LLM to extract precise episodic knowledge. By fusing this refined external context with the original input for fine-tuning or few-shot inference, KASD demonstrates that guiding models with structured, retrieved knowledge yields superior performance compared to unguided generation, marking a shift towards more robust, context-aware social computing agents.\n[翻译] 为了弥合静态文本识别与动态语境理解之间的鸿沟，Li等人（2023）提出了知识增强立场检测（KASD）框架，以解决短文本的语义稀缺问题。他们的方法从两个层面模拟了类人的推理过程：语篇层面，利用LLM解释并将标签、俚语等社会语言线索扩展为明确的自然语言；情景层面，结合主题建模与启发式相似度度量检索相关的维基百科文档，并通过LLM进行过滤和总结以提取精确的情景知识。通过将这种提炼后的外部语境与原始输入融合进行微调或少样本推理，KASD证明了利用结构化的检索知识引导模型比无引导的生成具有更优越的性能，这标志着向更鲁棒、具备语境感知能力的社会计算代理的转变。",
      "show_in_readme": true,
      "status": "unread",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1609/icwsm.v18i1.31360",
      "title": "Stance Detection with Collaborative Role-Infused LLM-Based Agents",
      "authors": "Xiaochong Lan, Chen Gao, Depeng Jin, Yong Li",
      "date": "2024-05-28",
      "category": "User Stance Detection",
      "summary_motivation": "In addressing the dual challenges of stance detection—the need for multi-faceted textual comprehension and complex reasoning over implicit stances—this study seeks to move beyond the data dependency of traditional methods and the suboptimal direct application of Large Language Models (LLMs).\n[翻译]\n为解决立场检测中的双重挑战——需要多层面的文本理解能力和对隐含立场的复杂推理——本研究旨在超越传统方法对数据的依赖以及直接应用大语言模型（LLM）的次优表现。",
      "summary_innovation": "The key innovation is the design of a multi-agent system (COLA) that simulates a debate arena, where LLM-based agents advocate for different stances, thereby transforming stance inference into a structured process of adversarial reasoning and collaborative synthesis.\n[翻译]\n其核心创新在于设计了一个模拟辩论场的多智能体系统（COLA），其中基于LLM的智能体为不同立场进行辩护，从而将立场推断转化为一个对抗性推理与协作合成的结构化过程。",
      "summary_method": "The COLA framework operates in three stages: a multi-dimensional analysis by role-specific agents (linguist, domain expert, social media veteran), a reasoning-enhanced debate where dedicated agents argue for ‘Favor’, ‘Against’, or ‘Neutral’ stances, and a final judgment stage that synthesizes all arguments.\n[翻译]\nCOLA框架按三阶段运行：由角色化智能体（语言学家、领域专家、社交媒体资深用户）进行多维度分析；一个推理增强的辩论阶段，由专门智能体为“支持”、“反对”或“中立”立场进行论证；以及一个综合所有论点的最终裁决阶段。",
      "summary_conclusion": "Experimental results demonstrate that this zero-shot, training-free approach achieves state-of-the-art performance, matching or surpassing models trained on in-target labeled data across multiple benchmarks, while providing explainable outputs.\n[翻译]\n实验结果表明，这种零样本、无需训练的方法实现了最先进的性能，在多个基准测试中达到甚至超越了依赖靶向标注数据训练的模型，同时能提供可解释的输出。",
      "summary_limitation": "A primary limitation is the potential inadequacy in handling real-time events due to static LLM knowledge. Future work aims to integrate real-time knowledge retrieval and extend the multi-agent debate paradigm to broader social reasoning tasks.\n[翻译]\n一个主要局限在于，由于LLM知识的静态性，其在处理实时事件时可能存在不足。未来工作旨在集成实时知识检索，并将多智能体辩论范式扩展到更广泛的社会推理任务中。",
      "paper_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/31360",
      "project_url": "https://github.com/tsinghua-fib-lab/COLA",
      "conference": "ICWSM",
      "title_translation": "",
      "analogy_summary": "AMB辩论场模拟（本质上类似高级cot）",
      "pipeline_image": "figures/COLA.png",
      "abstract": "Stance detection automatically detects the stance in a text towards a target, vital for content analysis in web and social media research. Despite their promising capabilities, LLMs encounter challenges when directly applied to stance detection. First, stance detection demands multi-aspect knowledge, from deciphering event-related terminologies to understanding the expression styles in social media platforms. Second, stance detection requires advanced reasoning to infer authors' implicit viewpoints, as stances are often subtly embedded rather than overtly stated in the text. To address these challenges, we design a three-stage framework COLA (short for Collaborative rOle-infused LLM-based Agents) in which LLMs are designated distinct roles, creating a collaborative system where each role contributes uniquely. Initially, in the multidimensional text analysis stage, we configure the LLMs to act as a linguistic expert, a domain specialist, and a social media veteran to get a multifaceted analysis of texts, thus overcoming the first challenge. Next, in the reasoning-enhanced debating stage, for each potential stance, we designate a specific LLM-based agent to advocate for it, guiding the LLM to detect logical connections between text features and stance, tackling the second challenge. Finally, in the stance conclusion stage, a final decision maker agent consolidates prior insights to determine the stance. Our approach avoids extra annotated data and model training and is highly usable. We achieve state-of-the-art performance across multiple datasets. Ablation studies validate the effectiveness of each role design in handling stance detection. Further experiments have demonstrated the explainability and the versatility of our approach. Our approach excels in usability, accuracy, effectiveness, explainability and versatility, highlighting its value.",
      "contributor": "",
      "notes": "【ABM方法】[引用文]Within the exploration of agent-based social interaction and emergent behavior, the work by Lan et al. (2024) constitutes an attempt to transition from static pattern recognition to dynamic, goal-oriented interaction simulation. Their proposed COLA framework transforms stance detection into a process of multi-agent collaborative and adversarial reasoning by constructing a “simulated debate arena” populated by role-infused LLM agents. The framework achieves excellent zero-shot performance without additional data training. Its “analyst-debater-summarizer” architecture mimics the social deliberation involved in opinion formation, serving as a prime example of how structured multi-agent interaction can be harnessed to elicit and regulate complex reasoning capabilities.\n[翻译]\n在探索基于智能体的社会性交互与涌现行为的背景下，Lan等人（2024）的工作进行了从静态模式识别向动态、目标导向交互仿真过渡的尝试。他们提出的COLA框架通过构建一个由角色化大语言模型智能体组成的“模拟辩论场”，将立场检测任务转化为一个多智能体协作推理与对抗辩论的过程。该框架在没有额外数据训练的情况下取得了优异的零样本检测性能。其“分析师-辩论家-总结者”的架构模拟了观点形成过程中的社会性思辨，是通过结构化多智能体交互来激发并规制复杂推理能力的典型例子。",
      "show_in_readme": true,
      "status": "skimmed",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.48550/arXiv.2509.04823",
      "title": "Evaluating cognitive-behavioral fixation via multimodal user viewing patterns on social media",
      "authors": "Yujie Wang, Yunwei Zhao, Jing Yang, Han Han, Shiguang Shan, Jie Zhang",
      "date": "2025-09-05",
      "category": "Social Psychological Phenomena Analysis",
      "summary_motivation": "It addresses the risk of cognitive-behavioral fixation (e.g., echo chambers, compulsive engagement) shaped by algorithmic curation on social media, which lacks scalable computational assessment methods.\n它旨在解决由社交媒体算法策展所引发的认知行为固化（如信息茧房、强迫性参与）风险，该领域此前缺乏可扩展的计算评估方法。",
      "summary_innovation": "It proposes the first computational framework to quantify attention fixation by hierarchically modeling user interests from multimodal data (text and video) and integrating diversity, dominance, and recurrence metrics.\n它首次提出了一个计算框架，通过对多模态数据（文本和视频）进行用户兴趣的层次化建模，并综合多样性、主导性和复现性指标，以量化注意力固化。",
      "summary_method": "The framework first extracts fine-grained topic phrases from multimodal content, then clusters them into higher-level thematic categories to model user attention history. Fixation is quantified by a composite score fusing entropy (diversity), HHI (dominance), and burstiness (recurrence).\n该框架首先从多模态内容中提取细粒度主题短语，随后将其聚类为高层主题类别以建模用户注意力历史。固化程度通过一个融合了熵（多样性）、HHI指数（主导性）和突发性（复现性）的复合分数进行量化。",
      "summary_conclusion": "The method outperforms baselines in topic modeling on multimodal datasets. On a real-world browsing dataset (XUB), it identified 8.59% of users with strong fixation tendencies, validated by human annotations (F1 ≈ 0.857).\n该方法在多模态数据集的主题建模上优于基线。在一个真实浏览数据集(XUB)上，它识别出8.59%的用户具有强固化倾向，并得到了人工标注的验证（F1 ≈ 0.857）。Limitations include modality constraints (lacking audio/interaction data), potential biases from underlying vision-language models, and equal weighting in the composite score awaiting further optimization.\n局限性包括模态限制（缺乏音频/交互数据）、底层视觉-语言模型的潜在偏差，以及复合分数中等权设置有待进一步优化。",
      "summary_limitation": "Limitations include modality constraints (lacking audio/interaction data), potential biases from underlying vision-language models, and equal weighting in the composite score awaiting further optimization.\n局限性包括模态限制（缺乏音频/交互数据）、底层视觉-语言模型的潜在偏差，以及复合分数中等权设置有待进一步优化。",
      "paper_url": "http://arxiv.org/abs/2509.04823",
      "project_url": "https://github.com/Liskie/cognitive-fixation-evaluation",
      "conference": "EMNLP 2025（arxiv版本）",
      "title_translation": "",
      "analogy_summary": "固化检测，评估用户注意力是否集中于狭窄领域，因此主要先对用户关注历史主题建模，然后聚类",
      "pipeline_image": "figures/CBF-Eval.png",
      "abstract": "Digital social media platforms frequently contribute to cognitive-behavioral fixation, a phenomenon in which users exhibit sustained and repetitive engagement with narrow content domains. While cognitive-behavioral fixation has been extensively studied in psychology, methods for computationally detecting and evaluating such fixation remain underexplored. To address this gap, we propose a novel framework for assessing cognitive-behavioral fixation by analyzing users' multimodal social media engagement patterns. Specifically, we introduce a multimodal topic extraction module and a cognitive-behavioral fixation quantification module that collaboratively enable adaptive, hierarchical, and interpretable assessment of user behavior. Experiments on existing benchmarks and a newly curated multimodal dataset demonstrate the effectiveness of our approach, laying the groundwork for scalable computational analysis of cognitive fixation. All code in this project is publicly available for research purposes at https://github.com/Liskie/cognitive-fixation-evaluation.",
      "contributor": "",
      "notes": "[引用文]To computationally assess how platform algorithms may narrow user attention, Wang et al. (2025) propose a novel framework for evaluating cognitive-behavioral fixation. They first employ multimodal hierarchical topic modeling to extract and cluster thematic interests from users' viewing histories. Then, they quantify fixation by integrating metrics of topical diversity, dominance, and temporal recurrence into a unified score. Validated on a dedicated dataset, this approach provides an interpretable measure for identifying users trapped in narrow engagement loops, offering a tool for individual-level behavioral modeling within larger social simulations.\n[翻译]\n为了从计算角度评估平台算法如何收窄用户注意力，Wang等人(2025)提出了一个评估认知行为固化的新框架。他们首先采用多模态分层主题建模，从用户的浏览历史中提取并聚类主题兴趣。然后，通过将主题多样性、主导性和时间复现性指标整合为一个统一分数来量化固化程度。该方法在专用数据集上得到验证，为识别陷入狭窄参与循环的用户提供了一个可解释的度量，为在更大规模社会仿真中进行个体层面的行为建模提供了工具。",
      "show_in_readme": true,
      "status": "unread",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1007/s42979-024-03055-1",
      "title": "Behavior Based Group Recommendation from Social Media Dataset by Using Deep Learning and Topic Modeling",
      "authors": "Md. Saddam Hossain Mukta, Jubaer Ahmed, Mohaimenul Azam Khan Raiaan, Nur Mohammad Fahad, Muhammad Nazrul Islam, Nafiz Imtiaz, ...",
      "date": "2024-07-16",
      "category": "Community Detection;User Profiling",
      "summary_motivation": "This research addresses the underexplored task of identifying user groups based on shared psychological attributes, proposing that similarity in Basic Human Values, derived from social media, can predict aligned real-world behaviors.\n\n[翻译]\n本研究旨在解决一个未被充分探索的任务：基于共享的心理属性识别用户群体，并提出从社交媒体衍生的基本人类价值观的相似性可以预测一致的真实世界行为。",
      "summary_innovation": "Its novelty lies in fusing graph neural networks with psycholinguistic analysis to model user values (e.g., hedonism) for group recommendation, introducing both graph-based (GHV) and context-psychological (CPHV) clustering methods.\n\n[翻译]\n其创新点在于融合图神经网络与心理语言分析，为用户价值观（如快乐主义）建模以进行群体推荐，并引入了基于图的（GHV）和上下文-心理的（CPHV）两种聚类方法。",
      "summary_method": "The methodology employs two parallel tracks: GHV uses GNNs and spectral clustering on user value scores, while CPHV further integrates topic modeling (LSA/BERT) and psychological lexicon (LIWC) analysis to refine group identification.\n\n[翻译]\n该方法采用双轨并行：GHV在用户价值分数上应用GNN和谱聚类，而CPHV进一步整合主题建模（LSA/BERT）和心理词典（LIWC）分析以优化群体识别。",
      "summary_conclusion": "The proposed CPHV method achieved superior clustering performance (SCC: 76%, ICC: 60%), validating that users grouped by high hedonism scores share common interests in areas like movies and technology.\n\n[翻译]\n所提出的CPHV方法取得了优越的聚类性能（SCC：76%，ICC：60%），验证了按高快乐主义分数分组的用户在电影、技术等领域具有共同的兴趣。",
      "summary_limitation": "Limitations include reliance on sufficient digital footprints and a static view of values. Future work suggests dynamic modeling and extension to other value dimensions and platforms.\n\n[翻译]\n局限性包括对足够数字足迹的依赖和对价值观的静态审视。未来工作建议进行动态建模，并将方法扩展到其他价值维度与平台。",
      "paper_url": "https://link.springer.com/10.1007/s42979-024-03055-1",
      "project_url": "",
      "conference": "Sn Comput. Sci.",
      "title_translation": "",
      "analogy_summary": "TLDR: A graph dataset is compiled using the strongest correlation among the features and then a graph clustering technique is applied to identify a suitable hedonist group (i.e., one dimension of values) for users’ recommendations, which is validated in real life by introducing two hypotheses.",
      "pipeline_image": "figures/BBGR.png;figures/BBGR-GHV.png;figures/BBGR-CPHV.png",
      "abstract": "Abstract\n            \n              In this digital era, users frequently share their thoughts, preferences, and ideas through social media, which reflect their Basic Human Values. Basic Human Values (aka values) are the fundamental aspects of human behavior, which define what we consider important, and worth having and pursue them. Existing studies identify the values of individuals from different social network usages such as Facebook and Reddit. However, discovering the similarity (or diversity) of value priorities among the members in a group is important since we can reveal many interesting insights such as finding a set of target customers, identifying the chain of misdeed groups, searching for similar acquaintances in workplaces, etc. In this paper, a graph dataset is compiled using the strongest correlation among the features and then we apply a graph clustering technique to identify a suitable hedonist group (i.e., one dimension of values) for users’ recommendations. Then, we also propose a behavior based (i.e., value ) group recommendation technique by analyzing users’ contextual and psychological attributes. Finally, we validate those group members in real life by introducing two hypotheses. In particular, we analyze the tweets of a total of 1140 users collected from Twitter. We obtain a substantial\n              intra-cluster correlation coefficient (ICC)\n              and\n              silhouette clustering coefficient (SCC)\n              scores of 65% and 76%, respectively, among the members in our discovered group.",
      "contributor": "",
      "notes": "[引用文]Mukta et al. (2024) advance beyond surface-level analytics by modeling the latent psychological attributes of users, specifically their Basic Human Values, from social media traces. Their fusion of GNNs with psychometric analysis exemplifies a shift towards cognitive-level understanding of user collectives, forming a crucial bridge between pattern recognition and the simulation of motivation-driven group behaviors.\n[翻译]\nMukta等人（2024）通过从社交媒体痕迹中建模用户的潜在心理属性（特别是其基本人类价值观），推进了超越表层分析的研究。他们将GNN与心理测量分析相融合，例证了向认知层面理解用户集体的转变，这在模式识别与动机驱动的群体行为仿真之间构成了关键的桥梁。",
      "show_in_readme": true,
      "status": "unread",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.0000/placeholder-PASUM",
      "title": "PASUM: A pre-training architecture for social media user modeling based on text graph",
      "authors": "Kun Wu, Xinyi Mou, Lanqing Xue, Zhenzhe Ying, Weiqiang Wang, Qi Zhang, Xuanjing Huang, Zhongyu Wei",
      "date": "2024-05",
      "category": "User Profiling",
      "summary_motivation": "To overcome the limitations of existing methods that struggle with lengthy user texts and the unavailability of explicit social graphs, this work addresses the challenge of learning generalizable user representations without relying on complete social network data.\n\n[翻译] 为克服现有方法在处理用户长文本和显式社交图谱缺失时的局限性，本工作旨在解决不依赖完整社交网络数据而学习可泛化用户表示的挑战。",
      "summary_innovation": "Its core innovation lies in an inductive pre-training architecture that represents users solely via personal text graphs and injects social structural awareness through inter-user and intra-user contrastive learning, eliminating the need for explicit social network input during inference.\n\n[翻译] 其核心创新在于一个归纳式预训练架构：仅通过个人文本图表征用户，并借助用户间与用户内对比学习注入社交结构感知，从而在推理时无需显式的社交网络输入。",
      "summary_method": "The PASUM framework first constructs a text graph from each user's microblogs. It then employs a Graph Isomorphism Network (GIN) to encode the graph into a user representation. Finally, it pre-trains the encoder using contrastive loss functions defined over user pairs (based on follow relations) and subgraph pairs (based on community membership).\n\n[翻译] PASUM框架首先从每位用户的微博构建文本图，随后使用图同构网络（GIN）将图表编码为用户表示，最后利用基于用户对（关注关系）和子图对（社区归属）定义的对比损失函数对编码器进行预训练。",
      "summary_conclusion": "Extensive experiments on user profiling tasks demonstrate that PASUM outperforms text-based and graph-based baselines, particularly showing robustness when social connections are sparse or absent, validating the effectiveness of its structure-infused pre-training.\n\n[翻译] 在多个用户画像任务上的实验表明，PASUM优于基于文本和基于图的方法基线，尤其在社交连接稀疏或缺失时表现出鲁棒性，验证了其融入结构的预训练策略的有效性。",
      "summary_limitation": "Limitations include mediocre few-shot performance and reliance solely on network-derived structural signals. Future work could integrate multimodal user behaviors and attributes to enrich the pre-training paradigm.\n\n[翻译] 其局限性包括小样本学习性能一般，且仅依赖于网络衍生的结构信号。未来工作可整合多模态用户行为与属性，以丰富预训练范式。",
      "paper_url": "https://aclanthology.org/2024.lrec-main.1107/",
      "project_url": "",
      "conference": "LREC-COLING 2024",
      "title_translation": "",
      "analogy_summary": "利用关注图网络的结构进行自监督训练（不同用户间对比学习，同用户不同社群间对比学习），使用词图结构聚合为用户表征，尝试解决长文本问题",
      "pipeline_image": "figures/PASUM.png",
      "abstract": "Modeling social media users is the core of social governance in the digital society. Existing works have incorporated different digital traces to better learn the representations of social media users, including text information encoded by pre-trained language models and social network information encoded by graph models. However, limited by overloaded text information and hard-to-collect social network information, they cannot utilize global text information and cannot be generalized without social relationships. In this paper, we propose a Pre-training Architecture for Social Media User Modeling based on Text Graph(PASUM). We aggregate all microblogs to represent social media users based on the text graph model and learn the mapping from microblogs to user representation. We further design inter-user and intra-user contrastive learning tasks to inject general structural information into the mapping. In different scenarios, we can represent users based on text, even without social network information. Experimental results on various downstream tasks demonstrate the effectiveness and superiority of our framework.",
      "contributor": "",
      "notes": "[note]关注网络的网络关系只是实现了训练数据的标注，并不是将整个图输入模型，**这相当于将图拓扑信息蒸馏到了非GNN模型中**。预训练时用户的特征表示也是词图聚合得到的。[引用文]In a technical approach to user modeling that does not require a global social graph at inference time, PASUM (Wu et al., 2024) pre-trains a user encoder by leveraging social network data only to generate supervision signals. The model processes a user's aggregated microblogs as a local text graph, and during pre-training, it is optimized so that its output representations satisfy constraints derived from follow networks (homophily) and community memberships (multi-faceted roles). This approach achieved superior accuracy on several downstream profiling tasks compared to methods that directly input social adjacency matrices, demonstrating the efficacy of distilling structural information into the model parameters via contrastive learning.\n\n[翻译] 作为一种在推理时无需全局社交图谱的用户建模技术方案，PASUM (Wu et al., 2024) 预训练用户编码器的方法仅利用社交网络数据来生成监督信号。该模型将用户聚合的微博处理为局部文本图，并在预训练期间进行优化，使其输出的表示满足源自关注网络（同质性）和社区归属（多面角色）的约束。与直接输入社交邻接矩阵的方法相比，该方法在多个下游画像任务上取得了更高的准确率，证明了通过对比学习将结构信息蒸馏到模型参数中的有效性。",
      "show_in_readme": true,
      "status": "skimmed",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1609/icwsm.v19i1.35813",
      "title": "Susceptibility of Communities Against Low-Credibility Content in Social News Websites",
      "authors": "Yigit Ege Bayiz, Arash Amini, Radu Marculescu, Ufuk Topcu",
      "date": "2025-06-07",
      "category": "Community Detection;Misinformation Analysis",
      "summary_motivation": "The proliferation of low-credibility and highly biased content on social news platforms like Reddit necessitates moving beyond individual fake-news detection to understanding systemic vulnerabilities at the community level. This study is motivated by the need to identify ideological communities that are particularly susceptible to such content.\n[翻译]\nReddit等社交新闻平台上低可信度和高偏见内容的泛滥，要求研究超越个体假新闻检测，转向理解社区层面的系统性脆弱性。本研究旨在识别对此类内容特别易感的意识形态社区。",
      "summary_innovation": "Its primary innovation lies in a novel framework that detects ideological communities based on user stance-aware embeddings, rather than platform-defined groups. It uniquely combines fine-tuned LLM-based stance detection, a learned affine transformation for contrary opinions, and spectral clustering to map communities onto a credibility-bias space for susceptibility analysis.\n[翻译]\n其主要创新在于一个新颖的框架，该框架基于用户立场感知嵌入而非平台定义的群组来检测意识形态社区。它独特地结合了基于微调LLM的立场检测、用于相反观点的仿射变换学习以及谱聚类，将社区映射到可信度-偏见空间以进行易感性分析。",
      "summary_method": "The methodology first embeds post titles via SBERT. It then employs a LoRA-tuned LLM to detect user stances (favor/against/neutral) in comments relative to parent posts. Comment embeddings are assigned based on these stances, using the post embedding or its learned affine-transformed negation. User embeddings are derived by averaging their comment embeddings. User-level credibility and bias scores are similarly aggregated from stance-adjusted scores of news sources (per Ad Fontes Media). Finally, spectral clustering on user embeddings reveals communities, whose susceptibility is profiled via the aggregated scores.\n[翻译]\n该方法首先通过SBERT嵌入帖子标题，然后使用经LoRA微调的大语言模型检测评论中用户相对于父帖的立场（支持/反对/中立）。根据这些立场，使用帖子嵌入或其学习到的仿射变换否定结果为评论分配嵌入向量。通过对用户的评论嵌入取平均得到用户嵌入。用户级的可信度与偏见分数以类似方式，根据立场调整后的新闻源分数进行聚合。最后，对用户嵌入进行谱聚类以揭示社区，并通过聚合分数分析其易感性。",
      "summary_conclusion": "The study demonstrates significant variance in susceptibility across the identified ideological clusters. For instance, the proportion of users prone to low-credibility content differed by 34 percentage points between the most and least susceptible clusters. A correlation was observed between the constructed user embedding space and the credibility-bias space, indicating that latent representations capture susceptibility-related features.\n[翻译]\n研究表明，所识别的不同意识形态聚类之间的易感性存在显著差异。例如，对低可信度内容易感的用户比例在最具易感性和最不具易感性的聚类间相差34个百分点。研究观察到构建的用户嵌入空间与可信度-偏见空间之间存在相关性，表明潜在表征捕捉到了与易感性相关的特征。",
      "summary_limitation": "Limitations include reliance on a single external source for news credibility/bias labels, potential platform-specific biases in the Reddit dataset, and the inherent assumption equating opposition to high-credibility content with low-credibility preference. Future work suggests incorporating comment semantics and user interaction graphs for richer embeddings.\n[翻译]\n局限性包括依赖单一外部来源进行新闻可信度/偏见标注、Reddit数据集中可能存在的平台特定偏见，以及将反对高可信度内容等同于偏好低可信度内容的内在假设。未来工作建议融入评论语义和用户交互图以获得更丰富的嵌入表征。",
      "paper_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/35813",
      "project_url": "",
      "conference": "ICWSM",
      "title_translation": "",
      "analogy_summary": "This work presents a computational framework for identifying and profiling ideological communities on social news platforms based on their susceptibility to low-credibility and biased content, using stance-derived user embeddings.\n[翻译]\n本研究提出了一个计算框架，利用立场导出的用户嵌入，来识别社交新闻平台上的意识形态社区并刻画其对于低可信度和偏见内容的易感性特征。",
      "pipeline_image": "figures/SC-LCC.png",
      "abstract": "Social news websites, such as Reddit, have evolved into prominent platforms for sharing and discussing news. A key issue on social news websites is the formation of low-credibility communities, which often lead to the spread of highly biased or uncredible news. We develop a method to identify communities prone to uncredible or highly biased news within a social news website. We employ a user embedding pipeline that detects user communities based on their stances toward posts and news sources. We then project each community onto a credibility-bias space and analyze the distributional characteristics of each projected community to identify those that have a high risk of adopting beliefs with low credibility or high bias. This approach also enables the prediction of individual users' susceptibility to low-credibility content based on their community affiliation. Our results show that latent space clusters effectively indicate the credibility and bias levels of their users, with significant variance observed across clusters---a 34% difference in the users' susceptibility to low-credibility content and a 8.3% difference in the users' susceptibility to high political bias.",
      "contributor": "",
      "notes": "【使用**立场检测**得到用户嵌入、然后**谱聚类用于社区分析**】[方法概括]\n1.帖子进行embedding获得特征向量，帖子的所有回复进行相对于帖子的立场检测。2.为评论分配特征向量（相同同帖子，相反为仿射，中立为均值）。3.对每个用户的所有评论进行特征聚合得到用户特征向量（特征向量只用于聚类）。4.通过比较源媒体数据为帖子内容分配可信度和偏见分数，根据对应评论的立场为其分配两个值，同样的聚合得到用户两值。5.根据用户特征向量进行聚类，结合用户两值获得聚类的两值，进行分析[引用文]Situated within the evolving scholarly focus that bridges pattern recognition and the simulation of collective social dynamics, Bayiz et al. (2025) shift the unit of analysis from individual users or sources to ideological communities to study their susceptibility to misinformation. This is achieved by constructing stance-aware user embeddings—where the stance of comments towards posts, identified via stance detection, is used to infer latent representations—followed by the application of spectral clustering to discover communities based on ideological alignment. They examine these communities within a credibility-bias space, revealing significant inter-community differences in susceptibility to misinformation\n[翻译]\n置于连接模式识别与集体社会动态仿真的学术演进焦点中，Bayiz等人（2025）将分析单元从个体用户或信源转向意识形态社区，以研究其对错误信息的易感性。这是通过构建立场感知的用户嵌入来实现的——其中，通过立场检测识别出的评论对帖子的立场被用于推断潜在表征——随后应用谱聚类来发现基于意识形态一致性的社区。他们在可信度-偏见空间中研究这些社区，揭示了对错误信息易感性的显著社群间差异。",
      "show_in_readme": true,
      "status": "skimmed",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.48550/arXiv.2504.10157",
      "title": "SocioVerse: A world model for social simulation powered by LLM agents and a pool of 10 million real-world users",
      "authors": "Xinnong Zhang, Jiayu Lin, Xinyi Mou, Shiyue Yang, Xiawei Liu, Libo Sun, Hanjia Lyu, Yihang Yang, Weihong Qi, Yue Chen, Guanying Li, ...",
      "date": "2025-07-15",
      "category": "Social Simulation",
      "summary_motivation": "",
      "summary_innovation": "",
      "summary_method": "",
      "summary_conclusion": "",
      "summary_limitation": "",
      "paper_url": "http://arxiv.org/abs/2504.10157",
      "project_url": "https://github.com/FudanDISC/SocioVerse",
      "conference": "",
      "title_translation": "",
      "analogy_summary": "TLDR: SocioVerse is introduced, an LLM-agent-driven world model for social simulation that can reflect large-scale population dynamics while ensuring diversity, credibility, and representativeness through standardized procedures and minimal manual adjustments.",
      "pipeline_image": "figures/SocioVerse.png",
      "abstract": "Social simulation is transforming traditional social science research by modeling human behavior through interactions between virtual individuals and their environments. With recent advances in large language models (LLMs), this approach has shown growing potential in capturing individual differences and predicting group behaviors. However, existing methods face alignment challenges related to the environment, target users, interaction mechanisms, and behavioral patterns. To this end, we introduce SocioVerse, an LLM-agent-driven world model for social simulation. Our framework features four powerful alignment components and a user pool of 10 million real individuals. To validate its effectiveness, we conducted large-scale simulation experiments across three distinct domains: politics, news, and economics. Results demonstrate that SocioVerse can reflect large-scale population dynamics while ensuring diversity, credibility, and representativeness through standardized procedures and minimal manual adjustments.",
      "contributor": "",
      "notes": "",
      "show_in_readme": true,
      "status": "unread",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1609/icwsm.v18i1.31304",
      "title": "The persuasive power of large language models",
      "authors": "Simon Martin Breum, Daniel Vædele Egdal, Victor Gram Mortensen, Anders Giovanni Møller, Luca Maria Aiello",
      "date": "2024-05-28",
      "category": "Social Bots;Other",
      "summary_motivation": "",
      "summary_innovation": "",
      "summary_method": "",
      "summary_conclusion": "",
      "summary_limitation": "",
      "paper_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/31304",
      "project_url": "",
      "conference": "ICWSM",
      "title_translation": "",
      "analogy_summary": "TLDR: 显示了SIRS过程在具有大型扩展子图的图（例如社交网络模型）上的生存时间的阈值行为，显示了随机图的严格阈值。",
      "pipeline_image": "figures/Persuasive-Power1.png;figures/Persuasive-Power2.png",
      "abstract": "The increasing capability of Large Language Models to act as human-like social agents raises two important questions in the area of opinion dynamics. First, whether these agents can generate effective arguments that could be injected into the online discourse to steer the public opinion. Second, whether artificial agents can interact with each other to reproduce dynamics of persuasion typical of human social systems, opening up opportunities for studying synthetic social systems as faithful proxies for opinion dynamics in human populations. To address these questions, we designed a synthetic persuasion dialogue scenario on the topic of climate change, where a 'convincer' agent generates a persuasive argument for a 'skeptic' agent, who subsequently assesses whether the argument changed its internal opinion state. Different types of arguments were generated to incorporate different linguistic dimensions underpinning psycho-linguistic theories of opinion change. We then asked human judges to evaluate the persuasiveness of machine-generated arguments. Arguments that included factual knowledge, markers of trust, expressions of support, and conveyed status were deemed most effective according to both humans and agents, with humans reporting a marked preference for knowledge-based arguments. Our experimental framework lays the groundwork for future in-silico studies of opinion dynamics, and our findings suggest that artificial agents have the potential of playing an important role in collective processes of opinion formation in online social media.",
      "contributor": "",
      "notes": "",
      "show_in_readme": true,
      "status": "unread",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1609/aaai.v39i27.35032",
      "title": "Pre-trained Behavioral Model for Malicious User Prediction on Social Platform",
      "authors": "Meng Jiang, Wenjie Wang, Shaofeng Hu, Kaishen Ou, Zhenjing Zheng, Fuli Feng",
      "date": "2025-04-11",
      "category": "Malicious User Detection",
      "summary_motivation": "Current supervised methods heavily rely on scarce labeled data, while existing self-supervised approaches often fail to capture complex repetitive and sporadic camouflaged patterns in user behavior sequences.\n[翻译] 现有的监督学习方法严重依赖稀缺的标注数据，而现有的自监督方法往往难以捕捉用户行为序列中复杂的重复性模式和零星的伪装模式。",
      "summary_innovation": "Distinct from content-based approaches, this work focuses exclusively on user behavior sequences, introducing behavior consistency and local disruption augmentations to specifically target repetitive and sporadic malicious patterns.\n[翻译] 与基于内容的方法不同，该工作专注于用户行为序列，引入了行为一致性增强和局部破坏增强策略，专门针对重复性和零星的恶意行为模式。",
      "summary_method": "The framework employs a three-stage self-supervised pre-training pipeline based on BERT, integrating masked behavior reconstruction, contrastive learning for pattern recognition, and a pseudo-malicious user sampling strategy to refine representations.\n[翻译] 该框架采用基于BERT的三阶段自监督预训练流程，集成了掩码行为重建、用于模式识别的对比学习以及伪恶意用户采样策略以优化特征表示。",
      "summary_conclusion": "Evaluated on a billion-scale industrial dataset from Weixin, the model demonstrates superior performance in both malicious user detection and classification tasks compared to graph-based and sequence-based baselines, particularly in cold-start scenarios.\n[翻译] 在微信的十亿级工业数据集上进行的评估显示，该模型在恶意用户检测和分类任务中均表现出优于基于图和基于序列的基线模型的性能，尤其是在冷启动场景下。",
      "summary_limitation": "The current iteration relies solely on behavior ID sequences, neglecting potential semantic information from generated content and structural signals from social interaction graphs.\n[翻译] 当前版本仅依赖于行为ID序列，忽略了生成内容中潜在的语义信息以及社交互动图中的结构性信号。",
      "paper_url": "https://ojs.aaai.org/index.php/AAAI/article/view/35032",
      "project_url": "",
      "conference": "AAAI",
      "title_translation": "",
      "analogy_summary": "MaP is a self-supervised pre-training framework designed to extract robust representations of malicious users by modeling repetitive and sporadic anomalies in behavior sequences without relying on content analysis.\n[翻译] MaP是一个自监督预训练框架，旨在通过对行为序列中的重复性和零星异常进行建模来提取鲁棒的恶意用户表示，而不依赖于内容分析。",
      "pipeline_image": "figures/MaP.png",
      "abstract": "The proliferation of malicious users on social platforms poses significant financial and psychological threats, with activities ranging from scams to the dissemination of illicit content. Existing malicious user prediction comprises supervised and self-supervised learning methods. However, the former relies on extensive labeled malicious users for training, while the latter typically focuses on one form of malicious activity and depends heavily on manually crafted rules and features during pre-training. Moreover, existing pre-training methods fail to effectively capture the crucial repetitive and sporadic behavior patterns of malicious users. To address these limitations, we propose a Malicious User Behavior Pre-training framework (MaP) to build pre-trained behavior models. MaP integrates malicious pattern recognition with behavior consistency augmentation and local disruption augmentation strategies for contrastive learning to capture repetitive and sporadic malicious patterns, respectively. We instantiate MaP on a billion-level behavior pre-training scenario within an industry context. Both online and offline evaluations validate the superior performance of MaP in malicious user detection and classification.",
      "contributor": "",
      "notes": "【恶意用户分析（基于行为模式）】[引用文]To address the limitations of content reliance and the scarcity of labeled data in anomaly detection, Jiang et al. (2025) proposed the Malicious User Behavior Pre-training framework (MaP). Instead of modeling user-generated content, this approach focuses exclusively on discerning patterns within user behavior sequences. The authors introduced a three-stage self-supervised learning pipeline that incorporates specific augmentation strategies—namely behavior consistency and local disruption—to capture two distinct categories of malicious activities: repetitive automated behaviors and sporadic, camouflaged actions. By leveraging a pseudo-malicious user sampling strategy, the model effectively generates discriminative user representations from billion-scale unlabeled data, significantly enhancing detection performance in downstream tasks compared to traditional sequence modeling approaches.[翻译]\n为了解决异常检测中对内容的依赖以及标注数据稀缺的局限性，Jiang等人 (2025) 提出了恶意用户行为预训练框架 (MaP)。该方法不单纯对用户生成的内容进行建模，而是专注于识别用户行为序列中的模式。作者引入了一个三阶段的自监督学习流程，结合了特定的增强策略——即行为一致性和局部破坏——以捕捉两类截然不同的恶意活动：重复的自动化行为和零星的、经过伪装的行动。通过利用伪恶意用户采样策略，该模型有效地从十亿级无标签数据中生成了具有判别力的用户表示，与传统的序列建模方法相比，显著提升了下游任务中的检测性能。",
      "show_in_readme": true,
      "status": "skimmed",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1109/TNSE.2024.3523300",
      "title": "Predicting Participation Shift of Users at the Next Stage in Social Networks",
      "authors": "Yichao Zhang, Zejian Wang, Huangxin Zhuang, Lei Song, Guanghui Wen, Jihong Guan, Shuigeng Zhou",
      "date": "2025-03",
      "category": "User Behavior Prediction;Information Diffusion Analysis",
      "summary_motivation": "Addresses the granularity gap in diffusion analysis by shifting focus from macro-level popularity prediction to micro-level participation shift prediction (i.e., identifying specific users transitioning from listeners to spreaders at the next timestamp), particularly under data-sparse \"cold start\" conditions.\n[翻译] 解决了传播分析中的粒度差距问题，将关注点从宏观流行度预测转移到微观层面的参与转变预测（即识别在下一时间戳从听众转变为传播者的具体用户），特别是在数据稀疏的“冷启动”条件下。",
      "summary_innovation": "Proposes an unsupervised Triple Ranking (TR) framework that integrates physics-inspired Social Gravity with temporal and sequential features, interpreting information cascades not merely as similarity measures but as dynamic activation signals that exert \"gravitational forces\" on potential candidates.\n[翻译] 提出了一种无监督的三重排名（TR）框架，该框架将受物理学启发的社会引力与时间和序列特征相结合，不仅将信息级联视为相似性度量，更将其视为对潜在候选人施加“引力”的动态激活信号。",
      "summary_method": "Decomposes the diffusion lifecycle into discrete stages and calculates three rankings for candidates: Exposure Time Ranking (based on response latency distributions derived from cascade timestamps), Social Gravity Ranking (modeling influence as physical forces from active neighbors in the cascade subgraph), and Cascade Similarity Ranking (learning latent user correlations via Skip-gram embeddings), which are fused linearly or via Graph Neural Networks (T-GCN/T-GAT).\n[翻译] 将传播生命周期分解为离散阶段，并为候选人计算三种排名：曝光时间排名（基于从级联时间戳导出的响应延迟分布）、社会引力排名（将影响力建模为级联子图中活跃邻居的物理作用力）和级联相似度排名（通过Skip-gram嵌入学习潜在的用户相关性），这些排名通过线性加权或图神经网络（T-GCN/T-GAT）进行融合。",
      "summary_conclusion": "Experimental evaluations on three Twitter datasets (Higgs, Munmun, Virality2013) demonstrate that the unsupervised TR model and its supervised variants consistently outperform probabilistic baselines (IC, DT, GT) and state-of-the-art GNNs (DeepInf) in Precision, Recall, and F1-Measure, with significantly reduced computational complexity.\n[翻译] 在三个Twitter数据集（Higgs, Munmun, Virality2013）上的实验评估表明，无监督TR模型及其有监督变体在精确率、召回率和F1值上均优于概率基线（IC, DT, GT）和最先进的GNN模型（DeepInf），且计算复杂度显著降低。",
      "summary_limitation": "The model currently relies exclusively on topological structure and temporal traces, neglecting semantic information (textual content) and assuming a static underlying network topology without accounting for structural evolution over time.\n[翻译] 该模型目前仅依赖拓扑结构和时间轨迹，忽略了语义信息（文本内容），且假设底层网络拓扑是静态的，未考虑结构随时间的演化。",
      "paper_url": "https://ieeexplore.ieee.org/document/10829773/",
      "project_url": "",
      "conference": "IEEE Trans. Netw. Sci. Eng.",
      "title_translation": "",
      "analogy_summary": "一个参与可能性排序算法，综合曝光时间排名、社会引力排名（借用万有引力思想）、级联相似度排名（与历史级联中的其他用户特征对比）",
      "pipeline_image": "figures/TR-1.png;figures/TR-2.png",
      "abstract": "In online social networks, numerous studies have demonstrated the challenge of predicting who will eventually engage in an information cascade with its initial part. Take a step back. Can we predict who will engage in the cascade at the next stage if the lifetime of cascades is divided into a certain number of stages? Although numerous attempts have been made to solve this problem, how to extract useful information from the historical cascades spreading within a sub-network and the connections among users remains an open question. This paper proposes a simple but efficient unsupervised agent-based model, the triple ranking model, which integrates exposure time ranking, social gravity ranking, and cascade similarity ranking. The rankings, a key component of our model, have been successful in characterizing the social impact of shifted users, temporal information, and sequential cascade information, demonstrating the generalizability of our approach. To test the contributions of the features in supervised frameworks, we fuse them with two graph neural networks, the graph convolutional network (GCN) and graph attention network (GAT). Our experimental results on three Twitter networks unequivocally show that the proposed algorithm outperforms the tested state-of-art algorithms across a series of performance metrics. Notably, its time complexity is also lower than theirs, further underscoring its superiority. The observations demonstrate that the rankings effectively abstract the features hidden in the information cascades and in the topology of social networks, paving the way for further studies on posting engagement.",
      "contributor": "",
      "notes": "【用户参与行为预测（方法），下一阶段会有哪些用户成为传播者（应用）】【也是一个不关注内容的，只关注级联图结构（包含时间）】[引用文]To understand the micro-dynamics of propagation, Zhang et al. [2025] move beyond static topological analysis to predict participation shifts at specific cascade stages. Their Triple Ranking (TR) model treats information cascades as dynamic subgraphs that actively influence the underlying user network. By introducing a physics-inspired Social Gravity mechanism, the method quantifies the cumulative impact of active neighbors on candidates as a resultant force, integrated with Exposure Time distributions and Cascade Similarity embeddings. This approach effectively addresses the cold-start problem in behavior prediction by fusing these structural and temporal signals into a unified ranking system, demonstrating that agent-based heuristics can effectively capture diffusion probabilities without extensive supervised training.\n[翻译] 为了理解传播的微观动态，Zhang等人 [2025] 超越了静态拓扑分析，转而预测特定级联阶段的参与转变。他们的三重排名（TR）模型将信息级联视为主动影响底层用户网络的动态子图。通过引入受物理学启发的社会引力机制，该方法将活跃邻居对候选人的累积影响量化为合力，并与曝光时间分布和级联相似度嵌入相结合。该方法通过将这些结构和时间信号融合到一个统一的排名系统中，有效解决了行为预测中的冷启动问题，证明了基于智能体的启发式方法无需大量监督训练即可有效捕捉传播概率。",
      "show_in_readme": true,
      "status": "skimmed",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1145/3581783.3612569",
      "title": "Multi-modal social bot detection: Learning homophilic and heterophilic connections adaptively",
      "authors": "Shilong Li, Boyu Qiao, Kun Li, Qianqian Lu, Meng Lin, Wei Zhou",
      "date": "2023-10-26",
      "category": "Malicious User Detection",
      "summary_motivation": "Existing graph-based detection methods largely rely on the homophily assumption, often failing to address relation camouflage, where bots establish heterophilic connections with humans to evade detection through feature smoothing.\n[翻译] 现有的基于图的检测方法很大程度上依赖于同质性假设，往往无法解决关系伪装问题，即机器人通过与人类建立异质连接，利用特征平滑来逃避检测。",
      "summary_innovation": "The study introduces an adaptive mechanism to distinguish between homophilic and heterophilic edges and constructs a node similarity graph to mitigate the isolation of bots within human-dominated neighborhoods.\n[翻译] 该研究引入了一种自适应机制来区分同质和异质边，并构建了一个节点相似性图，以缓解机器人在以人类为主的邻域中的孤立问题。",
      "summary_method": "BothH initializes multi-modal user representations using LMs and MLPs, constructs a composite graph supplemented by feature similarity, and employs an end-to-end framework that dynamically classifies edges to apply differentiated attention weights during neighbor aggregation.\n[翻译] BothH 利用语言模型和多层感知机初始化多模态用户表示，构建了由特征相似性补充的组合图，并采用端到端框架动态分类边缘，以便在邻居聚合过程中应用差异化的注意力权重。",
      "summary_conclusion": "The model achieves state-of-the-art performance across Cresci-15, MGTAB, and Twibot-20 datasets, notably attaining an F1-score of 91.27% on the highly heterophilic Twibot-20 benchmark.\n[翻译] 该模型在 Cresci-15、MGTAB 和 Twibot-20 数据集上均取得了最先进的性能，特别是在高度异质的 Twibot-20 基准测试中达到了 91.27% 的 F1 分数。",
      "summary_limitation": "Future work is suggested to explore the distinct connection preferences of various social bot types to further refine the heterophily-aware aggregation.\n[翻译] 未来的工作建议探索不同类型社交机器人的独特连接偏好，以进一步完善异质性感知聚合。",
      "paper_url": "https://dl.acm.org/doi/10.1145/3581783.3612569",
      "project_url": "",
      "conference": "Proceedings of the 31st ACM International Conference on Multimedia",
      "title_translation": "",
      "analogy_summary": "【争对包含机器人网络的异质性】使用节点特征相似度补充转发图中的边，确保bot的特征不会被包围他的正常用户平滑掉",
      "pipeline_image": "figures/BothH.png",
      "abstract": "The detection of social bots has become a critical task in maintaining the integrity of social media. With social bots evolving continually, they primarily evade detection by imitating human features and engaging in interactions with humans. To reduce the impact of social bots imitating human features, also known as feature camouflage, existing methods mainly utilize multi-modal user information for detection, especially GNN-based methods that utilize additional topological structure information. However, these methods ignore relation camouflage, which involves disguising through interactions with humans. We find that relation camouflage results in both homophilic connections formed by nodes of the same type and heterophilic connections formed by nodes of different types in social networks. The existing GNN-based detection methods assume all connections are homophilic while ignoring the difference among neighbors in heterophilic connections, which leads to a poor detection performance for bots with relation camouflage. To address this, we propose a multi-modal social bot detection method with learning homophilic and heterophilic connections adaptively (BothH for short). Specifically, firstly we determine whether each connection is homophilic or heterophilic with the connection classifier, and then we design a novel message propagating strategy that can learn the homophilic and heterophilic connections adaptively. We conduct experiments on the mainstream datasets and the results show that our model is superior to state-of-the-art methods.",
      "contributor": "",
      "notes": "[方法概括]1.初始化用户节点表示，meta info经过MLP，语义信息经过LM和MLP，分别编码后拼接。2.构建关注图。为防止bot特征被平滑，使用相似度补充图的边。3.经过一个分类模型将图的边进行分类，区分同质和异质边。4.进行GNN的邻居聚合，同质和异质视为不同的边，分别计算权重。5.残差后进行节点分类，损失为节点分类Loss + 边分类Loss[引用文]Addressing the limitation of homophily assumptions in graph-based detection, Li et al. [?] proposed BothH to counter relation camouflage where bots mix with human neighbors. The method fuses semantic and metadata features to initialize node representations and augments the original topology with a node similarity graph to connect isolated bots. It incorporates an auxiliary edge classifier to distinguish homophilic and heterophilic connections, subsequently splitting relations to apply distinct aggregation strategies. This approach effectively prevents feature smoothing in heterophilic environments and demonstrates superior performance on benchmarks like Twibot-20.\n[翻译] 中文文本：\n针对基于图的检测中同质性假设的局限性，Li 等人 [?] 提出了 BothH 以应对机器人混迹于人类邻居中的关系伪装问题。该方法融合语义和元数据特征来初始化节点表示，并利用节点相似性图增强原始拓扑结构以连接孤立的机器人。它结合了一个辅助边缘分类器来区分同质和异质连接，随后拆分关系以应用不同的聚合策略。这种方法有效地防止了异质环境中的特征平滑，并在 Twibot-20 等基准测试中表现出优越的性能。",
      "show_in_readme": true,
      "status": "skimmed",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1145/2783258.2783294",
      "title": "RSC: Mining and modeling temporal activity in social media",
      "authors": "Alceu Ferraz Costa, Yuto Yamaguchi, Agma Juci Machado Traina, Caetano Traina, Christos Faloutsos",
      "date": "2015-08-10",
      "category": "Malicious User Detection",
      "summary_motivation": "Existing stochastic models for human dynamics, such as Poisson processes, fail to simultaneously capture the complex temporal patterns—specifically burstiness, circadian rhythms, and heavy-tailed distributions—observed in large-scale social media data.\n[翻译] 现有的针对人类动力学的随机模型（如泊松过程）无法同时捕捉在大规模社交媒体数据中观察到的复杂时间模式，具体包括阵发性、昼夜节律和重尾分布。",
      "summary_innovation": "The paper proposes RSC, a generative model that introduces a Self-Correlated Process (SCorr) to incorporate memory effects into event generation, effectively modeling the positive correlation of inter-arrival times (IAT) that memoryless baselines ignore.\n[翻译] 该论文提出了RSC，这是一种生成模型，它引入了自相关过程（SCorr）将记忆效应纳入事件生成中，有效建模了无记忆基线模型所忽略的事件间隔时间（IAT）的正相关性",
      "summary_method": "The approach mines four statistical patterns from raw timestamps (positive correlation, heavy tails, periodic spikes, bimodal distribution) and employs a three-state stochastic machine (Active, Rest, Sleep) to generate synthetic timelines for anomaly detection.\n[翻译] 该方法从原始时间戳中挖掘出四种统计模式（正相关性、重尾、周期性峰值、双峰分布），并采用三状态随机机（活跃、休息、睡眠）来生成用于异常检测的合成时间线。",
      "summary_conclusion": "Experiments on 35 million postings demonstrate that RSC fits empirical data distributions more accurately than Self-Feeding Processes (SFP) and achieves over 94% precision in bot detection using solely temporal features.\n[翻译] 对3500万条帖子的实验表明，RSC在拟合经验数据分布方面比自反馈过程（SFP）更准确，并且仅使用时间特征即可实现超过94%的机器人检测精度。",
      "summary_limitation": "The model assumes a single, stable physiological rhythm, which may lead to false positives for accounts operated by multiple users, those employing scheduling tools, or users with extremely fragmented activity patterns lacking distinct sleep cycles.\n[翻译] 该模型假设存在单一且稳定的生理节律，对于由多人操作的账户、使用调度工具的账户，或缺乏明显睡眠周期的极度碎片化活跃用户，可能会导致误报。",
      "paper_url": "https://dl.acm.org/doi/10.1145/2783258.2783294",
      "project_url": "https://github.com/alceufc/rsc_model",
      "conference": "KDD '15: The 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
      "title_translation": "",
      "analogy_summary": "构建了一个正常人类发帖时间特征的数学模型（时间间隔正相关性、重尾分布、24h周期性、双峰分布）。相对于传统的泊松分布更符合现实，相异度较高的用户判定为机器人。是一个**只依赖时间特征**的模型",
      "pipeline_image": "figures/RSC.png",
      "abstract": "Can we identify patterns of temporal activities caused by human communications in social media? Is it possible to model these patterns and tell if a user is a human or a bot based only on the timing of their postings? Social media services allow users to make postings, generating large datasets of human activity time-stamps. In this paper we analyze time-stamp data from social media services and find that the distribution of postings inter-arrival times (IAT) is characterized by four patterns: (i) positive correlation between consecutive IATs, (ii) heavy tails, (iii) periodic spikes and (iv) bimodal distribution. Based on our findings, we propose Rest-Sleep-andComment (RSC), a generative model that is able to match all four discovered patterns. We demonstrate the utility of RSC by showing that it can accurately fit real time-stamp data from Reddit and Twitter. We also show that RSC can be used to spot outliers and detect users with non-human behavior, such as bots. We validate RSC using real data consisting of over 35 million postings from Twitter and Reddit. RSC consistently provides a better fit to real data and clearly outperform existing models for human dynamics. RSC was also able to detect bots with a precision higher than 94%.",
      "contributor": "",
      "notes": "[引用文]In the transition from statistical pattern recognition to generative social simulation, Costa et al. [1] introduced the Rest-Sleep-and-Comment (RSC) model. Transcending traditional memoryless baselines like Poisson processes, RSC employs a Self-Correlated Process (SCorr) within a three-state stochastic machine (Active, Rest, Sleep) to mathematically formalize human physiological rhythms. This approach allows for the generative reproduction of complex temporal dynamics—specifically positive inter-arrival time correlations, heavy tails, circadian periodicities, and bimodal distributions. By establishing a simulation-based baseline of organic behavior, the model enables a lightweight, timestamp-only anomaly detection framework where non-human actors are identified through their distributional dissimilarity to the generated human patterns.\n[翻译] 在从统计模式识别向生成式社会仿真过渡的过程中，Costa等人 [1] 引入了 Rest-Sleep-and-Comment (RSC) 模型。RSC 超越了像泊松过程这样的传统无记忆基线，在一个三状态随机机（活跃、休息、睡眠）中采用了自相关过程 (SCorr)，以此在数学上形式化人类的生理节律。这种方法允许对复杂的时间动力学进行生成式复现——具体包括正向间隔时间相关性、重尾、昼夜周期性和双峰分布。通过建立基于仿真的自然行为基线，该模型实现了一种轻量级、仅依赖时间戳的异常检测框架，非人类行动者通过其与生成的人类模式的分布相异度被识别出来。",
      "show_in_readme": true,
      "status": "skimmed",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1109/TNNLS.2024.3396192",
      "title": "Dispelling the fake: Social bot detection based on edge confidence evaluation",
      "authors": "Boyu Qiao, Wei Zhou, Kun Li, Shilong Li, Songlin Hu",
      "date": "2025-04",
      "category": "Malicious User Detection",
      "summary_motivation": "Mainstream GNN-based detection methods often struggle when the homophily assumption is violated by camouflaged connections between bots and humans. These \"unreliable edges\" cause message passing mechanisms to aggregate noise, making it difficult to differentiate bot representations from genuine users.\n[翻译] 主流基于GNN的检测方法常因机器人与人类之间的伪装连接破坏同质性假设而受挫。这些“不可靠边”导致消息传递机制聚合噪声，使得难以区分机器人与真实用户的表示。",
      "summary_innovation": "The paper proposes the BECE framework, which introduces an edge confidence evaluation mechanism to dynamically identify and pr\n[翻译] 该论文提出了BECE框架，引入边置信度评估机制以动态识别并剪枝不可靠边。其核心创新在于利用参数化高斯分布将边嵌入映射到随机潜在空间，通过正则化增强了模型对特征扰动的鲁棒性。",
      "summary_method": "The method first fuses multi-modal user features using multi-head attention mechanisms. It then constructs edge representations and reconstructs them via a parameterized Gaussian distribution to predict confidence scores. Finally, unreliable edges are removed based on Bernoulli sampling before performing node classification with standard GNN encoders.\n[翻译] 该方法首先利用多头注意力机制融合多模态用户特征。随后构建边表示，并通过参数化高斯分布对其进行重构以预测置信度分数。最后，在利用标准GNN编码器进行节点分类前，基于伯努利采样移除不可靠边。",
      "summary_conclusion": "Experiments on Cresci-15, Twibot-20, and MGTAB datasets demonstrate that BECE consistently outperforms state-of-the-art baselines like BotRGCN and RGT. Additionally, the edge confidence module proves effective as a plug-in across six different GNN architectures, maintaining high performance even with limited training data (30-50%).\n[翻译] 在Cresci-15、Twibot-20和MGTAB数据集上的实验表明，BECE在性能上持续优于BotRGCN和RGT等先进基线方法。此外，边置信度模块作为插件在六种不同的GNN架构中均表现有效，即使在训练数据有限（30-50%）的情况下仍保持高性能。",
      "summary_limitation": "The model exhibits limitations in discerning heterogeneous edges when the representations of connected node pairs are highly similar, as observed in parts of the MGTAB dataset. Future work intends to leverage richer structural information to refine edge embeddings and optimization strategies.\n[翻译] 当相连节点对的表示高度相似时（如在MGTAB数据集的部分样本中），模型在识别异质边方面表现出局限性。未来工作计划利用更丰富的结构信息来优化边嵌入和策略。",
      "paper_url": "https://ieeexplore.ieee.org/document/10530431/",
      "project_url": "",
      "conference": "IEEE Trans. Neural Netw. Learn. Syst.",
      "title_translation": "",
      "analogy_summary": "【争对包含机器人网络的异质性】BECE is a GNN-based framework that restores graph homophily by dynamically pruning unreliable human-bot connections through a Gaussian-regularized edge confidence evaluation mechanism.\n[翻译] BECE是一个基于GNN的框架，它通过高斯正则化的边置信度评估机制动态剪枝不可靠的人-机连接，从而恢复图的同质性。",
      "pipeline_image": "figures/BECE.png",
      "abstract": "Social bot detection is essential for maintaining the safety and integrity of online social networks (OSNs). Graph neural networks (GNNs) have emerged as a promising solution. Mainstream GNN-based social bot detection methods learn rich user representations by recursively performing message passing along user–user interaction edges, where users are treated as nodes and their relationships as edges. However, these methods face challenges when detecting advanced bots interacting with genuine accounts. Interaction with real accounts results in the graph structure containing camouflaged and unreliable edges. These unreliable edges interfere with the differentiation between bot and human representations, and the iterative graph encoding process amplifies this unreliability. In this article, we propose a social Bot detection method based on Edge Confidence Evaluation (BECE). Our model incorporates an edge confidence evaluation module that assesses the reliability of the edges and identifies the unreliable edges. Specifically, we design features for edges based on the representation of user nodes and introduce parameterized Gaussian distributions to map the edge embeddings into a latent semantic space. We optimize these embeddings by minimizing Kullback–Leibler (KL) divergence from the standard distribution and evaluate their confidence based on edge representation. Experimental results on three real-world datasets demonstrate that BECE is effective and superior in social bot detection. Additionally, experimental results on six widely used GNN architectures demonstrate that our proposed edge confidence evaluation module can be used as a plug-in to improve detection performance.",
      "contributor": "",
      "notes": "相对于论文BothH（Multi-modal social bot detection: Learning homophilic and heterophilic connections adaptively）对异质关系进行显性的建模，该文则选择排除异质关系以防止干扰[引用文]Unlike BothH [Citation] which explicitly models heterophilic connections to adaptively extract high-pass information, Qiao et al. [Year] propose a subtractive strategy in their BECE model to mitigate interference. Arguing that camouflaged edges between bots and humans violate the GNN homophily assumption, they introduce an Edge Confidence Evaluation module to filter out these unreliable connections. To address the noise inherent in edge features, BECE maps edge embeddings into a parameterized Gaussian distribution, ensuring that minor feature perturbations do not compromise detection accuracy. This stochastic reconstruction allows the model to robustly identify and prune heterophilic edges via Bernoulli sampling, thereby purifying the graph structure for subsequent message passing.\n[翻译] 与 BothH [引文] 显式建模异质连接以自适应提取高频信息的做法不同，Qiao等人 [年份] 在其 BECE 模型中提出了一种减法策略以减少干扰。他们认为机器人与人类之间的伪装连接破坏了GNN的同质性假设，因此引入了边置信度评估模块来过滤这些不可靠连接。为了解决边特征中固有的噪声问题，BECE将边嵌入映射为参数化高斯分布，确保微小的特征扰动不会损害检测精度。这种随机重构使得模型能够通过伯努利采样鲁棒地识别并剪枝异质边，从而为随后的消息传递净化图结构。",
      "show_in_readme": true,
      "status": "skimmed",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    }
  ],
  "meta": {
    "generated_at": "2026-01-29 17:13:31"
  }
}