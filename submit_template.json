{
  "papers": [
    {
      "doi": "10.1145/3581783.3612517",
      "title": "Multi-label emotion analysis in conversation via multimodal knowledge distillation",
      "authors": "Sidharth Anand∗,Naresh Kumar Devulapally∗,Sreyasee Das Bhattacharjee,Junsong Yuan",
      "date": "2023-10-27",
      "category": "Sentiment Analysis",
      "summary_motivation": "Addresses the limitations of single-dominant emotion assumptions by tackling the challenge of multi-label emotion co-occurrence and generalization across diverse socio-demographic groups, particularly varying age populations.\n[翻译] 针对现有多模态方法主要关注单一主导情感的局限性，该研究致力于解决情感标签共现的识别难题，并提升模型在不同社会人口统计学群体（特别是不同年龄段人群）中的泛化能力。",
      "summary_innovation": "将多模态知识蒸馏与标签一致性校准损失（LCC）相结合，减轻了模型对简单标签的过拟合（保证置信度相近）；构建了一个利用蒸馏方法的整体框架，其目的是为了融合各模态能力",
      "summary_method": "Employing a Multimodal Transformer Network where mode-specific peer branches (visual, audio, textual) collaboratively distill learned probabilistic uncertainty into a fusion branch via cross-network attention and noise contrastive estimation.……\n[翻译] 将三个特定模态的对等分支通过跨网络注意力和噪声对比估计，协同地将其学习到的概率蒸馏到融合分支中，构建了一个拥有四个分支的整体预测模型。[值得关注]视频使用Tubelet embedding技术，将视频切分为时空小块（Spatial-Temporal Tubes），保留时空信息",
      "summary_conclusion": "Demonstrates state-of-the-art performance on MOSEI, EmoReact, and ElderReact datasets, achieving an approximate 17% improvement in weighted F1-score during cross-dataset evaluations, thereby validating robustness in age-diverse scenarios.\n[翻译] 在MOSEI、EmoReact和ElderReact数据集上最先进的性能，跨数据集评估有约17%的加权F1提升，在跨年龄场景下具有鲁棒性。",
      "summary_limitation": "The approach necessitates the reduction of complex emotion categories to basic subsets for cross-dataset consistency and entails significant computational overhead due to the spatiotemporal tubelet embedding mechanism.\n[翻译] 为了保持跨数据集一致性，要将复杂情感类归约为基础子集，由于采用时空Tubelet嵌入机制，导致了显著的计算开销",
      "paper_url": "https://dl.acm.org/doi/10.1145/3581783.3612517",
      "project_url": "https://github.com/neuralnaresh/multimodal-emotion-recognition",
      "conference": "Proceedings of the 31st ACM International Conference on Multimedia",
      "title_translation": "[AI generated] **中文标题：** 基于多模态知识蒸馏的对话多标签情感分析话多标签情感分析",
      "analogy_summary": "三个专家分别处理一个模态，训练的同时将能力蒸馏给融合分支，最终形成一个整体模型，教师（分支专家）与学生（融合专家）一同处理多模态内容，得到情感分类",
      "pipeline_image": "figures/SeMuL-PCD.png",
      "abstract": "Evaluating speaker emotion in conversations is crucial for various applications requiring human-computer interaction. However, co-occurrences of multiple emotional states (e.g. 'anger' and 'frustration' may occur together or one may influence the occurrence of the other) and their dynamic evolution may vary dramatically due to the speaker's internal (e.g., influence of their personalized socio-cultural-educational and demographic backgrounds) and external contexts. Thus far, the previous focus has been on evaluating only the dominant emotion observed in a speaker at a given time, which is susceptible to producing misleading classification decisions for difficult multi-labels during testing. In this work, we present Self-supervised Multi- Label Peer Collaborative Distillation (SeMuL-PCD) Learning via an efficient Multimodal Transformer Network, in which complementary feedback from multiple mode-specific peer networks (e.g.transcript, audio, visual) are distilled into a single mode-ensembled fusion network for estimating multiple emotions simultaneously. The proposed Multimodal Distillation Loss calibrates the fusion network by minimizing the Kullback-Leibler divergence with the peer networks. Additionally, each peer network is conditioned using a self-supervised contrastive objective to improve the generalization across diverse socio-demographic speaker backgrounds. By enabling peer collaborative learning that allows each network to independently learn their mode-specific discriminative patterns,SeMUL-PCD is effective across different conversation environments. In particular, the model not only outperforms the current state-of-the-art models on several large-scale public datasets (e.g., MOSEI, EmoReact and ElderReact), but with around 17% improved weighted F1-score in the cross-dataset experimental settings. The model also demonstrates an impressive generalization ability across age and demography-diverse populations.",
      "contributor": "anonymous",
      "notes": "【面向结果模型训练】[引用句]\"Transscending the traditional paradigm of identifying single dominant emotions, Anand et al. [2023] proposed SeMuL-PCD to enhance the granularity of affective perception in diverse social contexts; by leveraging a collaborative distillation mechanism that calibrates mode-specific feedback, their model robustly disentangles multi-label emotional co-occurrences across varying demographic backgrounds (e.g., children and the elderly), thereby providing a more nuanced foundation for socially adaptive agents.\"\n[翻译] “为了超越识别单一主导情感的传统范式，Anand等人[2023]提出了SeMuL-PCD，旨在增强不同社会语境下情感感知的粒度；通过利用一种校准模态特定反馈的协作蒸馏机制，该模型能够在不同的人口统计背景（如儿童和老人）下鲁棒地解耦多标签情感的共现关系，从而为具备社会适应能力的智能体提供了更精细的情感理解基础。”",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": ""
    },
    {
      "doi": "10.1609/icwsm.v19i1.35801",
      "title": "Extracting affect aggregates from longitudinal social media data with temporal adapters for large language models",
      "authors": "Georg Ahnert, Max Pellert, David Garcia, Markus Strohmaier",
      "date": "2025-06-07",
      "category": "Sentiment Analysis",
      "summary_motivation": "Addresses the temporal misalignment inherent in prompt-based in silico surveys and the scalability bottlenecks of traditional affective computing, which heavily relies on resource-intensive labeled datasets or static dictionaries.\n[翻译] 解决了基于提示词的in silico（计算机模拟）调查中固有的时间错位问题，以及传统情感计算严重依赖资源密集型标注数据集或静态词典的可扩展性瓶颈",
      "summary_innovation": "利用LoRA作为模块化学习元件的“时间适配器”，以捕捉特定时期独有的时间与语言特征。通过将这些轻量级适配器与冻结基座模型的固有推理能力产生协同作用，该框架实现了高效且可扩展的纵向情感预测。",
      "summary_method": "Employs a two-stage framework: first, fine-tuning weekly LoRA adapters on longitudinal Twitter timelines via a self-supervised causal language modeling objective; second, probing the adapted models with standard psychometric questionnaires to extract aggregate affect via token probability distributions.\n[翻译] 采用双阶段框架：首先，通过自监督的因果语言建模目标在纵向Twitter时间线上微调每周的LoRA适配器；其次，使用标准心理测量问卷探测适配后的模型，通过Token概率分布提取聚合情感<br>[通俗核心]在每周分别进行LoRA自监督微调，让模型的预测尽可能和原数据一样。使用专业问卷作为prompt，模拟模型回答问卷，最终得到一个情感概率随时间的分布，与公众真实分布对比",
      "summary_conclusion": "Demonstrates strong, significant correlations with representative polling data (YouGov) during the COVID-19 pandemic, achieving performance comparable to supervised baselines (e.g., TweetNLP) while offering superior flexibility in querying diverse and complex collective attitudes.\n[翻译] 展示了在COVID-19大流行期间与代表性民调数据（YouGov）的强显著相关性，实现了与监督基线模型（如TweetNLP）相当的性能，同时在查询多样化且复杂的集体态度方面提供了更优越的灵活性。",
      "summary_limitation": "Primarily effective for longitudinal trend analysis rather than absolute cross-sectional calibration, and the representativeness of the emergent sentiment is constrained by the demographic biases inherent in the social media training corpora.\n[翻译] 主要在纵向趋势分析而非绝对横截面校准方面有效，且涌现出的情感代表性受限于社交媒体训练语料库中固有的人口统计学偏差",
      "paper_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/35801",
      "project_url": "https://github.com/dess-mannheim/temporal-adapters",
      "conference": "ICWSM",
      "title_translation": "[AI generated] **中文标题：** 利用面向大语言模型的时间适配器从纵向社交媒体数据中提取情感聚合指标\n\n**说明：** 此翻译力求准确、专业，符合学术论文标题的规范。\n*   **Extracting affect aggregates** 译为“提取情感聚合指标”，其中“affect”在心理学和情感计算领域常译为“情感”，“aggregates”译为“聚合指标”以体现其作为测量结果的属性。\n*   **from longitudinal social media data**",
      "analogy_summary": "对于每周，训练一个LoRA作为时间适配器，使模型获得了根据时间段预测情感的能力",
      "pipeline_image": "figures/Temporal Adapters.png;figures/Temporal Adapters2.png",
      "abstract": "This paper proposes temporally aligned Large Language Models (LLMs) as a tool for longitudinal analysis of social media data. We fine-tune Temporal Adapters for Llama 3 8B on full timelines from a panel of British Twitter users and extract longitudinal aggregates of emotions and attitudes with established questionnaires. We focus our analysis on the beginning of the COVID-19 pandemic that had a strong impact on public opinion and collective emotions. We validate our estimates against representative British survey data and find strong positive and significant correlations for several collective emotions. The estimates obtained are robust across multiple training seeds and prompt formulations, and in line with collective emotions extracted using a traditional classification model trained on labeled data. We demonstrate the flexibility of our method on questions of public opinion for which no pre-trained classifier is available. Our work extends the analysis of affect in LLMs to a longitudinal setting through Temporal Adapters. It enables flexible and new approaches to the longitudinal analysis of social media data.",
      "contributor": "anonymous",
      "notes": "【集体情感分析】通过LoRA自监督学到的是该特定时间段内公众的语言风格和关注点，结合基础模型的固有能力获得了预测特定时间内公众情感的能力，很神奇，这是一个通用方法\n[引用文]Moving beyond traditional supervised classifiers, Ahnert et al. (2025) demonstrate a shift toward the social simulation paradigm by proposing Temporal Adapters. Instead of training models to explicitly recognize emotion patterns, they utilize self-supervised learning to train lightweight LoRA modules as learning components, aligning the frozen LLM with specific temporal and linguistic contexts derived from longitudinal social media data. This equips the model with the capability to predict public sentiment within specific timeframes. Their approach validates that scalable and accurate tracking of public opinion dynamic\n[翻译]\n超越了传统的监督分类器，Ahnert等人 (2025) 通过提出 “时间适配器” 展示了向社会仿真范式的转变。他们不再训练模型去显式地识别情感模式，而是通过自监督学习训练轻量级的LoRA模块作为学习元件，将冻结的大语言模型与源自纵向社交媒体数据的特定时间及语言语境相对齐。使模型获得了预测特定时间内公众情感的能力。他们的方法证实，通过时间对齐而非标签监督，即可实现对民意动态的可扩展且准确的追踪。",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": ""
    },
    {
      "doi": "10.1609/icwsm.v19i1.35800",
      "title": "Conversation Kernels: A Flexible Mechanism to Learn Relevant Context for Online Conversation Understanding",
      "authors": "to be filled in",
      "date": "2025-06-07",
      "category": "Base Techniques;Comment Generation",
      "summary_motivation": "Addressing the sparsity and context-dependency of individual online utterances, where traditional models often fail to capture implicit dependencies within conversation trees or introduce noise through indiscriminate context inclusion.\n[翻译] 针对在线言论固有的稀疏性和语境依赖性问题，即传统模型往往难以捕捉对话树内的隐式依赖关系，或因无差别地引入上下文而产生噪声",
      "summary_innovation": "The proposal of \"Conversation Kernels,\" a general-purpose mechanism that employs flexible topological shapes to retrieve fine-grained, structured conversational context, distinguishing itself by identifying the \"right\" structural neighborhood rather than merely increasing context length.\n[翻译] 提出了“对话核”这一通用机制，利用灵活的拓扑形状来检索细粒度的结构化对话上下文；其独到之处在于通过识别“正确”的结构邻域而非单纯增加上下文长度来理解对话。",
      "summary_method": "An end-to-end trained probabilistic framework that first retrieves relevant structural windows (e.g., ancestors, neighbors) via similarity scoring, and subsequently fuses these contexts through a weighted marginalization of the predictive distributions generated by a RoBERTa-based encoder.\n[翻译] 一个端到端训练的概率框架，首先通过相似度评分检索相关的结构化窗口（如祖先、邻居），随后通过对RoBERTa编码器生成的预测分布进行加权求和（边缘化），从而融合这些上下文信息。[通俗核心]针对目标评论构建回复树，取几个窗口（如父评论窗口、1跳窗口），每个窗口中所有评论与原评论拼接，并进行预测，最后不同窗口与原评论的相关性经过softmax作为权重，对所有预测置信度加权和，得到最终结果",
      "summary_conclusion": "Extensive experiments on Slashdot data demonstrate that context-augmented kernels outperform baseline transformers by up to 20% in accuracy and surpass general-purpose LLMs (GPT-3.5/4) in specific categorization tasks, revealing that different tasks require distinct structural context patterns.\n[翻译] 在Slashdot数据上的广泛实验表明，上下文增强的核机制在准确率上比基线Transformer模型高出20%，并在特定分类任务中超越了通用大语言模型（GPT-3.5/4），揭示了不同任务需要截然不同的结构化上下文模式。",
      "summary_limitation": "The approach relies heavily on explicit tree-structured reply threads, limiting applicability in flat discussion formats, and may face cold-start challenges in early-stage conversations with sparse context.\n[翻译] 该方法严重依赖显式的树状回复线索，限制了其在扁平化讨论形式中的适用性，并且在上下文稀疏的对话早期阶段可能面临冷启动挑战。",
      "paper_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/35800",
      "project_url": "https://netsys.surrey.ac.uk/datasets/slashdot/",
      "conference": "ICWSM",
      "title_translation": "[AI generated] **中文标题：对话核：一种学习在线对话理解相关上下文的灵活机制**",
      "analogy_summary": "A flexible, structural context discovery framework that enhances conversation understanding by learning to attend to relevant topological neighborhoods within conversation trees.[翻译] 一个灵活的结构化上下文发现框架，通过学习关注对话树内相关的拓扑邻域来增强对话理解能力。",
      "pipeline_image": "figures/Conversation Kernels.png;figures/Conversation Kernels2.png",
      "abstract": "Understanding online conversations has attracted research attention with the growth of social networks and online discussion forums. Content analysis of posts and replies in online conversations is difficult because each individual utterance is usually short and may implicitly refer to other posts within the same conversation. Thus, understanding individual posts requires capturing the conversational context and dependencies between different parts of a conversation tree and then encoding the context dependencies between posts and comments/replies into the language model.\n\nTo this end, we propose a general-purpose mechanism to discover appropriate conversational context for various aspects about an online post in a conversation, such as whether it is informative, insightful, interesting or funny. Specifically, we design two families of Conversation Kernels, which explore different parts of the neighborhood of a post in the tree representing the conversation and through this, build relevant conversational context that is appropriate for each task being considered. We apply our developed method to conversations crawled from slashdot.org, which allows users to apply highly different labels to posts, such as `insightful', `funny', etc., and therefore provides an ideal experimental platform to study whether a framework such as Conversation Kernels is general-purpose and flexible enough to be adapted to disparately different conversation understanding tasks.\n\nWe perform extensive experiments and find that context-augmented conversation kernels can significantly outperform transformer-based baselines, with absolute improvements in accuracy up to 20% and up to 19% for macro-F1 score. Our evaluations also show that conversation kernels outperform state-of-the-art large language models including GPT-4. We also showcase the generalizability and demonstrate that conversation kernels can be a general-purpose approach that flexibly handles distinctly different conversation understanding tasks in a unified manner.",
      "contributor": "anonymous",
      "notes": "【基础技术—上下文感知方法】可用于所有内容理解任务，论文中的实验用的是是否受欢迎二分类\n[引用文]To better bridge pattern recognition with social interaction structures, Agarwal et al. (2025) proposed Conversation Kernels, an end-to-end framework designed to extract fine-grained context from conversation trees. By dynamically retrieving and weighting specific topological neighborhoods (e.g., ancestors or siblings) rather than ingesting linear history, their method effectively filters noise inherent in social discussions. This structural selectivity demonstrates that incorporating explicit interaction topologies is crucial for accurately decoding the nature of online conversations, yielding performance that surpasses even general-purpose Large Language Models like GPT-4.\n[翻译]\n为了更好地将模式识别与社会互动结构联系起来，Agarwal等人 (2025) 提出了“对话核（Conversation Kernels）”，这是一种旨在从对话树中提取细粒度上下文的端到端框架。通过动态检索并加权特定的拓扑邻域（如祖先或兄弟节点）而非摄入线性历史，该方法有效地过滤了社会讨论中固有的噪声。这种结构选择性证明，结合显式的互动拓扑对于准确解读在线对话的性质至关重要，其表现甚至超越了像 GPT-4 这样的通用大语言模型。",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": ""
    },
    {
      "doi": "10.1017/pan.2023.2",
      "title": "Out of one, many: Using language models to simulate human samples",
      "authors": "Lisa P. Argyle,Ethan C. Busby,Nancy Fulda2, Joshua R. Gubler,Christopher Rytting and David Wingate",
      "date": "2023-07",
      "category": "Social Simulation",
      "summary_motivation": "LLM's well-documented propensity to replicate societal biases is often viewed as a liability, but this paper reconsiders it as a potential asset, suggesting these biases reflect the complex, fine-grained attitudinal distributions embedded within human subpopulations.\n\n[翻译]模型复制社会偏见的倾向通常被视为缺陷，但本文将其重新视为一种潜在优势，认为这些偏见反映了内嵌于人类亚群体中复杂、细粒度的态度分布。",
      "summary_innovation": "(i) proposing the novel concept of “algorithmic fidelity” and its four criteria, establishing a framework to quantify how well LLMs simulate human populations; (ii) introducing “silicon sampling,” a method that conditions models on real demographic backstories to generate representative virtual samples\n[翻译] (i) 提出“算法保真度”新概念及其四个标准，建立了量化LLM模拟人类群体效果的框架；(ii) 引入“硅采样”方法，基于真实人口背景故事对模型进行条件化，以生成有代表性的虚拟样本",
      "summary_method": "(i) extracting sociodemographic profiles from large-scale human surveys; (ii) constructing first-person narrative backstories as conditioning prompts; (iii) feeding these prompts into GPT-3 to generate responses (“silicon samples”) to specific questions; (iv) statistically comparing the generated data with original human data to validate algorithmic fidelity across various metrics.\n\n[翻译] (i) 从大规模人类调查中提取社会人口学特征；(ii) 构建第一人称叙事背景故事作为条件化提示；(iii) 将这些提示输入GPT-3，以生成针对特定问题的回答（“硅样本”）；(iv) 从多维度统计上比较生成数据与原始人类数据，以验证算法保真度。[通俗核心]方法很简单，使用提示词模版填入符合人口统计特征的受访者特征，让LLM输出指定回答，与人类样本做对齐",
      "summary_conclusion": "The study demonstrates that GPT-3 exhibits high algorithmic fidelity: human evaluators struggle to distinguish its outputs from human text, and its generated data closely replicates not only aggregate opinion distributions (e.g., vote shares) but also the complex correlational structures between demographics, attitudes, and behaviors found in real human data.\n\n[翻译] 研究表明GPT-3表现出高算法保真度：人类评估者难以区分其输出与人类文本，其生成的数据不仅紧密复现了聚合意见分布（如投票份额），还复现了真实人类数据中人口特征、态度和行为之间复杂的相关性结构。",
      "summary_limitation": "提示词中显示标明角色身份，会让LLM过度重视，有走捷径之嫌",
      "paper_url": "https://www.cambridge.org/core/journals/political-analysis/article/out-of-one-many-using-language-models-to-simulate-human-samples/035D7C8A55B237942FB6DBAD7CAA4E49",
      "project_url": "",
      "conference": "Political Analysis",
      "title_translation": "[AI generated] **中文标题：** 一源多相：利用语言模型模拟人类样本\n\n**翻译说明：**\n1.  **“Out of one, many”** 译为“一源多相”，旨在传达“从一个（语言模型）中，可以产生出多种（不同人类亚群体的）样本”的核心思想。“多相”一词在学术语境中可指代多种形态或类型，契合原文的哲学意涵和模拟多样性。\n2.  **主标题",
      "analogy_summary": "让LLM模仿人类进行社会学实验，通过与真实情况对齐来判断LLM相关预测能力",
      "pipeline_image": "figures/Out of One, Many.png;figures/Out of One, Many2.png",
      "abstract": "We propose and explore the possibility that language models can be studied as effective proxies for specific human subpopulations in social science research. Practical and research applications of artificial intelligence tools have sometimes been limited by problematic biases (such as racism or sexism), which are often treated as uniform properties of the models. We show that the “algorithmic bias” within one such tool—the GPT-3 language model—is instead both fine-grained and demographically correlated, meaning that proper conditioning will cause it to accurately emulate response distributions from a wide variety of human subgroups. We term this property algorithmic fidelity and explore its extent in GPT-3. We create “silicon samples” by conditioning the model on thousands of sociodemographic backstories from real human participants in multiple large surveys conducted in the United States. We then compare the silicon and human samples to demonstrate that the information contained in GPT-3 goes far beyond surface similarity. It is nuanced, multifaceted, and reflects the complex interplay between ideas, attitudes, and sociocultural context that characterize human attitudes. We suggest that language models with sufficient algorithmic fidelity thus constitute a novel and powerful tool to advance understanding of humans and society across a variety of disciplines.",
      "contributor": "anonymous",
      "notes": "[引用文]Argyle et al. (2023) represent a pivotal shift from viewing LLMs as mere pattern recognition tools to employing them as tools for social simulation. Their work provides a paradigmatic methodology—centered on the concept of “algorithmic fidelity”—for experimentally testing whether and how the statistical predictions of an LLM align with nuanced human societal patterns. By conditioning GPT-3 on detailed demographic backstories within prompts (“silicon sampling”), they demonstrated that the model itself could generate attitudes and internal correlations that closely mirror those of real human subgroups. This marks a transition from goal-oriented text generation to the study of simulated social emergence.\n\n[翻译]\nArgyle等人(2023)的研究标志着一个关键转变：从将LLM视为单纯的模式识别工具，转向将其用作社会仿真的工具。他们的工作提供了一种范式方法——围绕“算法保真度”概念——来实验性地测试LLM的统计预测是否及如何与人类社会模式对齐。通过在提示词中为GPT-3施加详细的人口背景故事条件（“硅采样”），他们证明了该模型能够涌现出与真实人类亚群体高度吻合的态度及内部关联。标志着从目标导向的文本生成向模拟社会涌现研究的过渡",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": ""
    },
    {
      "doi": "10.18653/v1/2024.findings-emnlp.153",
      "title": "Are Large Language Models (LLMs) Good Social Predictors?",
      "authors": "Kaiqi Yang*,Hang Li*,Hongzhi Wen,Tai-Quan Peng,Jiliang Tang,Hui Liu",
      "date": "2024",
      "category": "Social Simulation",
      "summary_motivation": "论文Out of one, many: Using language models to simulate human samples可能利用了捷径特性，且能力难以从宏观细化到个体",
      "summary_innovation": "[AI generated] Proposes a novel social prediction benchmark (Soc-PRF) categorizing features by mutability to rigorously evaluate LLMs and reveals their reliance on input shortcuts.\n[翻译]：提出了一个按特征可变性分类的新颖社会预测基准（Soc-PRF），以严格评估LLMs，并揭示了其对输入捷径的依赖。",
      "summary_method": "First, a replication and ablation study on the ANES voting dataset quantifies the performance drop when removing highly correlated “shortcut” inputs (e.g., party ID). Second, a new benchmark is constructed using Gallup World Poll data. Features are categorized by mutability (low: demographics; high: attitudes/behaviors). Three prediction settings are defined—low-to-high, high-to-low, and high-to-high—simulating realistic data collection scenarios. Multiple LLMs are evaluated under zero-shot prompting, with AUC as the primary metric.\n[翻译]：首先，在ANES投票数据集上进行复制和消融研究，量化了移除高度相关的“捷径”输入（如党派身份）后的性能下降。其次，使用盖洛普世界民意调查数据构建了一个新基准。特征按可变性分类（低：人口统计学特征；高：态度/行为）。定义了三种预测设定——低推高、高推低和高推高——以模拟现实的数据收集场景。在零样本提示下评估了多种LLMs，以AUC为主要指标。",
      "summary_conclusion": "The high performance in prior voting prediction vanishes when shortcuts are removed, with accuracy dropping to near-random levels (e.g., ~61% for GPT-3.5). In the stringent Soc-PRF settings devoid of shortcuts, all tested LLMs (including GPT-4) perform no better than random guessing (AUC ~50). [翻译]： 先前投票预测中的高性能消失，准确率下降至接近随机水平（例如，GPT-3.5约为61%）。在排除捷径的严格Soc-PRF设定中，所有测试的LLMs（包括GPT-4）的表现均不优于随机猜测（AUC ~50）。",
      "summary_limitation": "[AI generated] The promising performance of LLMs in social prediction heavily relies on unrealistic shortcut features, and their ability to generalize to real-world scenarios with ordinary inputs remains questionable. [翻译]：LLMs在社会预测中的优异表现严重依赖不现实的捷径特征，其使用普通输入泛化到真实场景的能力存疑。",
      "paper_url": "https://aclanthology.org/2024.findings-emnlp.153",
      "project_url": "",
      "conference": "EMNLP Findings",
      "title_translation": "[AI generated] **中文标题：** 大语言模型是优秀的社会预测器吗？\n\n**翻译说明：**\n1.  **准确性：** 直译核心疑问“Are ... Good Social Predictors?”，准确传达原文的探究性。\n2.  **专业性：** 使用“大语言模型”、“社会预测器”等标准学术术语，符合计算机科学和社会科学交叉领域的表述习惯。\n3.  **简洁性：** 标题简洁明了，直接点明论文的核心",
      "analogy_summary": "消融了最能影响预测结果的“意识形态自我定位”和“党派认同”，发现预测能力接近于随机",
      "pipeline_image": "figures/anti-Out of One, Many.png",
      "abstract": "With the recent advancement of Large Language Models (LLMs), efforts have been made to leverage LLMs in crucial social science study methods, including predicting human features of social life such as presidential voting. Existing works suggest that LLMs are capable of generating human-like responses. Nevertheless, it is unclear how well LLMs work and where the plausible predictions derive from. This paper critically examines the performance of LLMs as social predictors, pointing out the source of correct predictions and limitations. Based on the notion of mutability that classifies social features, we design three realistic settings and a novel social prediction task, where the LLMs make predictions with input features of the same mutability and accessibility with the response feature. We find that the promising performance achieved by previous studies is because of input shortcut features to the response, which are hard to capture in reality; the performance degrades dramatically to near-random after removing the shortcuts. With the comprehensive investigations on various LLMs, we reveal that LLMs struggle to work as expected on social prediction when given ordinarily available input features without shortcuts. We further investigate possible reasons for this phenomenon and suggest potential ways to enhance LLMs for social prediction.",
      "contributor": "anonymous",
      "notes": "[引用文]As the field evolves from pattern recognition towards social simulation and emergent understanding, a critical reassessment of our tools is imperative. Yang et al. (2024) provide a pivotal corrective in this transition. Their work challenges the optimistic narrative that LLMs can serve as accurate social predictors. They demonstrate that previously reported successes in tasks like vote prediction critically depended on \"shortcut features\" (e.g., using party identification to predict vote choice) and, by introducing a novel shortcut-free benchmark (Soc-PRF), reveal a significant gap. In settings devoid of such shortcuts, even state-of-the-art LLMs perform at random levels. This finding underscores a fundamental limitation: while current LLMs are excellent pattern recognizers of surface correlations, they lack the deeper causal or contextual reasoning necessary for genuine social simulation and the emergence of robust socio-behavioral understanding. Their research suggests that achieving true social fidelity requires moving beyond exploiting statistical artifacts in data.\n\n[翻译]\n\n随着该领域从模式识别向社会仿真与涌现性理解演进，对我们的工具进行批判性重估势在必行。Yang等人（2024）在这一转变中提供了一个关键修正。他们的工作挑战了“LLMs能作为准确社会预测器”的乐观论述。他们证明，先前在投票预测等任务中报告的成功，关键依赖于“捷径特征”（例如，用党派身份预测投票选择），并通过引入一个新颖的、无捷径的基准（Soc-PRF），揭示了一个显著的差距。在缺少此类捷径的设定中，即使是最先进的LLMs表现也处于随机水平。这一发现强调了一个根本性局限：当前的LLMs虽然是优秀的表面相关性模式识别器，但缺乏真正的社会仿真以及涌现出稳健社会行为理解所必需的、更深层的因果或语境推理能力。他们的研究表明，要实现真正的社会拟真度，需要超越对数据中统计假象的利用。",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": ""
    },
    {
      "doi": "10.1609/aaai.v39i12.33430",
      "title": "Towards Effective, Efficient and Unsupervised Social Event Detection in the Hyperbolic Space",
      "authors": "Xiaoyan Yu,Yifan Wei,Shuaishuai Zhou,Zhiwei Yang,Li Sun,Hao Peng,Liehuang Zhu*,Philip S. Yu",
      "date": "2025-04-11",
      "category": "Event Extraction",
      "summary_motivation": "Social event detection on social media platforms faces significant challenges due to the large scale, dynamic nature, and complex relational structures inherent in user-generated content. Existing methods often suffer from inefficiency in processing massive message streams and limited expressive power in capturing hierarchical event structures.\n[翻译]：由于用户生成内容规模庞大、动态性强且关系结构复杂，社交媒体平台上的社交事件检测面临显著挑战。现有方法在处理海量消息流时常效率低下，且在捕捉层次化事件结构方面表达能力有限。",
      "summary_innovation": "The paper introduces HyperSED, a novel unsupervised framework that reduces computational overhead through a two-stage compression mechanism—semantic-based anchor construction and graph sparsification—and represents event clusters via a differentiable partitioning tree learned in hyperbolic space. This approach effectively captures hierarchical and nested event structures without requiring predefined cluster counts.\n[翻译]：本文提出HyperSED，一种新颖的无监督框架，通过基于语义的锚点构建与图稀疏化两阶段压缩机制降低计算开销，并利用在双曲空间中学习的可微划分树表示事件聚类。该方法无需预设聚类数量，即可有效捕捉层次化与嵌套的事件结构。",
      "summary_method": "The framework first constructs a semantic anchor graph to compress message nodes and simplify relational edges. It then maps the anchor graph into hyperbolic space and employs a hyperbolic graph autoencoder to learn structure-aware representations. Finally, a partitioning tree is built and optimized via differentiable structural information minimization, yielding hierarchical event clusters.\n[翻译]：该框架首先构建语义锚点图以压缩消息节点并简化关系边，随后将锚点图映射至双曲空间，采用双曲图自编码器学习结构感知表示，最终通过可微结构信息最小化构建并优化划分树，得到层次化事件簇",
      "summary_conclusion": "Experiments on real-world Twitter datasets demonstrate that HyperSED achieves competitive performance in normalized mutual information, adjusted mutual information, and adjusted Rand index, while improving computational efficiency by up to 37 times compared to state-of-the-art unsupervised baselines.\n[翻译]：在真实Twitter数据集上的实验表明，HyperSED在归一化互信息、调整互信息与调整兰德指数上均取得具有竞争力的性能，同时相比前沿无监督基线，计算效率提升最高达37倍。",
      "summary_limitation": "The performance may marginally decline in some message blocks due to potential errors in anchor construction, where semantically distinct messages are incorrectly grouped. Additionally, the efficiency gains come with a slight trade-off in clustering granularity control.\n[翻译]：由于锚点构建中可能出现语义不同消息被错误分组的情况，该模型在部分消息块上的性能可能略有下降。此外，效率提升在一定程度上以聚类粒度控制的精细度为代价。",
      "paper_url": "https://ojs.aaai.org/index.php/AAAI/article/view/33430",
      "project_url": "",
      "conference": "AAAI",
      "title_translation": "[AI generated] 中文标题：面向双曲空间中高效、有效且无监督的社交事件检测\n\n（说明：该翻译遵循以下原则：\n1. 专业术语准确对应：\"Hyperbolic Space\"译为\"双曲空间\"，\"Unsupervised\"译为\"无监督\"\n2. 学术风格保持：采用\"面向...的...\"句式体现研究导向性\n3. 逻辑结构清晰：通过顿号连接\"高效、有效\"突出框架的多重优势\n4. 领域",
      "analogy_summary": "通过两层压缩减少开销（简化边、节点聚合为锚点），通过划分树表示事件聚类",
      "pipeline_image": "figures/HyperSED.png",
      "abstract": "The vast, complex, and dynamic nature of social message data has posed challenges to social event detection (SED). Despite considerable effort, these challenges persist, often resulting in inadequately expressive message representations (ineffective) and prolonged learning durations (inefficient). In response to the challenges, this work introduces an unsupervised framework, HyperSED (Hyperbolic SED). Specifically, the proposed framework first models social messages into semantic-based message anchors, and then leverages the structure of the anchor graph and the expressiveness of the hyperbolic space to acquire structure- and geometry-aware anchor representations. Finally, HyperSED builds the partitioning tree of the anchor message graph by incorporating differentiable structural information as the reflection of the detected events. Extensive experiments on public datasets demonstrate HyperSED's competitive performance, along with a substantial improvement in efficiency compared to the current state-of-the-art unsupervised paradigm. Statistically, HyperSED boosts incremental SED by an average of 2%, 2%, and 25% in NMI, AMI, and ARI, respectively; enhancing efficiency by up to 37.41 times and at least 12.10 times, illustrating the advancement of the proposed framework.",
      "contributor": "anonymous",
      "notes": "[notes]为什么用双曲空间？ 现实世界的事件和话题往往具有层次结构（如“体育 -> 足球 -> 世界杯”）。双曲空间的几何特性（指数级增长的空间）能更自然、更紧凑地嵌入这种树状或层次化数据。<br>[通俗核心]通过消息各属性的相同性（用户、标签）构建网络；通过方法精简网络边【压缩1】；根据相关性将相似信息聚类为锚点，锚点之间有节点相连的构建边，得到锚点图【压缩2】；映射到双曲空间进行自监督重建训练（图自编码器GAE）获得聚合模型；模型输出根据特征向量距离自底向上聚合形成划分树，该树即表示消息各层级聚类关系。每个聚类节点都代表了一个某层级事件（如体育、世界杯、新冠）[引用文]HyperSED demonstrates how structural and geometric inductive biases can be integrated into scalable unsupervised learning (Yu et al., 2025). By compressing the message graph into semantic anchors and learning a partitioning tree in hyperbolic space—where internal nodes formed through bottom‑up aggregation represent concrete event categories—the framework not only enhances detection efficiency but also captures the multi‑scale organization of social events.\n\n[翻译]HyperSED展示了如何将结构与几何归纳偏置融入可扩展的无监督学习（Yu et al., 2025）。该框架通过将消息图压缩为语义锚点，并在双曲空间中学习划分树——其中通过自底向上聚合形成的内部节点代表具体的事件类别——不仅提升了检测效率，还捕捉了社交事件的多尺度组织特征。",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": ""
    },
    {
      "doi": "10.1007/978-981-99-8181-6_33",
      "title": "A Three-Stage Framework for Event-Event Relation Extraction with Large Language Model",
      "authors": "Feng Huang,Qiang Huang,YueTong Zhao,ZhiXiao Qi,BingKun Wang,YongFeng Huang,SongBin Li",
      "date": "2024",
      "category": "Event Extraction",
      "summary_motivation": "Traditional event relation extraction methods rely heavily on annotated data, which is costly and difficult to scale. The zero-shot capability of large language models remains underexplored for temporal and causal relation tasks.\n[翻译]\n传统事件关系提取方法严重依赖标注数据，成本高且难以扩展。大语言模型在时序与因果关系任务中的零样本能力尚未充分挖掘。",
      "summary_innovation": "A three-stage framework (ThreeEERE) is proposed, integrating an improved Auto-CoT prompting strategy with local knowledge retrieval to enable zero-shot event-event relation extraction without task-specific training.\n[翻译]\n提出三阶段框架ThreeEERE，融合改进的Auto-CoT提示策略与本地知识检索，实现无需任务特定训练的零样本事件-关系提取。",
      "summary_method": "构建示范样例（包含cot部分）->检索本地知识->取高于阈值的答案",
      "summary_conclusion": "ThreeEERE outperforms standard prompting methods and matches or surpasses several supervised baselines in event, temporal, and causal relation extraction across multiple datasets.\n[翻译]\n在多个数据集上的事件、时序与因果关系提取任务中，ThreeEERE优于标准提示方法，并达到或超越若干监督基线。",
      "summary_limitation": "Potential inconsistency between generated reasoning chains and gold answers in demonstrations may introduce noise and affect model stability.And it relies on the construction of a local knowledge base.\n[翻译]\n示范中生成的推理链与标准答案之间可能存在不一致，可能引入噪声并影响模型稳定性。且依赖于本地知识库构建",
      "paper_url": "https://link.springer.com/10.1007/978-981-99-8181-6_33",
      "project_url": "",
      "conference": "Neural Information Processing",
      "title_translation": "[AI generated] **中文标题：** 基于大语言模型的事件-事件关系提取三阶段框架\n\n**说明：** 此翻译准确传达了原标题的核心信息：\n1.  **“A Three-Stage Framework”** 译为 **“三阶段框架”**，清晰直接。\n2.  **“for Event-Event Relation Extraction”** 译为 **“事件-事件关系提取”**，符合计算机科学和自然语言处理领域的专业术语习惯（“关系抽取”或“",
      "analogy_summary": "通过结构化prompt构建的，无训练零样本的，依赖于本地知识库的，事件抽取方法",
      "pipeline_image": "figures/ThreeEERE.png",
      "abstract": "Expanding the parameter count of a large language model (LLM) alone is insufficient to achieve satisfactory outcomes in natural language processing tasks, specifically event extraction (EE), event temporal relation extraction (ETRE), and event causal relation extraction (ECRE). To tackle these challenges, we propose a novel three-stage extraction framework (ThreeEERE) that integrates an improved automatic chain of thought prompting (Auto-CoT) with LLM and is tailored based on a golden rule to maximize event and relation extraction precision. The three stages include constructing examples in each category, federating local knowledge to extract relationships between events, and selecting the best answer. By following these stages, we can achieve our objective. Although supervised models dominate for these tasks, our experiments on three types of extraction tasks demonstrate that utilizing these three stages approach yields significant results in event extraction and event relation extraction, even surpassing some supervised model methods in the extraction task.",
      "contributor": "anonymous",
      "notes": "[notes]聚类只是为了选择最接近聚类中心的测试样本，作为示范样例（因为接近中心意味着更能代表该聚类语义特征），之后的操作就是输入测试样例和这些示范样例（答案部分替换为标准答案）以及检索得到的本地知识，最终取超过阈值的结果<br>[引用文]The three-stage framework proposed by Huang et al. (2024) integrates chain-of-thought reasoning with localized knowledge, demonstrating the feasibility of eliciting zero-shot inference of complex event relations from large language models through meticulously designed prompts, without the need for supervised fine-tuning.\n[翻译]\nHuang等人（2024）提出的三阶段框架，将思维链推理与本地化知识相结合，证明了通过精心设计的提示词，无需监督微调即可从大语言模型中激发出对复杂事件关系的零样本推断能力。",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": ""
    },
    {
      "doi": "10.1609/icwsm.v19i1.35804",
      "title": "News Source Credibility Assessment: A Reddit Case Study",
      "authors": "Arash Amini, Yigit Ege Bayiz, Ashwin Ram, Radu Marculescu, and Ufuk Topcu",
      "date": "2025-06-07",
      "category": "Misinformation Analysis",
      "summary_motivation": "Driven by the proliferation of misinformation on social media, this work shifts focus from fact-checking individual news items to assessing the systemic credibility of news sources, addressing a critical gap in combating information pollution at its origin.\n[翻译]\n本研究受社交媒体虚假信息泛滥的驱动，将重点从核查单一新闻的真实性，转向评估新闻来源的系统性可信度，以应对从源头治理信息污染这一关键问题。",
      "summary_innovation": "Its core innovation lies in constructing a weighted post-to-post network based on the semantic similarity of user comments. This network models latent socio-contextual linkages between submissions, which are then integrated via a Graph Convolutional Network (GCN) to enhance the binary classification of source credibility.\n[翻译]\n其核心创新在于基于用户评论的语义相似性构建了一个加权帖子间网络。该网络建模了帖子间潜在的社会语境关联，并通过图卷积网络（GCN）整合这些关联，以提升对新闻来源可信度的二分类性能。",
      "summary_method": "The framework, CREDiBERT, first trains a bi-encoder on paired submissions about the same event to learn credibility-aware text embeddings. It then builds a novel graph where edge weights encode user reaction similarity via comments. Finally, a GCN fuses these textual and social signals for final classification.\n[翻译]\n该框架（CREDiBERT）首先在描述同一事件的成对帖子上训练一个双编码器，以学习具有可信度感知的文本嵌入。随后，它构建了一个新颖的图结构，其中边的权重通过评论编码了用户反应的相似性。最后，一个图卷积网络（GCN）融合了这些文本与社会信号以完成最终分类。",
      "summary_conclusion": "The model outperforms BERT-based baselines by 3% in F1-score for credibility assessment. Incorporating the user-interaction graph yields a further 8% gain, demonstrating the significant value of socially-grounded signals in evaluating information ecosystems.\n[翻译]\n该模型在可信度评估任务上的F1分数比基于BERT的基线模型高出3%。融入用户交互图后，性能进一步提升了8%，这证明了基于社交的感知信号在评估信息生态系统中的重要价值。",
      "summary_limitation": "The method assesses source reputation rather than article veracity, leaving it blind to one-off falsehoods from otherwise credible outlets. Its performance is also tied to the bias present in the training data from specific online communities.\n[翻译]\n该方法评估的是来源声誉而非文章真实性，因此无法识别那些来自通常可信媒体的偶然性虚假信息。同时，其性能受限于来自特定网络社区的训练数据中存在的固有偏差。",
      "paper_url": "https://ojs.aaai.org/index.php/ICWSM/article/view/35804",
      "project_url": "",
      "conference": "ICWSM",
      "title_translation": "[AI generated] 新闻来源可信度评估：一项基于Reddit的案例研究",
      "analogy_summary": "通过帖子间的评论区相似性构建加权铁子网络，以求找到水军蛛丝马迹，进而确定新闻来源是否可信",
      "pipeline_image": "figures/CREDiBERT.png",
      "abstract": "We present a transformer-based model for credibility assessment, CREDiBERT (CREDibility assessment using  Bi-directional Encoder Representations from Transformers), fine-tuned for Reddit submissions focusing on political discourse. We adopt a semi-supervised training approach for CREDiBERT, leveraging the community structure of Reddit. By encoding submission content using CREDiBERT and integrating it with a classification neural network, we improve the credibility assessment for Reddit submission by 3% in F1 score compared to existing methods. Additionally, we introduce a new version of the post-to-post network in Reddit that efficiently encodes user interactions to enhance the credibility assessment task by 8%  in the F1 score. We demonstrate CREDiBERT's applicability by evaluating the susceptibility of Reddit communities to different topics and assessing the credibility score of unseen sources.",
      "contributor": "anonymous",
      "notes": "[notes]关键设计在于通过评论区的评论相似性建模不同帖子间的潜在联系（加权帖子网络的边权重），在GCN中利用该联系来进行帖子的来源新闻的可信性二分类<br>[引用文]Amini et al. (2025) move beyond purely content-based pattern recognition, attempting instead to establish connections between posts and the credibility of news sources. Their CREDiBERT framework innovatively constructs a weighted post-to-post network from user comment similarities. This graph structure captures community-specific reaction patterns, which, when processed through a Graph Convolutional Network, significantly enhance the classification of news source credibility. This work underscores a paradigm shift: credibility assessment is beginning to focus on the patterns of information dissemination, rather than solely analyzing the specific content.\n[翻译]\nAmini等人（2025）的研究超越了单纯的基于内容的模式识别，转而尝试建立帖子与新闻来源可信度的联系。他们的CREDiBERT框架创新性地从用户评论相似性中构建了一个加权帖子间网络。该图结构捕获了社区的特定反应模式，这些模式通过图卷积网络处理后，显著增强了对新闻来源可信度的分类能力。这项工作强调了一个范式转变：可信度评估开始关注消息的传播模式，而不仅仅是分析具体内容。",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": ""
    },
    {
      "doi": "10.1145/3627673.3679519",
      "title": "Let silence speak: Enhancing fake news detection with generated comments from large language models",
      "authors": "Qiong Nan,Qiang Sheng∗,Juan Cao,Beizhe Hu,Danding Wang,Jintao Li",
      "date": "2024-10-21",
      "category": "Misinformation Analysis",
      "summary_motivation": "Comment-based fake news detection is hindered by the scarcity and skewed distribution of real user comments (e.g., in early stages or from “silent” users), leading to an incomplete and biased perception of public feedback.\n\n[翻译]基于评论的虚假新闻检测受限于真实用户评论的稀缺性与分布偏差（例如在早期传播阶段或来自“沉默”用户），导致对公众反馈的感知不完整且存在偏差。",
      "summary_innovation": "使用LLM补充评论特征，解决该领域评论数据不足和不全面的问题",
      "summary_method": "The GenFEND framework: (1) generates comments by prompting an LLM with 30 predefined user profiles (gender/age/education); (2) analyzes them via group-wise semantic averaging and diversity measurement across demographic views; (3) aggregates intra-view and inter-view features adaptively for final classification.\n\n[翻译]GenFEND框架：(1) 通过为LLM提供30个预定义用户画像（性别/年龄/教育）来生成评论；(2) 通过分组语义平均和跨人口统计视图的多样性度量对其进行分析；(3) 自适应地聚合视图内和视图间的特征以进行最终分类。",
      "summary_conclusion": "GenFEND consistently boosts both content-only and comment-based detectors across datasets. Notably, LLM-generated comments provide effective signals for early detection and can outperform actual comments, especially in identifying fake news.\n\n[翻译]GenFEND在多个数据集上持续提升了仅使用内容和使用评论的检测器性能。值得注意的是，LLM生成的评论为早期检测提供了有效信号，并且可以超越真实评论的效果，尤其在识别虚假新闻方面。",
      "summary_limitation": "Limitations include dependence on LLM generation quality, limited considered user attributes, and higher computational cost. Future work may explore more nuanced user modeling, dynamic profile generation, and integration with real social graphs.\n\n[翻译]局限性包括对LLM生成质量的依赖、所考虑用户属性的有限性以及较高的计算成本。未来工作可探索更细致的用户建模、动态画像生成以及与真实社交图谱的结合。",
      "paper_url": "https://dl.acm.org/doi/10.1145/3627673.3679519",
      "project_url": "",
      "conference": "CIKM '24",
      "title_translation": "[AI generated] **中文标题：** 让沉默发声：利用大语言模型生成评论增强虚假新闻检测\n\n**说明：** 该翻译准确传达了原标题的核心思想，即通过生成“沉默用户”的评论来提升检测效果。“让沉默发声”这一表述生动且符合中文语境，整体风格专业、简洁，适用于学术论文标题。",
      "analogy_summary": "“让沉默的用户发声——用LLM生成多样评论，补充评论特征，提升虚假新闻检测的覆盖力和早期性能。”",
      "pipeline_image": "figures/GenFEND.png",
      "abstract": "Fake news detection plays a crucial role in protecting social media users and maintaining a healthy news ecosystem. Among existing works, comment-based fake news detection methods are empirically shown as promising because comments could reflect users' opinions, stances, and emotions and deepen models' understanding of fake news. Unfortunately, due to exposure bias and users' different willingness to comment, it is not easy to obtain diverse comments in reality, especially for early detection scenarios. Without obtaining the comments from the \"silent'' users, the perceived opinions may be incomplete, subsequently affecting news veracity judgment. In this paper, we explore the possibility of finding an alternative source of comments to guarantee the availability of diverse comments, especially those from silent users. Specifically, we propose to adopt large language models (LLMs) as a user simulator and comment generator, and design GenFEND, a generated feedback-enhanced detection framework, which generates comments by prompting LLMs with diverse user profiles and aggregating generated comments from multiple subpopulation groups. Experiments demonstrate the effectiveness of GenFEND and further analysis shows that the generated comments cover more diverse users and could even be more effective than actual comments.",
      "contributor": "anonymous",
      "notes": "[引用文]Within the task of False Content Analysis, a key bottleneck is the scarcity of early-stage comments and the absence of opinions from silent users. The GenFEND framework (Nan et al., 2024) addresses this by using Large Language Models (LLMs) to supplement these missing comments. Instead of passively relying on sparse real comments, their approach actively generates a rich set of synthetic comments conditioned on diverse user profiles (e.g., gender, age, education level). This method effectively performs data augmentation in the social comment space, providing a stable and diverse informational supplement. This helps models establish a more complete perceptual foundation for veracity judgment and has proven to be highly effective for early fake news detection.\n[翻译]\n在虚假内容分析任务中，一个关键瓶颈是早期评论的稀缺性和沉默用户意见的缺失。GenFEND框架 (Nan et al., 2024) 通过使用大语言模型来补充这部分缺失的评论，从而解决了这一问题。该方法不再被动地依赖稀疏的真实评论，而是主动生成一组以多样化用户画像（如性别、年龄、教育程度）为条件的丰富合成评论。该方法有效地在社交评论空间进行了数据增强，提供了一个稳定且多样化的信息补充。这有助于模型为真实性判断建立更完整的感知基础，并被证明对早期虚假新闻检测非常有效。",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": ""
    }
  ],
  "meta": {
    "generated_at": "2026-01-21 02:16:53"
  }
}