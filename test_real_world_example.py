"""
å®Œæ•´ç¤ºä¾‹ï¼šä»Zotero Metaæå–åˆ†ç±»å¹¶éªŒè¯
"""
import json
from src.process_zotero_meta import ZoteroProcessor

# æ¨¡æ‹ŸçœŸå®çš„Zoteroå¯¼å‡ºæ•°æ®
real_world_example = {
    "itemType": "conferencePaper",
    "title": "Large Language Models for Social Media Content Moderation",
    "DOI": "10.1145/example.2024",
    "date": "2024-03-15",
    "url": "https://arxiv.org/abs/2403.12345",
    "abstractNote": "This paper explores the application of large language models in detecting hate speech and misinformation on social media platforms.",
    "creators": [
        {"creatorType": "author", "firstName": "Alice", "lastName": "Zhang"},
        {"creatorType": "author", "firstName": "Bob", "lastName": "Johnson"},
        {"creatorType": "author", "firstName": "Carol", "lastName": "Williams"}
    ],
    "conferenceName": "CHI 2024",
    "extra": "titleTranslation: å¤§è¯­è¨€æ¨¡å‹åœ¨ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸ä¸­çš„åº”ç”¨\nTLDR: æœ¬æ–‡ç ”ç©¶äº†å¤§è¯­è¨€æ¨¡å‹åœ¨ç¤¾äº¤åª’ä½“å¹³å°ä¸Šæ£€æµ‹ä»‡æ¨è¨€è®ºå’Œè™šå‡ä¿¡æ¯çš„åº”ç”¨",
    "tags": [
        {"tag": "cat Hate Speech Analysis"},
        {"tag": "cat Misinformation Analysis"},
        {"tag": "cat Social Media Security"},
        {"tag": "large language model"},
        {"tag": "content moderation"},
        {"tag": "social media"}
    ],
    "notes": [
        {"note": "<p>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåˆ›æ–°çš„æ–¹æ³•</p>"}
    ]
}

# å¤„ç†æ•°æ®
processor = ZoteroProcessor()
papers = processor.process_meta_data(real_world_example)

if papers:
    paper = papers[0]
    
    print("=" * 70)
    print("å®Œæ•´ç¤ºä¾‹ï¼šä»çœŸå®Zoteroæ•°æ®æå–è®ºæ–‡ä¿¡æ¯")
    print("=" * 70)
    
    print(f"\nğŸ“„ åŸºæœ¬ä¿¡æ¯")
    print(f"   æ ‡é¢˜: {paper.title}")
    print(f"   ä½œè€…: {paper.authors}")
    print(f"   ä¼šè®®: {paper.conference}")
    print(f"   æ—¥æœŸ: {paper.date}")
    print(f"   DOI: {paper.doi}")
    print(f"   URL: {paper.paper_url}")
    
    print(f"\nğŸ·ï¸  æå–çš„åˆ†ç±»")
    if paper.category:
        categories = paper.category.split(";")
        for i, cat in enumerate(categories, 1):
            print(f"   {i}. {cat}")
        print(f"   æ ¼å¼: {paper.category}")
    else:
        print(f"   æ— åˆ†ç±»")
    
    print(f"\nğŸ“ å…¶ä»–å­—æ®µ")
    print(f"   æ ‡é¢˜ç¿»è¯‘: {paper.title_translation}")
    print(f"   TLDR: {paper.analogy_summary}")
    print(f"   æ‘˜è¦: {paper.abstract[:100]}...")
    print(f"   ç¬”è®°: {paper.notes}")
    
    print(f"\nğŸ” åŸå§‹Tagsæ•°ç»„")
    print(json.dumps(real_world_example["tags"], indent=2, ensure_ascii=False))
    
    print(f"\nâœ… åˆ†ç±»æå–åˆ†æ")
    print(f"   - æ€»å…± {len(real_world_example['tags'])} ä¸ªæ ‡ç­¾")
    category_count = len(paper.category.split(";")) if paper.category else 0
    print(f"   - æå–å‡º {category_count} ä¸ªåˆ†ç±»")
    print(f"   - åˆ†ç±»æ ¼å¼: åˆ†å·åˆ†éš”çš„å­—ç¬¦ä¸²")
    print(f"   - å¿½ç•¥äº†éåˆ†ç±»æ ‡ç­¾: large language model, content moderation, social media")
    
    print("\n" + "=" * 70)
    print("æµ‹è¯•å®Œæˆï¼æ‰€æœ‰å­—æ®µéƒ½å·²æ­£ç¡®æå–")
    print("=" * 70)
else:
    print("âŒ æ— æ³•å¤„ç†æ•°æ®")
